// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: yandex/cloud/mdb/kafka/v1/cluster.proto

package yandex.cloud.api.mdb.kafka.v1;

public final class ClusterOuterClass {
  private ClusterOuterClass() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (com.google.protobuf.ExtensionRegistryLite) registry);
  }
  public interface ClusterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.Cluster)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * ID of the Apache Kafka® cluster.
     * This ID is assigned at creation time.
     * </pre>
     *
     * <code>string id = 1;</code>
     */
    java.lang.String getId();
    /**
     * <pre>
     * ID of the Apache Kafka® cluster.
     * This ID is assigned at creation time.
     * </pre>
     *
     * <code>string id = 1;</code>
     */
    com.google.protobuf.ByteString
        getIdBytes();

    /**
     * <pre>
     * ID of the folder that the Apache Kafka® cluster belongs to.
     * </pre>
     *
     * <code>string folder_id = 2;</code>
     */
    java.lang.String getFolderId();
    /**
     * <pre>
     * ID of the folder that the Apache Kafka® cluster belongs to.
     * </pre>
     *
     * <code>string folder_id = 2;</code>
     */
    com.google.protobuf.ByteString
        getFolderIdBytes();

    /**
     * <pre>
     * Creation timestamp.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp created_at = 3;</code>
     */
    boolean hasCreatedAt();
    /**
     * <pre>
     * Creation timestamp.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp created_at = 3;</code>
     */
    com.google.protobuf.Timestamp getCreatedAt();
    /**
     * <pre>
     * Creation timestamp.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp created_at = 3;</code>
     */
    com.google.protobuf.TimestampOrBuilder getCreatedAtOrBuilder();

    /**
     * <pre>
     * Name of the Apache Kafka® cluster.
     * The name must be unique within the folder. 1-63 characters long. Value must match the regular expression `[a-zA-Z0-9_-]*`.
     * </pre>
     *
     * <code>string name = 4;</code>
     */
    java.lang.String getName();
    /**
     * <pre>
     * Name of the Apache Kafka® cluster.
     * The name must be unique within the folder. 1-63 characters long. Value must match the regular expression `[a-zA-Z0-9_-]*`.
     * </pre>
     *
     * <code>string name = 4;</code>
     */
    com.google.protobuf.ByteString
        getNameBytes();

    /**
     * <pre>
     * Description of the Apache Kafka® cluster. 0-256 characters long.
     * </pre>
     *
     * <code>string description = 5;</code>
     */
    java.lang.String getDescription();
    /**
     * <pre>
     * Description of the Apache Kafka® cluster. 0-256 characters long.
     * </pre>
     *
     * <code>string description = 5;</code>
     */
    com.google.protobuf.ByteString
        getDescriptionBytes();

    /**
     * <pre>
     * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
     * A maximum of 64 labels per resource is allowed.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 6;</code>
     */
    int getLabelsCount();
    /**
     * <pre>
     * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
     * A maximum of 64 labels per resource is allowed.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 6;</code>
     */
    boolean containsLabels(
        java.lang.String key);
    /**
     * Use {@link #getLabelsMap()} instead.
     */
    @java.lang.Deprecated
    java.util.Map<java.lang.String, java.lang.String>
    getLabels();
    /**
     * <pre>
     * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
     * A maximum of 64 labels per resource is allowed.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 6;</code>
     */
    java.util.Map<java.lang.String, java.lang.String>
    getLabelsMap();
    /**
     * <pre>
     * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
     * A maximum of 64 labels per resource is allowed.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 6;</code>
     */

    java.lang.String getLabelsOrDefault(
        java.lang.String key,
        java.lang.String defaultValue);
    /**
     * <pre>
     * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
     * A maximum of 64 labels per resource is allowed.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 6;</code>
     */

    java.lang.String getLabelsOrThrow(
        java.lang.String key);

    /**
     * <pre>
     * Deployment environment of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Environment environment = 7;</code>
     */
    int getEnvironmentValue();
    /**
     * <pre>
     * Deployment environment of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Environment environment = 7;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Environment getEnvironment();

    /**
     * <pre>
     * Description of monitoring systems relevant to the Apache Kafka® cluster.
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
     */
    java.util.List<yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring> 
        getMonitoringList();
    /**
     * <pre>
     * Description of monitoring systems relevant to the Apache Kafka® cluster.
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring getMonitoring(int index);
    /**
     * <pre>
     * Description of monitoring systems relevant to the Apache Kafka® cluster.
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
     */
    int getMonitoringCount();
    /**
     * <pre>
     * Description of monitoring systems relevant to the Apache Kafka® cluster.
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
     */
    java.util.List<? extends yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.MonitoringOrBuilder> 
        getMonitoringOrBuilderList();
    /**
     * <pre>
     * Description of monitoring systems relevant to the Apache Kafka® cluster.
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.MonitoringOrBuilder getMonitoringOrBuilder(
        int index);

    /**
     * <pre>
     * Configuration of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
     */
    boolean hasConfig();
    /**
     * <pre>
     * Configuration of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec getConfig();
    /**
     * <pre>
     * Configuration of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpecOrBuilder getConfigOrBuilder();

    /**
     * <pre>
     * ID of the network that the cluster belongs to.
     * </pre>
     *
     * <code>string network_id = 10;</code>
     */
    java.lang.String getNetworkId();
    /**
     * <pre>
     * ID of the network that the cluster belongs to.
     * </pre>
     *
     * <code>string network_id = 10;</code>
     */
    com.google.protobuf.ByteString
        getNetworkIdBytes();

    /**
     * <pre>
     * Aggregated cluster health.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Health health = 11;</code>
     */
    int getHealthValue();
    /**
     * <pre>
     * Aggregated cluster health.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Health health = 11;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Health getHealth();

    /**
     * <pre>
     * Current state of the cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Status status = 12;</code>
     */
    int getStatusValue();
    /**
     * <pre>
     * Current state of the cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Status status = 12;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Status getStatus();

    /**
     * <pre>
     * User security groups
     * </pre>
     *
     * <code>repeated string security_group_ids = 13;</code>
     */
    java.util.List<java.lang.String>
        getSecurityGroupIdsList();
    /**
     * <pre>
     * User security groups
     * </pre>
     *
     * <code>repeated string security_group_ids = 13;</code>
     */
    int getSecurityGroupIdsCount();
    /**
     * <pre>
     * User security groups
     * </pre>
     *
     * <code>repeated string security_group_ids = 13;</code>
     */
    java.lang.String getSecurityGroupIds(int index);
    /**
     * <pre>
     * User security groups
     * </pre>
     *
     * <code>repeated string security_group_ids = 13;</code>
     */
    com.google.protobuf.ByteString
        getSecurityGroupIdsBytes(int index);

    /**
     * <pre>
     * Host groups hosting VMs of the cluster.
     * </pre>
     *
     * <code>repeated string host_group_ids = 14;</code>
     */
    java.util.List<java.lang.String>
        getHostGroupIdsList();
    /**
     * <pre>
     * Host groups hosting VMs of the cluster.
     * </pre>
     *
     * <code>repeated string host_group_ids = 14;</code>
     */
    int getHostGroupIdsCount();
    /**
     * <pre>
     * Host groups hosting VMs of the cluster.
     * </pre>
     *
     * <code>repeated string host_group_ids = 14;</code>
     */
    java.lang.String getHostGroupIds(int index);
    /**
     * <pre>
     * Host groups hosting VMs of the cluster.
     * </pre>
     *
     * <code>repeated string host_group_ids = 14;</code>
     */
    com.google.protobuf.ByteString
        getHostGroupIdsBytes(int index);

    /**
     * <pre>
     * Deletion Protection inhibits deletion of the cluster
     * </pre>
     *
     * <code>bool deletion_protection = 15;</code>
     */
    boolean getDeletionProtection();

    /**
     * <pre>
     * Window of maintenance operations.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
     */
    boolean hasMaintenanceWindow();
    /**
     * <pre>
     * Window of maintenance operations.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow getMaintenanceWindow();
    /**
     * <pre>
     * Window of maintenance operations.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindowOrBuilder getMaintenanceWindowOrBuilder();

    /**
     * <pre>
     * Scheduled maintenance operation.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
     */
    boolean hasPlannedOperation();
    /**
     * <pre>
     * Scheduled maintenance operation.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation getPlannedOperation();
    /**
     * <pre>
     * Scheduled maintenance operation.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperationOrBuilder getPlannedOperationOrBuilder();
  }
  /**
   * <pre>
   * An Apache Kafka® cluster resource.
   * For more information, see the [Concepts](/docs/managed-kafka/concepts) section of the documentation.
   * </pre>
   *
   * Protobuf type {@code yandex.cloud.mdb.kafka.v1.Cluster}
   */
  public  static final class Cluster extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.Cluster)
      ClusterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Cluster.newBuilder() to construct.
    private Cluster(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Cluster() {
      id_ = "";
      folderId_ = "";
      name_ = "";
      description_ = "";
      environment_ = 0;
      monitoring_ = java.util.Collections.emptyList();
      networkId_ = "";
      health_ = 0;
      status_ = 0;
      securityGroupIds_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      hostGroupIds_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      deletionProtection_ = false;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private Cluster(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              id_ = s;
              break;
            }
            case 18: {
              java.lang.String s = input.readStringRequireUtf8();

              folderId_ = s;
              break;
            }
            case 26: {
              com.google.protobuf.Timestamp.Builder subBuilder = null;
              if (createdAt_ != null) {
                subBuilder = createdAt_.toBuilder();
              }
              createdAt_ = input.readMessage(com.google.protobuf.Timestamp.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(createdAt_);
                createdAt_ = subBuilder.buildPartial();
              }

              break;
            }
            case 34: {
              java.lang.String s = input.readStringRequireUtf8();

              name_ = s;
              break;
            }
            case 42: {
              java.lang.String s = input.readStringRequireUtf8();

              description_ = s;
              break;
            }
            case 50: {
              if (!((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
                labels_ = com.google.protobuf.MapField.newMapField(
                    LabelsDefaultEntryHolder.defaultEntry);
                mutable_bitField0_ |= 0x00000020;
              }
              com.google.protobuf.MapEntry<java.lang.String, java.lang.String>
              labels__ = input.readMessage(
                  LabelsDefaultEntryHolder.defaultEntry.getParserForType(), extensionRegistry);
              labels_.getMutableMap().put(
                  labels__.getKey(), labels__.getValue());
              break;
            }
            case 56: {
              int rawValue = input.readEnum();

              environment_ = rawValue;
              break;
            }
            case 66: {
              if (!((mutable_bitField0_ & 0x00000080) == 0x00000080)) {
                monitoring_ = new java.util.ArrayList<yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring>();
                mutable_bitField0_ |= 0x00000080;
              }
              monitoring_.add(
                  input.readMessage(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.parser(), extensionRegistry));
              break;
            }
            case 74: {
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Builder subBuilder = null;
              if (config_ != null) {
                subBuilder = config_.toBuilder();
              }
              config_ = input.readMessage(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(config_);
                config_ = subBuilder.buildPartial();
              }

              break;
            }
            case 82: {
              java.lang.String s = input.readStringRequireUtf8();

              networkId_ = s;
              break;
            }
            case 88: {
              int rawValue = input.readEnum();

              health_ = rawValue;
              break;
            }
            case 96: {
              int rawValue = input.readEnum();

              status_ = rawValue;
              break;
            }
            case 106: {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00001000) == 0x00001000)) {
                securityGroupIds_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00001000;
              }
              securityGroupIds_.add(s);
              break;
            }
            case 114: {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00002000) == 0x00002000)) {
                hostGroupIds_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00002000;
              }
              hostGroupIds_.add(s);
              break;
            }
            case 120: {

              deletionProtection_ = input.readBool();
              break;
            }
            case 130: {
              yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow.Builder subBuilder = null;
              if (maintenanceWindow_ != null) {
                subBuilder = maintenanceWindow_.toBuilder();
              }
              maintenanceWindow_ = input.readMessage(yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(maintenanceWindow_);
                maintenanceWindow_ = subBuilder.buildPartial();
              }

              break;
            }
            case 138: {
              yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation.Builder subBuilder = null;
              if (plannedOperation_ != null) {
                subBuilder = plannedOperation_.toBuilder();
              }
              plannedOperation_ = input.readMessage(yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(plannedOperation_);
                plannedOperation_ = subBuilder.buildPartial();
              }

              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000080) == 0x00000080)) {
          monitoring_ = java.util.Collections.unmodifiableList(monitoring_);
        }
        if (((mutable_bitField0_ & 0x00001000) == 0x00001000)) {
          securityGroupIds_ = securityGroupIds_.getUnmodifiableView();
        }
        if (((mutable_bitField0_ & 0x00002000) == 0x00002000)) {
          hostGroupIds_ = hostGroupIds_.getUnmodifiableView();
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Cluster_descriptor;
    }

    @SuppressWarnings({"rawtypes"})
    @java.lang.Override
    protected com.google.protobuf.MapField internalGetMapField(
        int number) {
      switch (number) {
        case 6:
          return internalGetLabels();
        default:
          throw new RuntimeException(
              "Invalid map field number: " + number);
      }
    }
    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Cluster_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Builder.class);
    }

    /**
     * Protobuf enum {@code yandex.cloud.mdb.kafka.v1.Cluster.Environment}
     */
    public enum Environment
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>ENVIRONMENT_UNSPECIFIED = 0;</code>
       */
      ENVIRONMENT_UNSPECIFIED(0),
      /**
       * <pre>
       * stable environment with a conservative update policy when only hotfixes are applied during regular maintenance.
       * </pre>
       *
       * <code>PRODUCTION = 1;</code>
       */
      PRODUCTION(1),
      /**
       * <pre>
       * environment with a more aggressive update policy when new versions are rolled out irrespective of backward compatibility.
       * </pre>
       *
       * <code>PRESTABLE = 2;</code>
       */
      PRESTABLE(2),
      UNRECOGNIZED(-1),
      ;

      /**
       * <code>ENVIRONMENT_UNSPECIFIED = 0;</code>
       */
      public static final int ENVIRONMENT_UNSPECIFIED_VALUE = 0;
      /**
       * <pre>
       * stable environment with a conservative update policy when only hotfixes are applied during regular maintenance.
       * </pre>
       *
       * <code>PRODUCTION = 1;</code>
       */
      public static final int PRODUCTION_VALUE = 1;
      /**
       * <pre>
       * environment with a more aggressive update policy when new versions are rolled out irrespective of backward compatibility.
       * </pre>
       *
       * <code>PRESTABLE = 2;</code>
       */
      public static final int PRESTABLE_VALUE = 2;


      public final int getNumber() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalArgumentException(
              "Can't get the number of an unknown enum value.");
        }
        return value;
      }

      /**
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static Environment valueOf(int value) {
        return forNumber(value);
      }

      public static Environment forNumber(int value) {
        switch (value) {
          case 0: return ENVIRONMENT_UNSPECIFIED;
          case 1: return PRODUCTION;
          case 2: return PRESTABLE;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<Environment>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final com.google.protobuf.Internal.EnumLiteMap<
          Environment> internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<Environment>() {
              public Environment findValueByNumber(int number) {
                return Environment.forNumber(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(ordinal());
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.getDescriptor().getEnumTypes().get(0);
      }

      private static final Environment[] VALUES = values();

      public static Environment valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        if (desc.getIndex() == -1) {
          return UNRECOGNIZED;
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private Environment(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:yandex.cloud.mdb.kafka.v1.Cluster.Environment)
    }

    /**
     * Protobuf enum {@code yandex.cloud.mdb.kafka.v1.Cluster.Health}
     */
    public enum Health
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <pre>
       * state of the cluster is unknown ([Host.health] of all hosts in the cluster is `UNKNOWN`).
       * </pre>
       *
       * <code>HEALTH_UNKNOWN = 0;</code>
       */
      HEALTH_UNKNOWN(0),
      /**
       * <pre>
       * cluster is alive and well ([Host.health] of all hosts in the cluster is `ALIVE`).
       * </pre>
       *
       * <code>ALIVE = 1;</code>
       */
      ALIVE(1),
      /**
       * <pre>
       * cluster is inoperable ([Host.health] of all hosts in the cluster is `DEAD`).
       * </pre>
       *
       * <code>DEAD = 2;</code>
       */
      DEAD(2),
      /**
       * <pre>
       * cluster is in degraded state ([Host.health] of at least one of the hosts in the cluster is not `ALIVE`).
       * </pre>
       *
       * <code>DEGRADED = 3;</code>
       */
      DEGRADED(3),
      UNRECOGNIZED(-1),
      ;

      /**
       * <pre>
       * state of the cluster is unknown ([Host.health] of all hosts in the cluster is `UNKNOWN`).
       * </pre>
       *
       * <code>HEALTH_UNKNOWN = 0;</code>
       */
      public static final int HEALTH_UNKNOWN_VALUE = 0;
      /**
       * <pre>
       * cluster is alive and well ([Host.health] of all hosts in the cluster is `ALIVE`).
       * </pre>
       *
       * <code>ALIVE = 1;</code>
       */
      public static final int ALIVE_VALUE = 1;
      /**
       * <pre>
       * cluster is inoperable ([Host.health] of all hosts in the cluster is `DEAD`).
       * </pre>
       *
       * <code>DEAD = 2;</code>
       */
      public static final int DEAD_VALUE = 2;
      /**
       * <pre>
       * cluster is in degraded state ([Host.health] of at least one of the hosts in the cluster is not `ALIVE`).
       * </pre>
       *
       * <code>DEGRADED = 3;</code>
       */
      public static final int DEGRADED_VALUE = 3;


      public final int getNumber() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalArgumentException(
              "Can't get the number of an unknown enum value.");
        }
        return value;
      }

      /**
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static Health valueOf(int value) {
        return forNumber(value);
      }

      public static Health forNumber(int value) {
        switch (value) {
          case 0: return HEALTH_UNKNOWN;
          case 1: return ALIVE;
          case 2: return DEAD;
          case 3: return DEGRADED;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<Health>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final com.google.protobuf.Internal.EnumLiteMap<
          Health> internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<Health>() {
              public Health findValueByNumber(int number) {
                return Health.forNumber(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(ordinal());
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.getDescriptor().getEnumTypes().get(1);
      }

      private static final Health[] VALUES = values();

      public static Health valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        if (desc.getIndex() == -1) {
          return UNRECOGNIZED;
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private Health(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:yandex.cloud.mdb.kafka.v1.Cluster.Health)
    }

    /**
     * Protobuf enum {@code yandex.cloud.mdb.kafka.v1.Cluster.Status}
     */
    public enum Status
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <pre>
       * cluster state is unknown.
       * </pre>
       *
       * <code>STATUS_UNKNOWN = 0;</code>
       */
      STATUS_UNKNOWN(0),
      /**
       * <pre>
       * cluster is being created.
       * </pre>
       *
       * <code>CREATING = 1;</code>
       */
      CREATING(1),
      /**
       * <pre>
       * cluster is running normally.
       * </pre>
       *
       * <code>RUNNING = 2;</code>
       */
      RUNNING(2),
      /**
       * <pre>
       * cluster encountered a problem and cannot operate.
       * </pre>
       *
       * <code>ERROR = 3;</code>
       */
      ERROR(3),
      /**
       * <pre>
       * cluster is being updated.
       * </pre>
       *
       * <code>UPDATING = 4;</code>
       */
      UPDATING(4),
      /**
       * <pre>
       * cluster is stopping.
       * </pre>
       *
       * <code>STOPPING = 5;</code>
       */
      STOPPING(5),
      /**
       * <pre>
       * cluster stopped.
       * </pre>
       *
       * <code>STOPPED = 6;</code>
       */
      STOPPED(6),
      /**
       * <pre>
       * cluster is starting.
       * </pre>
       *
       * <code>STARTING = 7;</code>
       */
      STARTING(7),
      UNRECOGNIZED(-1),
      ;

      /**
       * <pre>
       * cluster state is unknown.
       * </pre>
       *
       * <code>STATUS_UNKNOWN = 0;</code>
       */
      public static final int STATUS_UNKNOWN_VALUE = 0;
      /**
       * <pre>
       * cluster is being created.
       * </pre>
       *
       * <code>CREATING = 1;</code>
       */
      public static final int CREATING_VALUE = 1;
      /**
       * <pre>
       * cluster is running normally.
       * </pre>
       *
       * <code>RUNNING = 2;</code>
       */
      public static final int RUNNING_VALUE = 2;
      /**
       * <pre>
       * cluster encountered a problem and cannot operate.
       * </pre>
       *
       * <code>ERROR = 3;</code>
       */
      public static final int ERROR_VALUE = 3;
      /**
       * <pre>
       * cluster is being updated.
       * </pre>
       *
       * <code>UPDATING = 4;</code>
       */
      public static final int UPDATING_VALUE = 4;
      /**
       * <pre>
       * cluster is stopping.
       * </pre>
       *
       * <code>STOPPING = 5;</code>
       */
      public static final int STOPPING_VALUE = 5;
      /**
       * <pre>
       * cluster stopped.
       * </pre>
       *
       * <code>STOPPED = 6;</code>
       */
      public static final int STOPPED_VALUE = 6;
      /**
       * <pre>
       * cluster is starting.
       * </pre>
       *
       * <code>STARTING = 7;</code>
       */
      public static final int STARTING_VALUE = 7;


      public final int getNumber() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalArgumentException(
              "Can't get the number of an unknown enum value.");
        }
        return value;
      }

      /**
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static Status valueOf(int value) {
        return forNumber(value);
      }

      public static Status forNumber(int value) {
        switch (value) {
          case 0: return STATUS_UNKNOWN;
          case 1: return CREATING;
          case 2: return RUNNING;
          case 3: return ERROR;
          case 4: return UPDATING;
          case 5: return STOPPING;
          case 6: return STOPPED;
          case 7: return STARTING;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<Status>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final com.google.protobuf.Internal.EnumLiteMap<
          Status> internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<Status>() {
              public Status findValueByNumber(int number) {
                return Status.forNumber(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(ordinal());
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.getDescriptor().getEnumTypes().get(2);
      }

      private static final Status[] VALUES = values();

      public static Status valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        if (desc.getIndex() == -1) {
          return UNRECOGNIZED;
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private Status(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:yandex.cloud.mdb.kafka.v1.Cluster.Status)
    }

    private int bitField0_;
    public static final int ID_FIELD_NUMBER = 1;
    private volatile java.lang.Object id_;
    /**
     * <pre>
     * ID of the Apache Kafka® cluster.
     * This ID is assigned at creation time.
     * </pre>
     *
     * <code>string id = 1;</code>
     */
    public java.lang.String getId() {
      java.lang.Object ref = id_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        id_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of the Apache Kafka® cluster.
     * This ID is assigned at creation time.
     * </pre>
     *
     * <code>string id = 1;</code>
     */
    public com.google.protobuf.ByteString
        getIdBytes() {
      java.lang.Object ref = id_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        id_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int FOLDER_ID_FIELD_NUMBER = 2;
    private volatile java.lang.Object folderId_;
    /**
     * <pre>
     * ID of the folder that the Apache Kafka® cluster belongs to.
     * </pre>
     *
     * <code>string folder_id = 2;</code>
     */
    public java.lang.String getFolderId() {
      java.lang.Object ref = folderId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        folderId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of the folder that the Apache Kafka® cluster belongs to.
     * </pre>
     *
     * <code>string folder_id = 2;</code>
     */
    public com.google.protobuf.ByteString
        getFolderIdBytes() {
      java.lang.Object ref = folderId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        folderId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CREATED_AT_FIELD_NUMBER = 3;
    private com.google.protobuf.Timestamp createdAt_;
    /**
     * <pre>
     * Creation timestamp.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp created_at = 3;</code>
     */
    public boolean hasCreatedAt() {
      return createdAt_ != null;
    }
    /**
     * <pre>
     * Creation timestamp.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp created_at = 3;</code>
     */
    public com.google.protobuf.Timestamp getCreatedAt() {
      return createdAt_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : createdAt_;
    }
    /**
     * <pre>
     * Creation timestamp.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp created_at = 3;</code>
     */
    public com.google.protobuf.TimestampOrBuilder getCreatedAtOrBuilder() {
      return getCreatedAt();
    }

    public static final int NAME_FIELD_NUMBER = 4;
    private volatile java.lang.Object name_;
    /**
     * <pre>
     * Name of the Apache Kafka® cluster.
     * The name must be unique within the folder. 1-63 characters long. Value must match the regular expression `[a-zA-Z0-9_-]*`.
     * </pre>
     *
     * <code>string name = 4;</code>
     */
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        name_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Name of the Apache Kafka® cluster.
     * The name must be unique within the folder. 1-63 characters long. Value must match the regular expression `[a-zA-Z0-9_-]*`.
     * </pre>
     *
     * <code>string name = 4;</code>
     */
    public com.google.protobuf.ByteString
        getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int DESCRIPTION_FIELD_NUMBER = 5;
    private volatile java.lang.Object description_;
    /**
     * <pre>
     * Description of the Apache Kafka® cluster. 0-256 characters long.
     * </pre>
     *
     * <code>string description = 5;</code>
     */
    public java.lang.String getDescription() {
      java.lang.Object ref = description_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        description_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Description of the Apache Kafka® cluster. 0-256 characters long.
     * </pre>
     *
     * <code>string description = 5;</code>
     */
    public com.google.protobuf.ByteString
        getDescriptionBytes() {
      java.lang.Object ref = description_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        description_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int LABELS_FIELD_NUMBER = 6;
    private static final class LabelsDefaultEntryHolder {
      static final com.google.protobuf.MapEntry<
          java.lang.String, java.lang.String> defaultEntry =
              com.google.protobuf.MapEntry
              .<java.lang.String, java.lang.String>newDefaultInstance(
                  yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Cluster_LabelsEntry_descriptor, 
                  com.google.protobuf.WireFormat.FieldType.STRING,
                  "",
                  com.google.protobuf.WireFormat.FieldType.STRING,
                  "");
    }
    private com.google.protobuf.MapField<
        java.lang.String, java.lang.String> labels_;
    private com.google.protobuf.MapField<java.lang.String, java.lang.String>
    internalGetLabels() {
      if (labels_ == null) {
        return com.google.protobuf.MapField.emptyMapField(
            LabelsDefaultEntryHolder.defaultEntry);
      }
      return labels_;
    }

    public int getLabelsCount() {
      return internalGetLabels().getMap().size();
    }
    /**
     * <pre>
     * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
     * A maximum of 64 labels per resource is allowed.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 6;</code>
     */

    public boolean containsLabels(
        java.lang.String key) {
      if (key == null) { throw new java.lang.NullPointerException(); }
      return internalGetLabels().getMap().containsKey(key);
    }
    /**
     * Use {@link #getLabelsMap()} instead.
     */
    @java.lang.Deprecated
    public java.util.Map<java.lang.String, java.lang.String> getLabels() {
      return getLabelsMap();
    }
    /**
     * <pre>
     * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
     * A maximum of 64 labels per resource is allowed.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 6;</code>
     */

    public java.util.Map<java.lang.String, java.lang.String> getLabelsMap() {
      return internalGetLabels().getMap();
    }
    /**
     * <pre>
     * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
     * A maximum of 64 labels per resource is allowed.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 6;</code>
     */

    public java.lang.String getLabelsOrDefault(
        java.lang.String key,
        java.lang.String defaultValue) {
      if (key == null) { throw new java.lang.NullPointerException(); }
      java.util.Map<java.lang.String, java.lang.String> map =
          internalGetLabels().getMap();
      return map.containsKey(key) ? map.get(key) : defaultValue;
    }
    /**
     * <pre>
     * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
     * A maximum of 64 labels per resource is allowed.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 6;</code>
     */

    public java.lang.String getLabelsOrThrow(
        java.lang.String key) {
      if (key == null) { throw new java.lang.NullPointerException(); }
      java.util.Map<java.lang.String, java.lang.String> map =
          internalGetLabels().getMap();
      if (!map.containsKey(key)) {
        throw new java.lang.IllegalArgumentException();
      }
      return map.get(key);
    }

    public static final int ENVIRONMENT_FIELD_NUMBER = 7;
    private int environment_;
    /**
     * <pre>
     * Deployment environment of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Environment environment = 7;</code>
     */
    public int getEnvironmentValue() {
      return environment_;
    }
    /**
     * <pre>
     * Deployment environment of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Environment environment = 7;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Environment getEnvironment() {
      @SuppressWarnings("deprecation")
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Environment result = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Environment.valueOf(environment_);
      return result == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Environment.UNRECOGNIZED : result;
    }

    public static final int MONITORING_FIELD_NUMBER = 8;
    private java.util.List<yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring> monitoring_;
    /**
     * <pre>
     * Description of monitoring systems relevant to the Apache Kafka® cluster.
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
     */
    public java.util.List<yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring> getMonitoringList() {
      return monitoring_;
    }
    /**
     * <pre>
     * Description of monitoring systems relevant to the Apache Kafka® cluster.
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
     */
    public java.util.List<? extends yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.MonitoringOrBuilder> 
        getMonitoringOrBuilderList() {
      return monitoring_;
    }
    /**
     * <pre>
     * Description of monitoring systems relevant to the Apache Kafka® cluster.
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
     */
    public int getMonitoringCount() {
      return monitoring_.size();
    }
    /**
     * <pre>
     * Description of monitoring systems relevant to the Apache Kafka® cluster.
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring getMonitoring(int index) {
      return monitoring_.get(index);
    }
    /**
     * <pre>
     * Description of monitoring systems relevant to the Apache Kafka® cluster.
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.MonitoringOrBuilder getMonitoringOrBuilder(
        int index) {
      return monitoring_.get(index);
    }

    public static final int CONFIG_FIELD_NUMBER = 9;
    private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec config_;
    /**
     * <pre>
     * Configuration of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
     */
    public boolean hasConfig() {
      return config_ != null;
    }
    /**
     * <pre>
     * Configuration of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec getConfig() {
      return config_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.getDefaultInstance() : config_;
    }
    /**
     * <pre>
     * Configuration of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpecOrBuilder getConfigOrBuilder() {
      return getConfig();
    }

    public static final int NETWORK_ID_FIELD_NUMBER = 10;
    private volatile java.lang.Object networkId_;
    /**
     * <pre>
     * ID of the network that the cluster belongs to.
     * </pre>
     *
     * <code>string network_id = 10;</code>
     */
    public java.lang.String getNetworkId() {
      java.lang.Object ref = networkId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        networkId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of the network that the cluster belongs to.
     * </pre>
     *
     * <code>string network_id = 10;</code>
     */
    public com.google.protobuf.ByteString
        getNetworkIdBytes() {
      java.lang.Object ref = networkId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        networkId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int HEALTH_FIELD_NUMBER = 11;
    private int health_;
    /**
     * <pre>
     * Aggregated cluster health.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Health health = 11;</code>
     */
    public int getHealthValue() {
      return health_;
    }
    /**
     * <pre>
     * Aggregated cluster health.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Health health = 11;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Health getHealth() {
      @SuppressWarnings("deprecation")
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Health result = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Health.valueOf(health_);
      return result == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Health.UNRECOGNIZED : result;
    }

    public static final int STATUS_FIELD_NUMBER = 12;
    private int status_;
    /**
     * <pre>
     * Current state of the cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Status status = 12;</code>
     */
    public int getStatusValue() {
      return status_;
    }
    /**
     * <pre>
     * Current state of the cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Status status = 12;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Status getStatus() {
      @SuppressWarnings("deprecation")
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Status result = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Status.valueOf(status_);
      return result == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Status.UNRECOGNIZED : result;
    }

    public static final int SECURITY_GROUP_IDS_FIELD_NUMBER = 13;
    private com.google.protobuf.LazyStringList securityGroupIds_;
    /**
     * <pre>
     * User security groups
     * </pre>
     *
     * <code>repeated string security_group_ids = 13;</code>
     */
    public com.google.protobuf.ProtocolStringList
        getSecurityGroupIdsList() {
      return securityGroupIds_;
    }
    /**
     * <pre>
     * User security groups
     * </pre>
     *
     * <code>repeated string security_group_ids = 13;</code>
     */
    public int getSecurityGroupIdsCount() {
      return securityGroupIds_.size();
    }
    /**
     * <pre>
     * User security groups
     * </pre>
     *
     * <code>repeated string security_group_ids = 13;</code>
     */
    public java.lang.String getSecurityGroupIds(int index) {
      return securityGroupIds_.get(index);
    }
    /**
     * <pre>
     * User security groups
     * </pre>
     *
     * <code>repeated string security_group_ids = 13;</code>
     */
    public com.google.protobuf.ByteString
        getSecurityGroupIdsBytes(int index) {
      return securityGroupIds_.getByteString(index);
    }

    public static final int HOST_GROUP_IDS_FIELD_NUMBER = 14;
    private com.google.protobuf.LazyStringList hostGroupIds_;
    /**
     * <pre>
     * Host groups hosting VMs of the cluster.
     * </pre>
     *
     * <code>repeated string host_group_ids = 14;</code>
     */
    public com.google.protobuf.ProtocolStringList
        getHostGroupIdsList() {
      return hostGroupIds_;
    }
    /**
     * <pre>
     * Host groups hosting VMs of the cluster.
     * </pre>
     *
     * <code>repeated string host_group_ids = 14;</code>
     */
    public int getHostGroupIdsCount() {
      return hostGroupIds_.size();
    }
    /**
     * <pre>
     * Host groups hosting VMs of the cluster.
     * </pre>
     *
     * <code>repeated string host_group_ids = 14;</code>
     */
    public java.lang.String getHostGroupIds(int index) {
      return hostGroupIds_.get(index);
    }
    /**
     * <pre>
     * Host groups hosting VMs of the cluster.
     * </pre>
     *
     * <code>repeated string host_group_ids = 14;</code>
     */
    public com.google.protobuf.ByteString
        getHostGroupIdsBytes(int index) {
      return hostGroupIds_.getByteString(index);
    }

    public static final int DELETION_PROTECTION_FIELD_NUMBER = 15;
    private boolean deletionProtection_;
    /**
     * <pre>
     * Deletion Protection inhibits deletion of the cluster
     * </pre>
     *
     * <code>bool deletion_protection = 15;</code>
     */
    public boolean getDeletionProtection() {
      return deletionProtection_;
    }

    public static final int MAINTENANCE_WINDOW_FIELD_NUMBER = 16;
    private yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow maintenanceWindow_;
    /**
     * <pre>
     * Window of maintenance operations.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
     */
    public boolean hasMaintenanceWindow() {
      return maintenanceWindow_ != null;
    }
    /**
     * <pre>
     * Window of maintenance operations.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow getMaintenanceWindow() {
      return maintenanceWindow_ == null ? yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow.getDefaultInstance() : maintenanceWindow_;
    }
    /**
     * <pre>
     * Window of maintenance operations.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindowOrBuilder getMaintenanceWindowOrBuilder() {
      return getMaintenanceWindow();
    }

    public static final int PLANNED_OPERATION_FIELD_NUMBER = 17;
    private yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation plannedOperation_;
    /**
     * <pre>
     * Scheduled maintenance operation.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
     */
    public boolean hasPlannedOperation() {
      return plannedOperation_ != null;
    }
    /**
     * <pre>
     * Scheduled maintenance operation.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation getPlannedOperation() {
      return plannedOperation_ == null ? yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation.getDefaultInstance() : plannedOperation_;
    }
    /**
     * <pre>
     * Scheduled maintenance operation.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperationOrBuilder getPlannedOperationOrBuilder() {
      return getPlannedOperation();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!getIdBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, id_);
      }
      if (!getFolderIdBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, folderId_);
      }
      if (createdAt_ != null) {
        output.writeMessage(3, getCreatedAt());
      }
      if (!getNameBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 4, name_);
      }
      if (!getDescriptionBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 5, description_);
      }
      com.google.protobuf.GeneratedMessageV3
        .serializeStringMapTo(
          output,
          internalGetLabels(),
          LabelsDefaultEntryHolder.defaultEntry,
          6);
      if (environment_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Environment.ENVIRONMENT_UNSPECIFIED.getNumber()) {
        output.writeEnum(7, environment_);
      }
      for (int i = 0; i < monitoring_.size(); i++) {
        output.writeMessage(8, monitoring_.get(i));
      }
      if (config_ != null) {
        output.writeMessage(9, getConfig());
      }
      if (!getNetworkIdBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 10, networkId_);
      }
      if (health_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Health.HEALTH_UNKNOWN.getNumber()) {
        output.writeEnum(11, health_);
      }
      if (status_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Status.STATUS_UNKNOWN.getNumber()) {
        output.writeEnum(12, status_);
      }
      for (int i = 0; i < securityGroupIds_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 13, securityGroupIds_.getRaw(i));
      }
      for (int i = 0; i < hostGroupIds_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 14, hostGroupIds_.getRaw(i));
      }
      if (deletionProtection_ != false) {
        output.writeBool(15, deletionProtection_);
      }
      if (maintenanceWindow_ != null) {
        output.writeMessage(16, getMaintenanceWindow());
      }
      if (plannedOperation_ != null) {
        output.writeMessage(17, getPlannedOperation());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!getIdBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, id_);
      }
      if (!getFolderIdBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, folderId_);
      }
      if (createdAt_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getCreatedAt());
      }
      if (!getNameBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(4, name_);
      }
      if (!getDescriptionBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(5, description_);
      }
      for (java.util.Map.Entry<java.lang.String, java.lang.String> entry
           : internalGetLabels().getMap().entrySet()) {
        com.google.protobuf.MapEntry<java.lang.String, java.lang.String>
        labels__ = LabelsDefaultEntryHolder.defaultEntry.newBuilderForType()
            .setKey(entry.getKey())
            .setValue(entry.getValue())
            .build();
        size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(6, labels__);
      }
      if (environment_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Environment.ENVIRONMENT_UNSPECIFIED.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(7, environment_);
      }
      for (int i = 0; i < monitoring_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(8, monitoring_.get(i));
      }
      if (config_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(9, getConfig());
      }
      if (!getNetworkIdBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(10, networkId_);
      }
      if (health_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Health.HEALTH_UNKNOWN.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(11, health_);
      }
      if (status_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Status.STATUS_UNKNOWN.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(12, status_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < securityGroupIds_.size(); i++) {
          dataSize += computeStringSizeNoTag(securityGroupIds_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getSecurityGroupIdsList().size();
      }
      {
        int dataSize = 0;
        for (int i = 0; i < hostGroupIds_.size(); i++) {
          dataSize += computeStringSizeNoTag(hostGroupIds_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getHostGroupIdsList().size();
      }
      if (deletionProtection_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(15, deletionProtection_);
      }
      if (maintenanceWindow_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(16, getMaintenanceWindow());
      }
      if (plannedOperation_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(17, getPlannedOperation());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster)) {
        return super.equals(obj);
      }
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster other = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster) obj;

      boolean result = true;
      result = result && getId()
          .equals(other.getId());
      result = result && getFolderId()
          .equals(other.getFolderId());
      result = result && (hasCreatedAt() == other.hasCreatedAt());
      if (hasCreatedAt()) {
        result = result && getCreatedAt()
            .equals(other.getCreatedAt());
      }
      result = result && getName()
          .equals(other.getName());
      result = result && getDescription()
          .equals(other.getDescription());
      result = result && internalGetLabels().equals(
          other.internalGetLabels());
      result = result && environment_ == other.environment_;
      result = result && getMonitoringList()
          .equals(other.getMonitoringList());
      result = result && (hasConfig() == other.hasConfig());
      if (hasConfig()) {
        result = result && getConfig()
            .equals(other.getConfig());
      }
      result = result && getNetworkId()
          .equals(other.getNetworkId());
      result = result && health_ == other.health_;
      result = result && status_ == other.status_;
      result = result && getSecurityGroupIdsList()
          .equals(other.getSecurityGroupIdsList());
      result = result && getHostGroupIdsList()
          .equals(other.getHostGroupIdsList());
      result = result && (getDeletionProtection()
          == other.getDeletionProtection());
      result = result && (hasMaintenanceWindow() == other.hasMaintenanceWindow());
      if (hasMaintenanceWindow()) {
        result = result && getMaintenanceWindow()
            .equals(other.getMaintenanceWindow());
      }
      result = result && (hasPlannedOperation() == other.hasPlannedOperation());
      if (hasPlannedOperation()) {
        result = result && getPlannedOperation()
            .equals(other.getPlannedOperation());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + ID_FIELD_NUMBER;
      hash = (53 * hash) + getId().hashCode();
      hash = (37 * hash) + FOLDER_ID_FIELD_NUMBER;
      hash = (53 * hash) + getFolderId().hashCode();
      if (hasCreatedAt()) {
        hash = (37 * hash) + CREATED_AT_FIELD_NUMBER;
        hash = (53 * hash) + getCreatedAt().hashCode();
      }
      hash = (37 * hash) + NAME_FIELD_NUMBER;
      hash = (53 * hash) + getName().hashCode();
      hash = (37 * hash) + DESCRIPTION_FIELD_NUMBER;
      hash = (53 * hash) + getDescription().hashCode();
      if (!internalGetLabels().getMap().isEmpty()) {
        hash = (37 * hash) + LABELS_FIELD_NUMBER;
        hash = (53 * hash) + internalGetLabels().hashCode();
      }
      hash = (37 * hash) + ENVIRONMENT_FIELD_NUMBER;
      hash = (53 * hash) + environment_;
      if (getMonitoringCount() > 0) {
        hash = (37 * hash) + MONITORING_FIELD_NUMBER;
        hash = (53 * hash) + getMonitoringList().hashCode();
      }
      if (hasConfig()) {
        hash = (37 * hash) + CONFIG_FIELD_NUMBER;
        hash = (53 * hash) + getConfig().hashCode();
      }
      hash = (37 * hash) + NETWORK_ID_FIELD_NUMBER;
      hash = (53 * hash) + getNetworkId().hashCode();
      hash = (37 * hash) + HEALTH_FIELD_NUMBER;
      hash = (53 * hash) + health_;
      hash = (37 * hash) + STATUS_FIELD_NUMBER;
      hash = (53 * hash) + status_;
      if (getSecurityGroupIdsCount() > 0) {
        hash = (37 * hash) + SECURITY_GROUP_IDS_FIELD_NUMBER;
        hash = (53 * hash) + getSecurityGroupIdsList().hashCode();
      }
      if (getHostGroupIdsCount() > 0) {
        hash = (37 * hash) + HOST_GROUP_IDS_FIELD_NUMBER;
        hash = (53 * hash) + getHostGroupIdsList().hashCode();
      }
      hash = (37 * hash) + DELETION_PROTECTION_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getDeletionProtection());
      if (hasMaintenanceWindow()) {
        hash = (37 * hash) + MAINTENANCE_WINDOW_FIELD_NUMBER;
        hash = (53 * hash) + getMaintenanceWindow().hashCode();
      }
      if (hasPlannedOperation()) {
        hash = (37 * hash) + PLANNED_OPERATION_FIELD_NUMBER;
        hash = (53 * hash) + getPlannedOperation().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * An Apache Kafka® cluster resource.
     * For more information, see the [Concepts](/docs/managed-kafka/concepts) section of the documentation.
     * </pre>
     *
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.Cluster}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.Cluster)
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ClusterOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Cluster_descriptor;
      }

      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMapField(
          int number) {
        switch (number) {
          case 6:
            return internalGetLabels();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMutableMapField(
          int number) {
        switch (number) {
          case 6:
            return internalGetMutableLabels();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Cluster_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Builder.class);
      }

      // Construct using yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getMonitoringFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        id_ = "";

        folderId_ = "";

        if (createdAtBuilder_ == null) {
          createdAt_ = null;
        } else {
          createdAt_ = null;
          createdAtBuilder_ = null;
        }
        name_ = "";

        description_ = "";

        internalGetMutableLabels().clear();
        environment_ = 0;

        if (monitoringBuilder_ == null) {
          monitoring_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000080);
        } else {
          monitoringBuilder_.clear();
        }
        if (configBuilder_ == null) {
          config_ = null;
        } else {
          config_ = null;
          configBuilder_ = null;
        }
        networkId_ = "";

        health_ = 0;

        status_ = 0;

        securityGroupIds_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00001000);
        hostGroupIds_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00002000);
        deletionProtection_ = false;

        if (maintenanceWindowBuilder_ == null) {
          maintenanceWindow_ = null;
        } else {
          maintenanceWindow_ = null;
          maintenanceWindowBuilder_ = null;
        }
        if (plannedOperationBuilder_ == null) {
          plannedOperation_ = null;
        } else {
          plannedOperation_ = null;
          plannedOperationBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Cluster_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster getDefaultInstanceForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster build() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster buildPartial() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster result = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        result.id_ = id_;
        result.folderId_ = folderId_;
        if (createdAtBuilder_ == null) {
          result.createdAt_ = createdAt_;
        } else {
          result.createdAt_ = createdAtBuilder_.build();
        }
        result.name_ = name_;
        result.description_ = description_;
        result.labels_ = internalGetLabels();
        result.labels_.makeImmutable();
        result.environment_ = environment_;
        if (monitoringBuilder_ == null) {
          if (((bitField0_ & 0x00000080) == 0x00000080)) {
            monitoring_ = java.util.Collections.unmodifiableList(monitoring_);
            bitField0_ = (bitField0_ & ~0x00000080);
          }
          result.monitoring_ = monitoring_;
        } else {
          result.monitoring_ = monitoringBuilder_.build();
        }
        if (configBuilder_ == null) {
          result.config_ = config_;
        } else {
          result.config_ = configBuilder_.build();
        }
        result.networkId_ = networkId_;
        result.health_ = health_;
        result.status_ = status_;
        if (((bitField0_ & 0x00001000) == 0x00001000)) {
          securityGroupIds_ = securityGroupIds_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00001000);
        }
        result.securityGroupIds_ = securityGroupIds_;
        if (((bitField0_ & 0x00002000) == 0x00002000)) {
          hostGroupIds_ = hostGroupIds_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00002000);
        }
        result.hostGroupIds_ = hostGroupIds_;
        result.deletionProtection_ = deletionProtection_;
        if (maintenanceWindowBuilder_ == null) {
          result.maintenanceWindow_ = maintenanceWindow_;
        } else {
          result.maintenanceWindow_ = maintenanceWindowBuilder_.build();
        }
        if (plannedOperationBuilder_ == null) {
          result.plannedOperation_ = plannedOperation_;
        } else {
          result.plannedOperation_ = plannedOperationBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster) {
          return mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster other) {
        if (other == yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.getDefaultInstance()) return this;
        if (!other.getId().isEmpty()) {
          id_ = other.id_;
          onChanged();
        }
        if (!other.getFolderId().isEmpty()) {
          folderId_ = other.folderId_;
          onChanged();
        }
        if (other.hasCreatedAt()) {
          mergeCreatedAt(other.getCreatedAt());
        }
        if (!other.getName().isEmpty()) {
          name_ = other.name_;
          onChanged();
        }
        if (!other.getDescription().isEmpty()) {
          description_ = other.description_;
          onChanged();
        }
        internalGetMutableLabels().mergeFrom(
            other.internalGetLabels());
        if (other.environment_ != 0) {
          setEnvironmentValue(other.getEnvironmentValue());
        }
        if (monitoringBuilder_ == null) {
          if (!other.monitoring_.isEmpty()) {
            if (monitoring_.isEmpty()) {
              monitoring_ = other.monitoring_;
              bitField0_ = (bitField0_ & ~0x00000080);
            } else {
              ensureMonitoringIsMutable();
              monitoring_.addAll(other.monitoring_);
            }
            onChanged();
          }
        } else {
          if (!other.monitoring_.isEmpty()) {
            if (monitoringBuilder_.isEmpty()) {
              monitoringBuilder_.dispose();
              monitoringBuilder_ = null;
              monitoring_ = other.monitoring_;
              bitField0_ = (bitField0_ & ~0x00000080);
              monitoringBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getMonitoringFieldBuilder() : null;
            } else {
              monitoringBuilder_.addAllMessages(other.monitoring_);
            }
          }
        }
        if (other.hasConfig()) {
          mergeConfig(other.getConfig());
        }
        if (!other.getNetworkId().isEmpty()) {
          networkId_ = other.networkId_;
          onChanged();
        }
        if (other.health_ != 0) {
          setHealthValue(other.getHealthValue());
        }
        if (other.status_ != 0) {
          setStatusValue(other.getStatusValue());
        }
        if (!other.securityGroupIds_.isEmpty()) {
          if (securityGroupIds_.isEmpty()) {
            securityGroupIds_ = other.securityGroupIds_;
            bitField0_ = (bitField0_ & ~0x00001000);
          } else {
            ensureSecurityGroupIdsIsMutable();
            securityGroupIds_.addAll(other.securityGroupIds_);
          }
          onChanged();
        }
        if (!other.hostGroupIds_.isEmpty()) {
          if (hostGroupIds_.isEmpty()) {
            hostGroupIds_ = other.hostGroupIds_;
            bitField0_ = (bitField0_ & ~0x00002000);
          } else {
            ensureHostGroupIdsIsMutable();
            hostGroupIds_.addAll(other.hostGroupIds_);
          }
          onChanged();
        }
        if (other.getDeletionProtection() != false) {
          setDeletionProtection(other.getDeletionProtection());
        }
        if (other.hasMaintenanceWindow()) {
          mergeMaintenanceWindow(other.getMaintenanceWindow());
        }
        if (other.hasPlannedOperation()) {
          mergePlannedOperation(other.getPlannedOperation());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object id_ = "";
      /**
       * <pre>
       * ID of the Apache Kafka® cluster.
       * This ID is assigned at creation time.
       * </pre>
       *
       * <code>string id = 1;</code>
       */
      public java.lang.String getId() {
        java.lang.Object ref = id_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          id_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of the Apache Kafka® cluster.
       * This ID is assigned at creation time.
       * </pre>
       *
       * <code>string id = 1;</code>
       */
      public com.google.protobuf.ByteString
          getIdBytes() {
        java.lang.Object ref = id_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          id_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of the Apache Kafka® cluster.
       * This ID is assigned at creation time.
       * </pre>
       *
       * <code>string id = 1;</code>
       */
      public Builder setId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        id_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the Apache Kafka® cluster.
       * This ID is assigned at creation time.
       * </pre>
       *
       * <code>string id = 1;</code>
       */
      public Builder clearId() {
        
        id_ = getDefaultInstance().getId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the Apache Kafka® cluster.
       * This ID is assigned at creation time.
       * </pre>
       *
       * <code>string id = 1;</code>
       */
      public Builder setIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        id_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object folderId_ = "";
      /**
       * <pre>
       * ID of the folder that the Apache Kafka® cluster belongs to.
       * </pre>
       *
       * <code>string folder_id = 2;</code>
       */
      public java.lang.String getFolderId() {
        java.lang.Object ref = folderId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          folderId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of the folder that the Apache Kafka® cluster belongs to.
       * </pre>
       *
       * <code>string folder_id = 2;</code>
       */
      public com.google.protobuf.ByteString
          getFolderIdBytes() {
        java.lang.Object ref = folderId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          folderId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of the folder that the Apache Kafka® cluster belongs to.
       * </pre>
       *
       * <code>string folder_id = 2;</code>
       */
      public Builder setFolderId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        folderId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the folder that the Apache Kafka® cluster belongs to.
       * </pre>
       *
       * <code>string folder_id = 2;</code>
       */
      public Builder clearFolderId() {
        
        folderId_ = getDefaultInstance().getFolderId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the folder that the Apache Kafka® cluster belongs to.
       * </pre>
       *
       * <code>string folder_id = 2;</code>
       */
      public Builder setFolderIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        folderId_ = value;
        onChanged();
        return this;
      }

      private com.google.protobuf.Timestamp createdAt_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Timestamp, com.google.protobuf.Timestamp.Builder, com.google.protobuf.TimestampOrBuilder> createdAtBuilder_;
      /**
       * <pre>
       * Creation timestamp.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       */
      public boolean hasCreatedAt() {
        return createdAtBuilder_ != null || createdAt_ != null;
      }
      /**
       * <pre>
       * Creation timestamp.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       */
      public com.google.protobuf.Timestamp getCreatedAt() {
        if (createdAtBuilder_ == null) {
          return createdAt_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : createdAt_;
        } else {
          return createdAtBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Creation timestamp.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       */
      public Builder setCreatedAt(com.google.protobuf.Timestamp value) {
        if (createdAtBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          createdAt_ = value;
          onChanged();
        } else {
          createdAtBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Creation timestamp.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       */
      public Builder setCreatedAt(
          com.google.protobuf.Timestamp.Builder builderForValue) {
        if (createdAtBuilder_ == null) {
          createdAt_ = builderForValue.build();
          onChanged();
        } else {
          createdAtBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Creation timestamp.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       */
      public Builder mergeCreatedAt(com.google.protobuf.Timestamp value) {
        if (createdAtBuilder_ == null) {
          if (createdAt_ != null) {
            createdAt_ =
              com.google.protobuf.Timestamp.newBuilder(createdAt_).mergeFrom(value).buildPartial();
          } else {
            createdAt_ = value;
          }
          onChanged();
        } else {
          createdAtBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Creation timestamp.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       */
      public Builder clearCreatedAt() {
        if (createdAtBuilder_ == null) {
          createdAt_ = null;
          onChanged();
        } else {
          createdAt_ = null;
          createdAtBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Creation timestamp.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       */
      public com.google.protobuf.Timestamp.Builder getCreatedAtBuilder() {
        
        onChanged();
        return getCreatedAtFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Creation timestamp.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       */
      public com.google.protobuf.TimestampOrBuilder getCreatedAtOrBuilder() {
        if (createdAtBuilder_ != null) {
          return createdAtBuilder_.getMessageOrBuilder();
        } else {
          return createdAt_ == null ?
              com.google.protobuf.Timestamp.getDefaultInstance() : createdAt_;
        }
      }
      /**
       * <pre>
       * Creation timestamp.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Timestamp, com.google.protobuf.Timestamp.Builder, com.google.protobuf.TimestampOrBuilder> 
          getCreatedAtFieldBuilder() {
        if (createdAtBuilder_ == null) {
          createdAtBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Timestamp, com.google.protobuf.Timestamp.Builder, com.google.protobuf.TimestampOrBuilder>(
                  getCreatedAt(),
                  getParentForChildren(),
                  isClean());
          createdAt_ = null;
        }
        return createdAtBuilder_;
      }

      private java.lang.Object name_ = "";
      /**
       * <pre>
       * Name of the Apache Kafka® cluster.
       * The name must be unique within the folder. 1-63 characters long. Value must match the regular expression `[a-zA-Z0-9_-]*`.
       * </pre>
       *
       * <code>string name = 4;</code>
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Name of the Apache Kafka® cluster.
       * The name must be unique within the folder. 1-63 characters long. Value must match the regular expression `[a-zA-Z0-9_-]*`.
       * </pre>
       *
       * <code>string name = 4;</code>
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Name of the Apache Kafka® cluster.
       * The name must be unique within the folder. 1-63 characters long. Value must match the regular expression `[a-zA-Z0-9_-]*`.
       * </pre>
       *
       * <code>string name = 4;</code>
       */
      public Builder setName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Name of the Apache Kafka® cluster.
       * The name must be unique within the folder. 1-63 characters long. Value must match the regular expression `[a-zA-Z0-9_-]*`.
       * </pre>
       *
       * <code>string name = 4;</code>
       */
      public Builder clearName() {
        
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Name of the Apache Kafka® cluster.
       * The name must be unique within the folder. 1-63 characters long. Value must match the regular expression `[a-zA-Z0-9_-]*`.
       * </pre>
       *
       * <code>string name = 4;</code>
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        name_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object description_ = "";
      /**
       * <pre>
       * Description of the Apache Kafka® cluster. 0-256 characters long.
       * </pre>
       *
       * <code>string description = 5;</code>
       */
      public java.lang.String getDescription() {
        java.lang.Object ref = description_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          description_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Description of the Apache Kafka® cluster. 0-256 characters long.
       * </pre>
       *
       * <code>string description = 5;</code>
       */
      public com.google.protobuf.ByteString
          getDescriptionBytes() {
        java.lang.Object ref = description_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          description_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Description of the Apache Kafka® cluster. 0-256 characters long.
       * </pre>
       *
       * <code>string description = 5;</code>
       */
      public Builder setDescription(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        description_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Description of the Apache Kafka® cluster. 0-256 characters long.
       * </pre>
       *
       * <code>string description = 5;</code>
       */
      public Builder clearDescription() {
        
        description_ = getDefaultInstance().getDescription();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Description of the Apache Kafka® cluster. 0-256 characters long.
       * </pre>
       *
       * <code>string description = 5;</code>
       */
      public Builder setDescriptionBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        description_ = value;
        onChanged();
        return this;
      }

      private com.google.protobuf.MapField<
          java.lang.String, java.lang.String> labels_;
      private com.google.protobuf.MapField<java.lang.String, java.lang.String>
      internalGetLabels() {
        if (labels_ == null) {
          return com.google.protobuf.MapField.emptyMapField(
              LabelsDefaultEntryHolder.defaultEntry);
        }
        return labels_;
      }
      private com.google.protobuf.MapField<java.lang.String, java.lang.String>
      internalGetMutableLabels() {
        onChanged();;
        if (labels_ == null) {
          labels_ = com.google.protobuf.MapField.newMapField(
              LabelsDefaultEntryHolder.defaultEntry);
        }
        if (!labels_.isMutable()) {
          labels_ = labels_.copy();
        }
        return labels_;
      }

      public int getLabelsCount() {
        return internalGetLabels().getMap().size();
      }
      /**
       * <pre>
       * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
       * A maximum of 64 labels per resource is allowed.
       * </pre>
       *
       * <code>map&lt;string, string&gt; labels = 6;</code>
       */

      public boolean containsLabels(
          java.lang.String key) {
        if (key == null) { throw new java.lang.NullPointerException(); }
        return internalGetLabels().getMap().containsKey(key);
      }
      /**
       * Use {@link #getLabelsMap()} instead.
       */
      @java.lang.Deprecated
      public java.util.Map<java.lang.String, java.lang.String> getLabels() {
        return getLabelsMap();
      }
      /**
       * <pre>
       * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
       * A maximum of 64 labels per resource is allowed.
       * </pre>
       *
       * <code>map&lt;string, string&gt; labels = 6;</code>
       */

      public java.util.Map<java.lang.String, java.lang.String> getLabelsMap() {
        return internalGetLabels().getMap();
      }
      /**
       * <pre>
       * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
       * A maximum of 64 labels per resource is allowed.
       * </pre>
       *
       * <code>map&lt;string, string&gt; labels = 6;</code>
       */

      public java.lang.String getLabelsOrDefault(
          java.lang.String key,
          java.lang.String defaultValue) {
        if (key == null) { throw new java.lang.NullPointerException(); }
        java.util.Map<java.lang.String, java.lang.String> map =
            internalGetLabels().getMap();
        return map.containsKey(key) ? map.get(key) : defaultValue;
      }
      /**
       * <pre>
       * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
       * A maximum of 64 labels per resource is allowed.
       * </pre>
       *
       * <code>map&lt;string, string&gt; labels = 6;</code>
       */

      public java.lang.String getLabelsOrThrow(
          java.lang.String key) {
        if (key == null) { throw new java.lang.NullPointerException(); }
        java.util.Map<java.lang.String, java.lang.String> map =
            internalGetLabels().getMap();
        if (!map.containsKey(key)) {
          throw new java.lang.IllegalArgumentException();
        }
        return map.get(key);
      }

      public Builder clearLabels() {
        internalGetMutableLabels().getMutableMap()
            .clear();
        return this;
      }
      /**
       * <pre>
       * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
       * A maximum of 64 labels per resource is allowed.
       * </pre>
       *
       * <code>map&lt;string, string&gt; labels = 6;</code>
       */

      public Builder removeLabels(
          java.lang.String key) {
        if (key == null) { throw new java.lang.NullPointerException(); }
        internalGetMutableLabels().getMutableMap()
            .remove(key);
        return this;
      }
      /**
       * Use alternate mutation accessors instead.
       */
      @java.lang.Deprecated
      public java.util.Map<java.lang.String, java.lang.String>
      getMutableLabels() {
        return internalGetMutableLabels().getMutableMap();
      }
      /**
       * <pre>
       * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
       * A maximum of 64 labels per resource is allowed.
       * </pre>
       *
       * <code>map&lt;string, string&gt; labels = 6;</code>
       */
      public Builder putLabels(
          java.lang.String key,
          java.lang.String value) {
        if (key == null) { throw new java.lang.NullPointerException(); }
        if (value == null) { throw new java.lang.NullPointerException(); }
        internalGetMutableLabels().getMutableMap()
            .put(key, value);
        return this;
      }
      /**
       * <pre>
       * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
       * A maximum of 64 labels per resource is allowed.
       * </pre>
       *
       * <code>map&lt;string, string&gt; labels = 6;</code>
       */

      public Builder putAllLabels(
          java.util.Map<java.lang.String, java.lang.String> values) {
        internalGetMutableLabels().getMutableMap()
            .putAll(values);
        return this;
      }

      private int environment_ = 0;
      /**
       * <pre>
       * Deployment environment of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Environment environment = 7;</code>
       */
      public int getEnvironmentValue() {
        return environment_;
      }
      /**
       * <pre>
       * Deployment environment of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Environment environment = 7;</code>
       */
      public Builder setEnvironmentValue(int value) {
        environment_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Deployment environment of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Environment environment = 7;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Environment getEnvironment() {
        @SuppressWarnings("deprecation")
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Environment result = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Environment.valueOf(environment_);
        return result == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Environment.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       * Deployment environment of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Environment environment = 7;</code>
       */
      public Builder setEnvironment(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Environment value) {
        if (value == null) {
          throw new NullPointerException();
        }
        
        environment_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Deployment environment of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Environment environment = 7;</code>
       */
      public Builder clearEnvironment() {
        
        environment_ = 0;
        onChanged();
        return this;
      }

      private java.util.List<yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring> monitoring_ =
        java.util.Collections.emptyList();
      private void ensureMonitoringIsMutable() {
        if (!((bitField0_ & 0x00000080) == 0x00000080)) {
          monitoring_ = new java.util.ArrayList<yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring>(monitoring_);
          bitField0_ |= 0x00000080;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.MonitoringOrBuilder> monitoringBuilder_;

      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public java.util.List<yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring> getMonitoringList() {
        if (monitoringBuilder_ == null) {
          return java.util.Collections.unmodifiableList(monitoring_);
        } else {
          return monitoringBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public int getMonitoringCount() {
        if (monitoringBuilder_ == null) {
          return monitoring_.size();
        } else {
          return monitoringBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring getMonitoring(int index) {
        if (monitoringBuilder_ == null) {
          return monitoring_.get(index);
        } else {
          return monitoringBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public Builder setMonitoring(
          int index, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring value) {
        if (monitoringBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureMonitoringIsMutable();
          monitoring_.set(index, value);
          onChanged();
        } else {
          monitoringBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public Builder setMonitoring(
          int index, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.Builder builderForValue) {
        if (monitoringBuilder_ == null) {
          ensureMonitoringIsMutable();
          monitoring_.set(index, builderForValue.build());
          onChanged();
        } else {
          monitoringBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public Builder addMonitoring(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring value) {
        if (monitoringBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureMonitoringIsMutable();
          monitoring_.add(value);
          onChanged();
        } else {
          monitoringBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public Builder addMonitoring(
          int index, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring value) {
        if (monitoringBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureMonitoringIsMutable();
          monitoring_.add(index, value);
          onChanged();
        } else {
          monitoringBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public Builder addMonitoring(
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.Builder builderForValue) {
        if (monitoringBuilder_ == null) {
          ensureMonitoringIsMutable();
          monitoring_.add(builderForValue.build());
          onChanged();
        } else {
          monitoringBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public Builder addMonitoring(
          int index, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.Builder builderForValue) {
        if (monitoringBuilder_ == null) {
          ensureMonitoringIsMutable();
          monitoring_.add(index, builderForValue.build());
          onChanged();
        } else {
          monitoringBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public Builder addAllMonitoring(
          java.lang.Iterable<? extends yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring> values) {
        if (monitoringBuilder_ == null) {
          ensureMonitoringIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, monitoring_);
          onChanged();
        } else {
          monitoringBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public Builder clearMonitoring() {
        if (monitoringBuilder_ == null) {
          monitoring_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000080);
          onChanged();
        } else {
          monitoringBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public Builder removeMonitoring(int index) {
        if (monitoringBuilder_ == null) {
          ensureMonitoringIsMutable();
          monitoring_.remove(index);
          onChanged();
        } else {
          monitoringBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.Builder getMonitoringBuilder(
          int index) {
        return getMonitoringFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.MonitoringOrBuilder getMonitoringOrBuilder(
          int index) {
        if (monitoringBuilder_ == null) {
          return monitoring_.get(index);  } else {
          return monitoringBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public java.util.List<? extends yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.MonitoringOrBuilder> 
           getMonitoringOrBuilderList() {
        if (monitoringBuilder_ != null) {
          return monitoringBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(monitoring_);
        }
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.Builder addMonitoringBuilder() {
        return getMonitoringFieldBuilder().addBuilder(
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.getDefaultInstance());
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.Builder addMonitoringBuilder(
          int index) {
        return getMonitoringFieldBuilder().addBuilder(
            index, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.getDefaultInstance());
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public java.util.List<yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.Builder> 
           getMonitoringBuilderList() {
        return getMonitoringFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.MonitoringOrBuilder> 
          getMonitoringFieldBuilder() {
        if (monitoringBuilder_ == null) {
          monitoringBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.MonitoringOrBuilder>(
                  monitoring_,
                  ((bitField0_ & 0x00000080) == 0x00000080),
                  getParentForChildren(),
                  isClean());
          monitoring_ = null;
        }
        return monitoringBuilder_;
      }

      private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec config_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpecOrBuilder> configBuilder_;
      /**
       * <pre>
       * Configuration of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
       */
      public boolean hasConfig() {
        return configBuilder_ != null || config_ != null;
      }
      /**
       * <pre>
       * Configuration of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec getConfig() {
        if (configBuilder_ == null) {
          return config_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.getDefaultInstance() : config_;
        } else {
          return configBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Configuration of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
       */
      public Builder setConfig(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec value) {
        if (configBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          config_ = value;
          onChanged();
        } else {
          configBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Configuration of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
       */
      public Builder setConfig(
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Builder builderForValue) {
        if (configBuilder_ == null) {
          config_ = builderForValue.build();
          onChanged();
        } else {
          configBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Configuration of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
       */
      public Builder mergeConfig(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec value) {
        if (configBuilder_ == null) {
          if (config_ != null) {
            config_ =
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.newBuilder(config_).mergeFrom(value).buildPartial();
          } else {
            config_ = value;
          }
          onChanged();
        } else {
          configBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Configuration of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
       */
      public Builder clearConfig() {
        if (configBuilder_ == null) {
          config_ = null;
          onChanged();
        } else {
          config_ = null;
          configBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Configuration of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Builder getConfigBuilder() {
        
        onChanged();
        return getConfigFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Configuration of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpecOrBuilder getConfigOrBuilder() {
        if (configBuilder_ != null) {
          return configBuilder_.getMessageOrBuilder();
        } else {
          return config_ == null ?
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.getDefaultInstance() : config_;
        }
      }
      /**
       * <pre>
       * Configuration of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpecOrBuilder> 
          getConfigFieldBuilder() {
        if (configBuilder_ == null) {
          configBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpecOrBuilder>(
                  getConfig(),
                  getParentForChildren(),
                  isClean());
          config_ = null;
        }
        return configBuilder_;
      }

      private java.lang.Object networkId_ = "";
      /**
       * <pre>
       * ID of the network that the cluster belongs to.
       * </pre>
       *
       * <code>string network_id = 10;</code>
       */
      public java.lang.String getNetworkId() {
        java.lang.Object ref = networkId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          networkId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of the network that the cluster belongs to.
       * </pre>
       *
       * <code>string network_id = 10;</code>
       */
      public com.google.protobuf.ByteString
          getNetworkIdBytes() {
        java.lang.Object ref = networkId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          networkId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of the network that the cluster belongs to.
       * </pre>
       *
       * <code>string network_id = 10;</code>
       */
      public Builder setNetworkId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        networkId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the network that the cluster belongs to.
       * </pre>
       *
       * <code>string network_id = 10;</code>
       */
      public Builder clearNetworkId() {
        
        networkId_ = getDefaultInstance().getNetworkId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the network that the cluster belongs to.
       * </pre>
       *
       * <code>string network_id = 10;</code>
       */
      public Builder setNetworkIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        networkId_ = value;
        onChanged();
        return this;
      }

      private int health_ = 0;
      /**
       * <pre>
       * Aggregated cluster health.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Health health = 11;</code>
       */
      public int getHealthValue() {
        return health_;
      }
      /**
       * <pre>
       * Aggregated cluster health.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Health health = 11;</code>
       */
      public Builder setHealthValue(int value) {
        health_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Aggregated cluster health.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Health health = 11;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Health getHealth() {
        @SuppressWarnings("deprecation")
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Health result = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Health.valueOf(health_);
        return result == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Health.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       * Aggregated cluster health.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Health health = 11;</code>
       */
      public Builder setHealth(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Health value) {
        if (value == null) {
          throw new NullPointerException();
        }
        
        health_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Aggregated cluster health.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Health health = 11;</code>
       */
      public Builder clearHealth() {
        
        health_ = 0;
        onChanged();
        return this;
      }

      private int status_ = 0;
      /**
       * <pre>
       * Current state of the cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Status status = 12;</code>
       */
      public int getStatusValue() {
        return status_;
      }
      /**
       * <pre>
       * Current state of the cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Status status = 12;</code>
       */
      public Builder setStatusValue(int value) {
        status_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Current state of the cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Status status = 12;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Status getStatus() {
        @SuppressWarnings("deprecation")
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Status result = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Status.valueOf(status_);
        return result == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Status.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       * Current state of the cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Status status = 12;</code>
       */
      public Builder setStatus(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Status value) {
        if (value == null) {
          throw new NullPointerException();
        }
        
        status_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Current state of the cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Status status = 12;</code>
       */
      public Builder clearStatus() {
        
        status_ = 0;
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList securityGroupIds_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureSecurityGroupIdsIsMutable() {
        if (!((bitField0_ & 0x00001000) == 0x00001000)) {
          securityGroupIds_ = new com.google.protobuf.LazyStringArrayList(securityGroupIds_);
          bitField0_ |= 0x00001000;
         }
      }
      /**
       * <pre>
       * User security groups
       * </pre>
       *
       * <code>repeated string security_group_ids = 13;</code>
       */
      public com.google.protobuf.ProtocolStringList
          getSecurityGroupIdsList() {
        return securityGroupIds_.getUnmodifiableView();
      }
      /**
       * <pre>
       * User security groups
       * </pre>
       *
       * <code>repeated string security_group_ids = 13;</code>
       */
      public int getSecurityGroupIdsCount() {
        return securityGroupIds_.size();
      }
      /**
       * <pre>
       * User security groups
       * </pre>
       *
       * <code>repeated string security_group_ids = 13;</code>
       */
      public java.lang.String getSecurityGroupIds(int index) {
        return securityGroupIds_.get(index);
      }
      /**
       * <pre>
       * User security groups
       * </pre>
       *
       * <code>repeated string security_group_ids = 13;</code>
       */
      public com.google.protobuf.ByteString
          getSecurityGroupIdsBytes(int index) {
        return securityGroupIds_.getByteString(index);
      }
      /**
       * <pre>
       * User security groups
       * </pre>
       *
       * <code>repeated string security_group_ids = 13;</code>
       */
      public Builder setSecurityGroupIds(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureSecurityGroupIdsIsMutable();
        securityGroupIds_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * User security groups
       * </pre>
       *
       * <code>repeated string security_group_ids = 13;</code>
       */
      public Builder addSecurityGroupIds(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureSecurityGroupIdsIsMutable();
        securityGroupIds_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * User security groups
       * </pre>
       *
       * <code>repeated string security_group_ids = 13;</code>
       */
      public Builder addAllSecurityGroupIds(
          java.lang.Iterable<java.lang.String> values) {
        ensureSecurityGroupIdsIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, securityGroupIds_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * User security groups
       * </pre>
       *
       * <code>repeated string security_group_ids = 13;</code>
       */
      public Builder clearSecurityGroupIds() {
        securityGroupIds_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00001000);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * User security groups
       * </pre>
       *
       * <code>repeated string security_group_ids = 13;</code>
       */
      public Builder addSecurityGroupIdsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensureSecurityGroupIdsIsMutable();
        securityGroupIds_.add(value);
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList hostGroupIds_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureHostGroupIdsIsMutable() {
        if (!((bitField0_ & 0x00002000) == 0x00002000)) {
          hostGroupIds_ = new com.google.protobuf.LazyStringArrayList(hostGroupIds_);
          bitField0_ |= 0x00002000;
         }
      }
      /**
       * <pre>
       * Host groups hosting VMs of the cluster.
       * </pre>
       *
       * <code>repeated string host_group_ids = 14;</code>
       */
      public com.google.protobuf.ProtocolStringList
          getHostGroupIdsList() {
        return hostGroupIds_.getUnmodifiableView();
      }
      /**
       * <pre>
       * Host groups hosting VMs of the cluster.
       * </pre>
       *
       * <code>repeated string host_group_ids = 14;</code>
       */
      public int getHostGroupIdsCount() {
        return hostGroupIds_.size();
      }
      /**
       * <pre>
       * Host groups hosting VMs of the cluster.
       * </pre>
       *
       * <code>repeated string host_group_ids = 14;</code>
       */
      public java.lang.String getHostGroupIds(int index) {
        return hostGroupIds_.get(index);
      }
      /**
       * <pre>
       * Host groups hosting VMs of the cluster.
       * </pre>
       *
       * <code>repeated string host_group_ids = 14;</code>
       */
      public com.google.protobuf.ByteString
          getHostGroupIdsBytes(int index) {
        return hostGroupIds_.getByteString(index);
      }
      /**
       * <pre>
       * Host groups hosting VMs of the cluster.
       * </pre>
       *
       * <code>repeated string host_group_ids = 14;</code>
       */
      public Builder setHostGroupIds(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureHostGroupIdsIsMutable();
        hostGroupIds_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Host groups hosting VMs of the cluster.
       * </pre>
       *
       * <code>repeated string host_group_ids = 14;</code>
       */
      public Builder addHostGroupIds(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureHostGroupIdsIsMutable();
        hostGroupIds_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Host groups hosting VMs of the cluster.
       * </pre>
       *
       * <code>repeated string host_group_ids = 14;</code>
       */
      public Builder addAllHostGroupIds(
          java.lang.Iterable<java.lang.String> values) {
        ensureHostGroupIdsIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, hostGroupIds_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Host groups hosting VMs of the cluster.
       * </pre>
       *
       * <code>repeated string host_group_ids = 14;</code>
       */
      public Builder clearHostGroupIds() {
        hostGroupIds_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00002000);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Host groups hosting VMs of the cluster.
       * </pre>
       *
       * <code>repeated string host_group_ids = 14;</code>
       */
      public Builder addHostGroupIdsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensureHostGroupIdsIsMutable();
        hostGroupIds_.add(value);
        onChanged();
        return this;
      }

      private boolean deletionProtection_ ;
      /**
       * <pre>
       * Deletion Protection inhibits deletion of the cluster
       * </pre>
       *
       * <code>bool deletion_protection = 15;</code>
       */
      public boolean getDeletionProtection() {
        return deletionProtection_;
      }
      /**
       * <pre>
       * Deletion Protection inhibits deletion of the cluster
       * </pre>
       *
       * <code>bool deletion_protection = 15;</code>
       */
      public Builder setDeletionProtection(boolean value) {
        
        deletionProtection_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Deletion Protection inhibits deletion of the cluster
       * </pre>
       *
       * <code>bool deletion_protection = 15;</code>
       */
      public Builder clearDeletionProtection() {
        
        deletionProtection_ = false;
        onChanged();
        return this;
      }

      private yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow maintenanceWindow_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow, yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow.Builder, yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindowOrBuilder> maintenanceWindowBuilder_;
      /**
       * <pre>
       * Window of maintenance operations.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
       */
      public boolean hasMaintenanceWindow() {
        return maintenanceWindowBuilder_ != null || maintenanceWindow_ != null;
      }
      /**
       * <pre>
       * Window of maintenance operations.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow getMaintenanceWindow() {
        if (maintenanceWindowBuilder_ == null) {
          return maintenanceWindow_ == null ? yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow.getDefaultInstance() : maintenanceWindow_;
        } else {
          return maintenanceWindowBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Window of maintenance operations.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
       */
      public Builder setMaintenanceWindow(yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow value) {
        if (maintenanceWindowBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          maintenanceWindow_ = value;
          onChanged();
        } else {
          maintenanceWindowBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Window of maintenance operations.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
       */
      public Builder setMaintenanceWindow(
          yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow.Builder builderForValue) {
        if (maintenanceWindowBuilder_ == null) {
          maintenanceWindow_ = builderForValue.build();
          onChanged();
        } else {
          maintenanceWindowBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Window of maintenance operations.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
       */
      public Builder mergeMaintenanceWindow(yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow value) {
        if (maintenanceWindowBuilder_ == null) {
          if (maintenanceWindow_ != null) {
            maintenanceWindow_ =
              yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow.newBuilder(maintenanceWindow_).mergeFrom(value).buildPartial();
          } else {
            maintenanceWindow_ = value;
          }
          onChanged();
        } else {
          maintenanceWindowBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Window of maintenance operations.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
       */
      public Builder clearMaintenanceWindow() {
        if (maintenanceWindowBuilder_ == null) {
          maintenanceWindow_ = null;
          onChanged();
        } else {
          maintenanceWindow_ = null;
          maintenanceWindowBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Window of maintenance operations.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow.Builder getMaintenanceWindowBuilder() {
        
        onChanged();
        return getMaintenanceWindowFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Window of maintenance operations.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindowOrBuilder getMaintenanceWindowOrBuilder() {
        if (maintenanceWindowBuilder_ != null) {
          return maintenanceWindowBuilder_.getMessageOrBuilder();
        } else {
          return maintenanceWindow_ == null ?
              yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow.getDefaultInstance() : maintenanceWindow_;
        }
      }
      /**
       * <pre>
       * Window of maintenance operations.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow, yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow.Builder, yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindowOrBuilder> 
          getMaintenanceWindowFieldBuilder() {
        if (maintenanceWindowBuilder_ == null) {
          maintenanceWindowBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow, yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow.Builder, yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindowOrBuilder>(
                  getMaintenanceWindow(),
                  getParentForChildren(),
                  isClean());
          maintenanceWindow_ = null;
        }
        return maintenanceWindowBuilder_;
      }

      private yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation plannedOperation_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation, yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation.Builder, yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperationOrBuilder> plannedOperationBuilder_;
      /**
       * <pre>
       * Scheduled maintenance operation.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
       */
      public boolean hasPlannedOperation() {
        return plannedOperationBuilder_ != null || plannedOperation_ != null;
      }
      /**
       * <pre>
       * Scheduled maintenance operation.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation getPlannedOperation() {
        if (plannedOperationBuilder_ == null) {
          return plannedOperation_ == null ? yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation.getDefaultInstance() : plannedOperation_;
        } else {
          return plannedOperationBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Scheduled maintenance operation.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
       */
      public Builder setPlannedOperation(yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation value) {
        if (plannedOperationBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          plannedOperation_ = value;
          onChanged();
        } else {
          plannedOperationBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Scheduled maintenance operation.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
       */
      public Builder setPlannedOperation(
          yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation.Builder builderForValue) {
        if (plannedOperationBuilder_ == null) {
          plannedOperation_ = builderForValue.build();
          onChanged();
        } else {
          plannedOperationBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Scheduled maintenance operation.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
       */
      public Builder mergePlannedOperation(yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation value) {
        if (plannedOperationBuilder_ == null) {
          if (plannedOperation_ != null) {
            plannedOperation_ =
              yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation.newBuilder(plannedOperation_).mergeFrom(value).buildPartial();
          } else {
            plannedOperation_ = value;
          }
          onChanged();
        } else {
          plannedOperationBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Scheduled maintenance operation.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
       */
      public Builder clearPlannedOperation() {
        if (plannedOperationBuilder_ == null) {
          plannedOperation_ = null;
          onChanged();
        } else {
          plannedOperation_ = null;
          plannedOperationBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Scheduled maintenance operation.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation.Builder getPlannedOperationBuilder() {
        
        onChanged();
        return getPlannedOperationFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Scheduled maintenance operation.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperationOrBuilder getPlannedOperationOrBuilder() {
        if (plannedOperationBuilder_ != null) {
          return plannedOperationBuilder_.getMessageOrBuilder();
        } else {
          return plannedOperation_ == null ?
              yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation.getDefaultInstance() : plannedOperation_;
        }
      }
      /**
       * <pre>
       * Scheduled maintenance operation.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation, yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation.Builder, yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperationOrBuilder> 
          getPlannedOperationFieldBuilder() {
        if (plannedOperationBuilder_ == null) {
          plannedOperationBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation, yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation.Builder, yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperationOrBuilder>(
                  getPlannedOperation(),
                  getParentForChildren(),
                  isClean());
          plannedOperation_ = null;
        }
        return plannedOperationBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.Cluster)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.Cluster)
    private static final yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster();
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<Cluster>
        PARSER = new com.google.protobuf.AbstractParser<Cluster>() {
      @java.lang.Override
      public Cluster parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Cluster(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<Cluster> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Cluster> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface MonitoringOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.Monitoring)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Name of the monitoring system.
     * </pre>
     *
     * <code>string name = 1;</code>
     */
    java.lang.String getName();
    /**
     * <pre>
     * Name of the monitoring system.
     * </pre>
     *
     * <code>string name = 1;</code>
     */
    com.google.protobuf.ByteString
        getNameBytes();

    /**
     * <pre>
     * Description of the monitoring system.
     * </pre>
     *
     * <code>string description = 2;</code>
     */
    java.lang.String getDescription();
    /**
     * <pre>
     * Description of the monitoring system.
     * </pre>
     *
     * <code>string description = 2;</code>
     */
    com.google.protobuf.ByteString
        getDescriptionBytes();

    /**
     * <pre>
     * Link to the monitoring system charts for the Apache Kafka® cluster.
     * </pre>
     *
     * <code>string link = 3;</code>
     */
    java.lang.String getLink();
    /**
     * <pre>
     * Link to the monitoring system charts for the Apache Kafka® cluster.
     * </pre>
     *
     * <code>string link = 3;</code>
     */
    com.google.protobuf.ByteString
        getLinkBytes();
  }
  /**
   * <pre>
   * Metadata of monitoring system.
   * </pre>
   *
   * Protobuf type {@code yandex.cloud.mdb.kafka.v1.Monitoring}
   */
  public  static final class Monitoring extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.Monitoring)
      MonitoringOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Monitoring.newBuilder() to construct.
    private Monitoring(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Monitoring() {
      name_ = "";
      description_ = "";
      link_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private Monitoring(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              name_ = s;
              break;
            }
            case 18: {
              java.lang.String s = input.readStringRequireUtf8();

              description_ = s;
              break;
            }
            case 26: {
              java.lang.String s = input.readStringRequireUtf8();

              link_ = s;
              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Monitoring_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Monitoring_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.Builder.class);
    }

    public static final int NAME_FIELD_NUMBER = 1;
    private volatile java.lang.Object name_;
    /**
     * <pre>
     * Name of the monitoring system.
     * </pre>
     *
     * <code>string name = 1;</code>
     */
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        name_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Name of the monitoring system.
     * </pre>
     *
     * <code>string name = 1;</code>
     */
    public com.google.protobuf.ByteString
        getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int DESCRIPTION_FIELD_NUMBER = 2;
    private volatile java.lang.Object description_;
    /**
     * <pre>
     * Description of the monitoring system.
     * </pre>
     *
     * <code>string description = 2;</code>
     */
    public java.lang.String getDescription() {
      java.lang.Object ref = description_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        description_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Description of the monitoring system.
     * </pre>
     *
     * <code>string description = 2;</code>
     */
    public com.google.protobuf.ByteString
        getDescriptionBytes() {
      java.lang.Object ref = description_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        description_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int LINK_FIELD_NUMBER = 3;
    private volatile java.lang.Object link_;
    /**
     * <pre>
     * Link to the monitoring system charts for the Apache Kafka® cluster.
     * </pre>
     *
     * <code>string link = 3;</code>
     */
    public java.lang.String getLink() {
      java.lang.Object ref = link_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        link_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Link to the monitoring system charts for the Apache Kafka® cluster.
     * </pre>
     *
     * <code>string link = 3;</code>
     */
    public com.google.protobuf.ByteString
        getLinkBytes() {
      java.lang.Object ref = link_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        link_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!getNameBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, name_);
      }
      if (!getDescriptionBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, description_);
      }
      if (!getLinkBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, link_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!getNameBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, name_);
      }
      if (!getDescriptionBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, description_);
      }
      if (!getLinkBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, link_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring)) {
        return super.equals(obj);
      }
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring other = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring) obj;

      boolean result = true;
      result = result && getName()
          .equals(other.getName());
      result = result && getDescription()
          .equals(other.getDescription());
      result = result && getLink()
          .equals(other.getLink());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + NAME_FIELD_NUMBER;
      hash = (53 * hash) + getName().hashCode();
      hash = (37 * hash) + DESCRIPTION_FIELD_NUMBER;
      hash = (53 * hash) + getDescription().hashCode();
      hash = (37 * hash) + LINK_FIELD_NUMBER;
      hash = (53 * hash) + getLink().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Metadata of monitoring system.
     * </pre>
     *
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.Monitoring}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.Monitoring)
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.MonitoringOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Monitoring_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Monitoring_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.Builder.class);
      }

      // Construct using yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        name_ = "";

        description_ = "";

        link_ = "";

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Monitoring_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring getDefaultInstanceForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring build() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring buildPartial() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring result = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring(this);
        result.name_ = name_;
        result.description_ = description_;
        result.link_ = link_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring) {
          return mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring other) {
        if (other == yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.getDefaultInstance()) return this;
        if (!other.getName().isEmpty()) {
          name_ = other.name_;
          onChanged();
        }
        if (!other.getDescription().isEmpty()) {
          description_ = other.description_;
          onChanged();
        }
        if (!other.getLink().isEmpty()) {
          link_ = other.link_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private java.lang.Object name_ = "";
      /**
       * <pre>
       * Name of the monitoring system.
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Name of the monitoring system.
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Name of the monitoring system.
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public Builder setName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Name of the monitoring system.
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public Builder clearName() {
        
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Name of the monitoring system.
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        name_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object description_ = "";
      /**
       * <pre>
       * Description of the monitoring system.
       * </pre>
       *
       * <code>string description = 2;</code>
       */
      public java.lang.String getDescription() {
        java.lang.Object ref = description_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          description_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Description of the monitoring system.
       * </pre>
       *
       * <code>string description = 2;</code>
       */
      public com.google.protobuf.ByteString
          getDescriptionBytes() {
        java.lang.Object ref = description_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          description_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Description of the monitoring system.
       * </pre>
       *
       * <code>string description = 2;</code>
       */
      public Builder setDescription(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        description_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Description of the monitoring system.
       * </pre>
       *
       * <code>string description = 2;</code>
       */
      public Builder clearDescription() {
        
        description_ = getDefaultInstance().getDescription();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Description of the monitoring system.
       * </pre>
       *
       * <code>string description = 2;</code>
       */
      public Builder setDescriptionBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        description_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object link_ = "";
      /**
       * <pre>
       * Link to the monitoring system charts for the Apache Kafka® cluster.
       * </pre>
       *
       * <code>string link = 3;</code>
       */
      public java.lang.String getLink() {
        java.lang.Object ref = link_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          link_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Link to the monitoring system charts for the Apache Kafka® cluster.
       * </pre>
       *
       * <code>string link = 3;</code>
       */
      public com.google.protobuf.ByteString
          getLinkBytes() {
        java.lang.Object ref = link_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          link_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Link to the monitoring system charts for the Apache Kafka® cluster.
       * </pre>
       *
       * <code>string link = 3;</code>
       */
      public Builder setLink(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        link_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Link to the monitoring system charts for the Apache Kafka® cluster.
       * </pre>
       *
       * <code>string link = 3;</code>
       */
      public Builder clearLink() {
        
        link_ = getDefaultInstance().getLink();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Link to the monitoring system charts for the Apache Kafka® cluster.
       * </pre>
       *
       * <code>string link = 3;</code>
       */
      public Builder setLinkBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        link_ = value;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.Monitoring)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.Monitoring)
    private static final yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring();
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<Monitoring>
        PARSER = new com.google.protobuf.AbstractParser<Monitoring>() {
      @java.lang.Override
      public Monitoring parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Monitoring(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<Monitoring> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Monitoring> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ConfigSpecOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.ConfigSpec)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Version of Apache Kafka® used in the cluster. Possible values: `2.1`, `2.6`.
     * </pre>
     *
     * <code>string version = 1;</code>
     */
    java.lang.String getVersion();
    /**
     * <pre>
     * Version of Apache Kafka® used in the cluster. Possible values: `2.1`, `2.6`.
     * </pre>
     *
     * <code>string version = 1;</code>
     */
    com.google.protobuf.ByteString
        getVersionBytes();

    /**
     * <pre>
     * Configuration and resource allocation for Kafka brokers.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
     */
    boolean hasKafka();
    /**
     * <pre>
     * Configuration and resource allocation for Kafka brokers.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka getKafka();
    /**
     * <pre>
     * Configuration and resource allocation for Kafka brokers.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.KafkaOrBuilder getKafkaOrBuilder();

    /**
     * <pre>
     * Configuration and resource allocation for ZooKeeper hosts.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
     */
    boolean hasZookeeper();
    /**
     * <pre>
     * Configuration and resource allocation for ZooKeeper hosts.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper getZookeeper();
    /**
     * <pre>
     * Configuration and resource allocation for ZooKeeper hosts.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.ZookeeperOrBuilder getZookeeperOrBuilder();

    /**
     * <pre>
     * IDs of availability zones where Kafka brokers reside.
     * </pre>
     *
     * <code>repeated string zone_id = 4;</code>
     */
    java.util.List<java.lang.String>
        getZoneIdList();
    /**
     * <pre>
     * IDs of availability zones where Kafka brokers reside.
     * </pre>
     *
     * <code>repeated string zone_id = 4;</code>
     */
    int getZoneIdCount();
    /**
     * <pre>
     * IDs of availability zones where Kafka brokers reside.
     * </pre>
     *
     * <code>repeated string zone_id = 4;</code>
     */
    java.lang.String getZoneId(int index);
    /**
     * <pre>
     * IDs of availability zones where Kafka brokers reside.
     * </pre>
     *
     * <code>repeated string zone_id = 4;</code>
     */
    com.google.protobuf.ByteString
        getZoneIdBytes(int index);

    /**
     * <pre>
     * The number of Kafka brokers deployed in each availability zone.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
     */
    boolean hasBrokersCount();
    /**
     * <pre>
     * The number of Kafka brokers deployed in each availability zone.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
     */
    com.google.protobuf.Int64Value getBrokersCount();
    /**
     * <pre>
     * The number of Kafka brokers deployed in each availability zone.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getBrokersCountOrBuilder();

    /**
     * <pre>
     * The flag that defines whether a public IP address is assigned to the cluster.
     * If the value is `true`, then Apache Kafka® cluster is available on the Internet via it's public IP address.
     * </pre>
     *
     * <code>bool assign_public_ip = 6;</code>
     */
    boolean getAssignPublicIp();

    /**
     * <pre>
     * Allows to manage topics via AdminAPI
     * </pre>
     *
     * <code>bool unmanaged_topics = 7;</code>
     */
    boolean getUnmanagedTopics();

    /**
     * <pre>
     * Enables managed schema registry on cluster
     * </pre>
     *
     * <code>bool schema_registry = 8;</code>
     */
    boolean getSchemaRegistry();
  }
  /**
   * Protobuf type {@code yandex.cloud.mdb.kafka.v1.ConfigSpec}
   */
  public  static final class ConfigSpec extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.ConfigSpec)
      ConfigSpecOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ConfigSpec.newBuilder() to construct.
    private ConfigSpec(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ConfigSpec() {
      version_ = "";
      zoneId_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      assignPublicIp_ = false;
      unmanagedTopics_ = false;
      schemaRegistry_ = false;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ConfigSpec(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              version_ = s;
              break;
            }
            case 18: {
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.Builder subBuilder = null;
              if (kafka_ != null) {
                subBuilder = kafka_.toBuilder();
              }
              kafka_ = input.readMessage(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(kafka_);
                kafka_ = subBuilder.buildPartial();
              }

              break;
            }
            case 26: {
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.Builder subBuilder = null;
              if (zookeeper_ != null) {
                subBuilder = zookeeper_.toBuilder();
              }
              zookeeper_ = input.readMessage(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(zookeeper_);
                zookeeper_ = subBuilder.buildPartial();
              }

              break;
            }
            case 34: {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
                zoneId_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000008;
              }
              zoneId_.add(s);
              break;
            }
            case 42: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (brokersCount_ != null) {
                subBuilder = brokersCount_.toBuilder();
              }
              brokersCount_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(brokersCount_);
                brokersCount_ = subBuilder.buildPartial();
              }

              break;
            }
            case 48: {

              assignPublicIp_ = input.readBool();
              break;
            }
            case 56: {

              unmanagedTopics_ = input.readBool();
              break;
            }
            case 64: {

              schemaRegistry_ = input.readBool();
              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
          zoneId_ = zoneId_.getUnmodifiableView();
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Builder.class);
    }

    public interface KafkaOrBuilder extends
        // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <pre>
       * Resources allocated to Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
       */
      boolean hasResources();
      /**
       * <pre>
       * Resources allocated to Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
       */
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources getResources();
      /**
       * <pre>
       * Resources allocated to Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
       */
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder getResourcesOrBuilder();

      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_1 kafka_config_2_1 = 2[json_name = "kafkaConfig_2_1"];</code>
       */
      boolean hasKafkaConfig21();
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_1 kafka_config_2_1 = 2[json_name = "kafkaConfig_2_1"];</code>
       */
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 getKafkaConfig21();
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_1 kafka_config_2_1 = 2[json_name = "kafkaConfig_2_1"];</code>
       */
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1OrBuilder getKafkaConfig21OrBuilder();

      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_6 kafka_config_2_6 = 3[json_name = "kafkaConfig_2_6"];</code>
       */
      boolean hasKafkaConfig26();
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_6 kafka_config_2_6 = 3[json_name = "kafkaConfig_2_6"];</code>
       */
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 getKafkaConfig26();
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_6 kafka_config_2_6 = 3[json_name = "kafkaConfig_2_6"];</code>
       */
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6OrBuilder getKafkaConfig26OrBuilder();

      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4[json_name = "kafkaConfig_2_8"];</code>
       */
      boolean hasKafkaConfig28();
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4[json_name = "kafkaConfig_2_8"];</code>
       */
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 getKafkaConfig28();
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4[json_name = "kafkaConfig_2_8"];</code>
       */
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8OrBuilder getKafkaConfig28OrBuilder();

      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.KafkaConfigCase getKafkaConfigCase();
    }
    /**
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka}
     */
    public  static final class Kafka extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka)
        KafkaOrBuilder {
    private static final long serialVersionUID = 0L;
      // Use Kafka.newBuilder() to construct.
      private Kafka(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private Kafka() {
      }

      @java.lang.Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return this.unknownFields;
      }
      private Kafka(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        int mutable_bitField0_ = 0;
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
            com.google.protobuf.UnknownFieldSet.newBuilder();
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder subBuilder = null;
                if (resources_ != null) {
                  subBuilder = resources_.toBuilder();
                }
                resources_ = input.readMessage(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.parser(), extensionRegistry);
                if (subBuilder != null) {
                  subBuilder.mergeFrom(resources_);
                  resources_ = subBuilder.buildPartial();
                }

                break;
              }
              case 18: {
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1.Builder subBuilder = null;
                if (kafkaConfigCase_ == 2) {
                  subBuilder = ((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1) kafkaConfig_).toBuilder();
                }
                kafkaConfig_ =
                    input.readMessage(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1.parser(), extensionRegistry);
                if (subBuilder != null) {
                  subBuilder.mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1) kafkaConfig_);
                  kafkaConfig_ = subBuilder.buildPartial();
                }
                kafkaConfigCase_ = 2;
                break;
              }
              case 26: {
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6.Builder subBuilder = null;
                if (kafkaConfigCase_ == 3) {
                  subBuilder = ((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6) kafkaConfig_).toBuilder();
                }
                kafkaConfig_ =
                    input.readMessage(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6.parser(), extensionRegistry);
                if (subBuilder != null) {
                  subBuilder.mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6) kafkaConfig_);
                  kafkaConfig_ = subBuilder.buildPartial();
                }
                kafkaConfigCase_ = 3;
                break;
              }
              case 34: {
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.Builder subBuilder = null;
                if (kafkaConfigCase_ == 4) {
                  subBuilder = ((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) kafkaConfig_).toBuilder();
                }
                kafkaConfig_ =
                    input.readMessage(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.parser(), extensionRegistry);
                if (subBuilder != null) {
                  subBuilder.mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) kafkaConfig_);
                  kafkaConfig_ = subBuilder.buildPartial();
                }
                kafkaConfigCase_ = 4;
                break;
              }
              default: {
                if (!parseUnknownFieldProto3(
                    input, unknownFields, extensionRegistry, tag)) {
                  done = true;
                }
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          this.unknownFields = unknownFields.build();
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Kafka_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Kafka_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.Builder.class);
      }

      private int kafkaConfigCase_ = 0;
      private java.lang.Object kafkaConfig_;
      public enum KafkaConfigCase
          implements com.google.protobuf.Internal.EnumLite {
        KAFKA_CONFIG_2_1(2),
        KAFKA_CONFIG_2_6(3),
        KAFKA_CONFIG_2_8(4),
        KAFKACONFIG_NOT_SET(0);
        private final int value;
        private KafkaConfigCase(int value) {
          this.value = value;
        }
        /**
         * @deprecated Use {@link #forNumber(int)} instead.
         */
        @java.lang.Deprecated
        public static KafkaConfigCase valueOf(int value) {
          return forNumber(value);
        }

        public static KafkaConfigCase forNumber(int value) {
          switch (value) {
            case 2: return KAFKA_CONFIG_2_1;
            case 3: return KAFKA_CONFIG_2_6;
            case 4: return KAFKA_CONFIG_2_8;
            case 0: return KAFKACONFIG_NOT_SET;
            default: return null;
          }
        }
        public int getNumber() {
          return this.value;
        }
      };

      public KafkaConfigCase
      getKafkaConfigCase() {
        return KafkaConfigCase.forNumber(
            kafkaConfigCase_);
      }

      public static final int RESOURCES_FIELD_NUMBER = 1;
      private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources resources_;
      /**
       * <pre>
       * Resources allocated to Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
       */
      public boolean hasResources() {
        return resources_ != null;
      }
      /**
       * <pre>
       * Resources allocated to Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources getResources() {
        return resources_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.getDefaultInstance() : resources_;
      }
      /**
       * <pre>
       * Resources allocated to Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder getResourcesOrBuilder() {
        return getResources();
      }

      public static final int KAFKA_CONFIG_2_1_FIELD_NUMBER = 2;
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_1 kafka_config_2_1 = 2[json_name = "kafkaConfig_2_1"];</code>
       */
      public boolean hasKafkaConfig21() {
        return kafkaConfigCase_ == 2;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_1 kafka_config_2_1 = 2[json_name = "kafkaConfig_2_1"];</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 getKafkaConfig21() {
        if (kafkaConfigCase_ == 2) {
           return (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1) kafkaConfig_;
        }
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1.getDefaultInstance();
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_1 kafka_config_2_1 = 2[json_name = "kafkaConfig_2_1"];</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1OrBuilder getKafkaConfig21OrBuilder() {
        if (kafkaConfigCase_ == 2) {
           return (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1) kafkaConfig_;
        }
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1.getDefaultInstance();
      }

      public static final int KAFKA_CONFIG_2_6_FIELD_NUMBER = 3;
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_6 kafka_config_2_6 = 3[json_name = "kafkaConfig_2_6"];</code>
       */
      public boolean hasKafkaConfig26() {
        return kafkaConfigCase_ == 3;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_6 kafka_config_2_6 = 3[json_name = "kafkaConfig_2_6"];</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 getKafkaConfig26() {
        if (kafkaConfigCase_ == 3) {
           return (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6) kafkaConfig_;
        }
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6.getDefaultInstance();
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_6 kafka_config_2_6 = 3[json_name = "kafkaConfig_2_6"];</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6OrBuilder getKafkaConfig26OrBuilder() {
        if (kafkaConfigCase_ == 3) {
           return (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6) kafkaConfig_;
        }
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6.getDefaultInstance();
      }

      public static final int KAFKA_CONFIG_2_8_FIELD_NUMBER = 4;
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4[json_name = "kafkaConfig_2_8"];</code>
       */
      public boolean hasKafkaConfig28() {
        return kafkaConfigCase_ == 4;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4[json_name = "kafkaConfig_2_8"];</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 getKafkaConfig28() {
        if (kafkaConfigCase_ == 4) {
           return (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) kafkaConfig_;
        }
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.getDefaultInstance();
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4[json_name = "kafkaConfig_2_8"];</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8OrBuilder getKafkaConfig28OrBuilder() {
        if (kafkaConfigCase_ == 4) {
           return (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) kafkaConfig_;
        }
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.getDefaultInstance();
      }

      private byte memoizedIsInitialized = -1;
      @java.lang.Override
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      @java.lang.Override
      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (resources_ != null) {
          output.writeMessage(1, getResources());
        }
        if (kafkaConfigCase_ == 2) {
          output.writeMessage(2, (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1) kafkaConfig_);
        }
        if (kafkaConfigCase_ == 3) {
          output.writeMessage(3, (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6) kafkaConfig_);
        }
        if (kafkaConfigCase_ == 4) {
          output.writeMessage(4, (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) kafkaConfig_);
        }
        unknownFields.writeTo(output);
      }

      @java.lang.Override
      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (resources_ != null) {
          size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(1, getResources());
        }
        if (kafkaConfigCase_ == 2) {
          size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(2, (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1) kafkaConfig_);
        }
        if (kafkaConfigCase_ == 3) {
          size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(3, (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6) kafkaConfig_);
        }
        if (kafkaConfigCase_ == 4) {
          size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(4, (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) kafkaConfig_);
        }
        size += unknownFields.getSerializedSize();
        memoizedSize = size;
        return size;
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka)) {
          return super.equals(obj);
        }
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka other = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka) obj;

        boolean result = true;
        result = result && (hasResources() == other.hasResources());
        if (hasResources()) {
          result = result && getResources()
              .equals(other.getResources());
        }
        result = result && getKafkaConfigCase().equals(
            other.getKafkaConfigCase());
        if (!result) return false;
        switch (kafkaConfigCase_) {
          case 2:
            result = result && getKafkaConfig21()
                .equals(other.getKafkaConfig21());
            break;
          case 3:
            result = result && getKafkaConfig26()
                .equals(other.getKafkaConfig26());
            break;
          case 4:
            result = result && getKafkaConfig28()
                .equals(other.getKafkaConfig28());
            break;
          case 0:
          default:
        }
        result = result && unknownFields.equals(other.unknownFields);
        return result;
      }

      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptor().hashCode();
        if (hasResources()) {
          hash = (37 * hash) + RESOURCES_FIELD_NUMBER;
          hash = (53 * hash) + getResources().hashCode();
        }
        switch (kafkaConfigCase_) {
          case 2:
            hash = (37 * hash) + KAFKA_CONFIG_2_1_FIELD_NUMBER;
            hash = (53 * hash) + getKafkaConfig21().hashCode();
            break;
          case 3:
            hash = (37 * hash) + KAFKA_CONFIG_2_6_FIELD_NUMBER;
            hash = (53 * hash) + getKafkaConfig26().hashCode();
            break;
          case 4:
            hash = (37 * hash) + KAFKA_CONFIG_2_8_FIELD_NUMBER;
            hash = (53 * hash) + getKafkaConfig28().hashCode();
            break;
          case 0:
          default:
        }
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parseFrom(
          java.nio.ByteBuffer data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parseFrom(
          java.nio.ByteBuffer data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      @java.lang.Override
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      @java.lang.Override
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @java.lang.Override
      protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * Protobuf type {@code yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka)
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.KafkaOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Kafka_descriptor;
        }

        @java.lang.Override
        protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Kafka_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.Builder.class);
        }

        // Construct using yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
          }
        }
        @java.lang.Override
        public Builder clear() {
          super.clear();
          if (resourcesBuilder_ == null) {
            resources_ = null;
          } else {
            resources_ = null;
            resourcesBuilder_ = null;
          }
          kafkaConfigCase_ = 0;
          kafkaConfig_ = null;
          return this;
        }

        @java.lang.Override
        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Kafka_descriptor;
        }

        @java.lang.Override
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka getDefaultInstanceForType() {
          return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.getDefaultInstance();
        }

        @java.lang.Override
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka build() {
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        @java.lang.Override
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka buildPartial() {
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka result = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka(this);
          if (resourcesBuilder_ == null) {
            result.resources_ = resources_;
          } else {
            result.resources_ = resourcesBuilder_.build();
          }
          if (kafkaConfigCase_ == 2) {
            if (kafkaConfig21Builder_ == null) {
              result.kafkaConfig_ = kafkaConfig_;
            } else {
              result.kafkaConfig_ = kafkaConfig21Builder_.build();
            }
          }
          if (kafkaConfigCase_ == 3) {
            if (kafkaConfig26Builder_ == null) {
              result.kafkaConfig_ = kafkaConfig_;
            } else {
              result.kafkaConfig_ = kafkaConfig26Builder_.build();
            }
          }
          if (kafkaConfigCase_ == 4) {
            if (kafkaConfig28Builder_ == null) {
              result.kafkaConfig_ = kafkaConfig_;
            } else {
              result.kafkaConfig_ = kafkaConfig28Builder_.build();
            }
          }
          result.kafkaConfigCase_ = kafkaConfigCase_;
          onBuilt();
          return result;
        }

        @java.lang.Override
        public Builder clone() {
          return (Builder) super.clone();
        }
        @java.lang.Override
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return (Builder) super.setField(field, value);
        }
        @java.lang.Override
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return (Builder) super.clearField(field);
        }
        @java.lang.Override
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return (Builder) super.clearOneof(oneof);
        }
        @java.lang.Override
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, java.lang.Object value) {
          return (Builder) super.setRepeatedField(field, index, value);
        }
        @java.lang.Override
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return (Builder) super.addRepeatedField(field, value);
        }
        @java.lang.Override
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka) {
            return mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka other) {
          if (other == yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.getDefaultInstance()) return this;
          if (other.hasResources()) {
            mergeResources(other.getResources());
          }
          switch (other.getKafkaConfigCase()) {
            case KAFKA_CONFIG_2_1: {
              mergeKafkaConfig21(other.getKafkaConfig21());
              break;
            }
            case KAFKA_CONFIG_2_6: {
              mergeKafkaConfig26(other.getKafkaConfig26());
              break;
            }
            case KAFKA_CONFIG_2_8: {
              mergeKafkaConfig28(other.getKafkaConfig28());
              break;
            }
            case KAFKACONFIG_NOT_SET: {
              break;
            }
          }
          this.mergeUnknownFields(other.unknownFields);
          onChanged();
          return this;
        }

        @java.lang.Override
        public final boolean isInitialized() {
          return true;
        }

        @java.lang.Override
        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }
        private int kafkaConfigCase_ = 0;
        private java.lang.Object kafkaConfig_;
        public KafkaConfigCase
            getKafkaConfigCase() {
          return KafkaConfigCase.forNumber(
              kafkaConfigCase_);
        }

        public Builder clearKafkaConfig() {
          kafkaConfigCase_ = 0;
          kafkaConfig_ = null;
          onChanged();
          return this;
        }


        private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources resources_ = null;
        private com.google.protobuf.SingleFieldBuilderV3<
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder> resourcesBuilder_;
        /**
         * <pre>
         * Resources allocated to Kafka brokers.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public boolean hasResources() {
          return resourcesBuilder_ != null || resources_ != null;
        }
        /**
         * <pre>
         * Resources allocated to Kafka brokers.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources getResources() {
          if (resourcesBuilder_ == null) {
            return resources_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.getDefaultInstance() : resources_;
          } else {
            return resourcesBuilder_.getMessage();
          }
        }
        /**
         * <pre>
         * Resources allocated to Kafka brokers.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public Builder setResources(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources value) {
          if (resourcesBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            resources_ = value;
            onChanged();
          } else {
            resourcesBuilder_.setMessage(value);
          }

          return this;
        }
        /**
         * <pre>
         * Resources allocated to Kafka brokers.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public Builder setResources(
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder builderForValue) {
          if (resourcesBuilder_ == null) {
            resources_ = builderForValue.build();
            onChanged();
          } else {
            resourcesBuilder_.setMessage(builderForValue.build());
          }

          return this;
        }
        /**
         * <pre>
         * Resources allocated to Kafka brokers.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public Builder mergeResources(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources value) {
          if (resourcesBuilder_ == null) {
            if (resources_ != null) {
              resources_ =
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.newBuilder(resources_).mergeFrom(value).buildPartial();
            } else {
              resources_ = value;
            }
            onChanged();
          } else {
            resourcesBuilder_.mergeFrom(value);
          }

          return this;
        }
        /**
         * <pre>
         * Resources allocated to Kafka brokers.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public Builder clearResources() {
          if (resourcesBuilder_ == null) {
            resources_ = null;
            onChanged();
          } else {
            resources_ = null;
            resourcesBuilder_ = null;
          }

          return this;
        }
        /**
         * <pre>
         * Resources allocated to Kafka brokers.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder getResourcesBuilder() {
          
          onChanged();
          return getResourcesFieldBuilder().getBuilder();
        }
        /**
         * <pre>
         * Resources allocated to Kafka brokers.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder getResourcesOrBuilder() {
          if (resourcesBuilder_ != null) {
            return resourcesBuilder_.getMessageOrBuilder();
          } else {
            return resources_ == null ?
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.getDefaultInstance() : resources_;
          }
        }
        /**
         * <pre>
         * Resources allocated to Kafka brokers.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        private com.google.protobuf.SingleFieldBuilderV3<
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder> 
            getResourcesFieldBuilder() {
          if (resourcesBuilder_ == null) {
            resourcesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder>(
                    getResources(),
                    getParentForChildren(),
                    isClean());
            resources_ = null;
          }
          return resourcesBuilder_;
        }

        private com.google.protobuf.SingleFieldBuilderV3<
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1OrBuilder> kafkaConfig21Builder_;
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_1 kafka_config_2_1 = 2[json_name = "kafkaConfig_2_1"];</code>
         */
        public boolean hasKafkaConfig21() {
          return kafkaConfigCase_ == 2;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_1 kafka_config_2_1 = 2[json_name = "kafkaConfig_2_1"];</code>
         */
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 getKafkaConfig21() {
          if (kafkaConfig21Builder_ == null) {
            if (kafkaConfigCase_ == 2) {
              return (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1) kafkaConfig_;
            }
            return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1.getDefaultInstance();
          } else {
            if (kafkaConfigCase_ == 2) {
              return kafkaConfig21Builder_.getMessage();
            }
            return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1.getDefaultInstance();
          }
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_1 kafka_config_2_1 = 2[json_name = "kafkaConfig_2_1"];</code>
         */
        public Builder setKafkaConfig21(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 value) {
          if (kafkaConfig21Builder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            kafkaConfig_ = value;
            onChanged();
          } else {
            kafkaConfig21Builder_.setMessage(value);
          }
          kafkaConfigCase_ = 2;
          return this;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_1 kafka_config_2_1 = 2[json_name = "kafkaConfig_2_1"];</code>
         */
        public Builder setKafkaConfig21(
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1.Builder builderForValue) {
          if (kafkaConfig21Builder_ == null) {
            kafkaConfig_ = builderForValue.build();
            onChanged();
          } else {
            kafkaConfig21Builder_.setMessage(builderForValue.build());
          }
          kafkaConfigCase_ = 2;
          return this;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_1 kafka_config_2_1 = 2[json_name = "kafkaConfig_2_1"];</code>
         */
        public Builder mergeKafkaConfig21(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 value) {
          if (kafkaConfig21Builder_ == null) {
            if (kafkaConfigCase_ == 2 &&
                kafkaConfig_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1.getDefaultInstance()) {
              kafkaConfig_ = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1.newBuilder((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1) kafkaConfig_)
                  .mergeFrom(value).buildPartial();
            } else {
              kafkaConfig_ = value;
            }
            onChanged();
          } else {
            if (kafkaConfigCase_ == 2) {
              kafkaConfig21Builder_.mergeFrom(value);
            }
            kafkaConfig21Builder_.setMessage(value);
          }
          kafkaConfigCase_ = 2;
          return this;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_1 kafka_config_2_1 = 2[json_name = "kafkaConfig_2_1"];</code>
         */
        public Builder clearKafkaConfig21() {
          if (kafkaConfig21Builder_ == null) {
            if (kafkaConfigCase_ == 2) {
              kafkaConfigCase_ = 0;
              kafkaConfig_ = null;
              onChanged();
            }
          } else {
            if (kafkaConfigCase_ == 2) {
              kafkaConfigCase_ = 0;
              kafkaConfig_ = null;
            }
            kafkaConfig21Builder_.clear();
          }
          return this;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_1 kafka_config_2_1 = 2[json_name = "kafkaConfig_2_1"];</code>
         */
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1.Builder getKafkaConfig21Builder() {
          return getKafkaConfig21FieldBuilder().getBuilder();
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_1 kafka_config_2_1 = 2[json_name = "kafkaConfig_2_1"];</code>
         */
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1OrBuilder getKafkaConfig21OrBuilder() {
          if ((kafkaConfigCase_ == 2) && (kafkaConfig21Builder_ != null)) {
            return kafkaConfig21Builder_.getMessageOrBuilder();
          } else {
            if (kafkaConfigCase_ == 2) {
              return (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1) kafkaConfig_;
            }
            return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1.getDefaultInstance();
          }
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_1 kafka_config_2_1 = 2[json_name = "kafkaConfig_2_1"];</code>
         */
        private com.google.protobuf.SingleFieldBuilderV3<
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1OrBuilder> 
            getKafkaConfig21FieldBuilder() {
          if (kafkaConfig21Builder_ == null) {
            if (!(kafkaConfigCase_ == 2)) {
              kafkaConfig_ = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1.getDefaultInstance();
            }
            kafkaConfig21Builder_ = new com.google.protobuf.SingleFieldBuilderV3<
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1OrBuilder>(
                    (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1) kafkaConfig_,
                    getParentForChildren(),
                    isClean());
            kafkaConfig_ = null;
          }
          kafkaConfigCase_ = 2;
          onChanged();;
          return kafkaConfig21Builder_;
        }

        private com.google.protobuf.SingleFieldBuilderV3<
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6OrBuilder> kafkaConfig26Builder_;
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_6 kafka_config_2_6 = 3[json_name = "kafkaConfig_2_6"];</code>
         */
        public boolean hasKafkaConfig26() {
          return kafkaConfigCase_ == 3;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_6 kafka_config_2_6 = 3[json_name = "kafkaConfig_2_6"];</code>
         */
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 getKafkaConfig26() {
          if (kafkaConfig26Builder_ == null) {
            if (kafkaConfigCase_ == 3) {
              return (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6) kafkaConfig_;
            }
            return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6.getDefaultInstance();
          } else {
            if (kafkaConfigCase_ == 3) {
              return kafkaConfig26Builder_.getMessage();
            }
            return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6.getDefaultInstance();
          }
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_6 kafka_config_2_6 = 3[json_name = "kafkaConfig_2_6"];</code>
         */
        public Builder setKafkaConfig26(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 value) {
          if (kafkaConfig26Builder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            kafkaConfig_ = value;
            onChanged();
          } else {
            kafkaConfig26Builder_.setMessage(value);
          }
          kafkaConfigCase_ = 3;
          return this;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_6 kafka_config_2_6 = 3[json_name = "kafkaConfig_2_6"];</code>
         */
        public Builder setKafkaConfig26(
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6.Builder builderForValue) {
          if (kafkaConfig26Builder_ == null) {
            kafkaConfig_ = builderForValue.build();
            onChanged();
          } else {
            kafkaConfig26Builder_.setMessage(builderForValue.build());
          }
          kafkaConfigCase_ = 3;
          return this;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_6 kafka_config_2_6 = 3[json_name = "kafkaConfig_2_6"];</code>
         */
        public Builder mergeKafkaConfig26(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 value) {
          if (kafkaConfig26Builder_ == null) {
            if (kafkaConfigCase_ == 3 &&
                kafkaConfig_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6.getDefaultInstance()) {
              kafkaConfig_ = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6.newBuilder((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6) kafkaConfig_)
                  .mergeFrom(value).buildPartial();
            } else {
              kafkaConfig_ = value;
            }
            onChanged();
          } else {
            if (kafkaConfigCase_ == 3) {
              kafkaConfig26Builder_.mergeFrom(value);
            }
            kafkaConfig26Builder_.setMessage(value);
          }
          kafkaConfigCase_ = 3;
          return this;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_6 kafka_config_2_6 = 3[json_name = "kafkaConfig_2_6"];</code>
         */
        public Builder clearKafkaConfig26() {
          if (kafkaConfig26Builder_ == null) {
            if (kafkaConfigCase_ == 3) {
              kafkaConfigCase_ = 0;
              kafkaConfig_ = null;
              onChanged();
            }
          } else {
            if (kafkaConfigCase_ == 3) {
              kafkaConfigCase_ = 0;
              kafkaConfig_ = null;
            }
            kafkaConfig26Builder_.clear();
          }
          return this;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_6 kafka_config_2_6 = 3[json_name = "kafkaConfig_2_6"];</code>
         */
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6.Builder getKafkaConfig26Builder() {
          return getKafkaConfig26FieldBuilder().getBuilder();
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_6 kafka_config_2_6 = 3[json_name = "kafkaConfig_2_6"];</code>
         */
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6OrBuilder getKafkaConfig26OrBuilder() {
          if ((kafkaConfigCase_ == 3) && (kafkaConfig26Builder_ != null)) {
            return kafkaConfig26Builder_.getMessageOrBuilder();
          } else {
            if (kafkaConfigCase_ == 3) {
              return (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6) kafkaConfig_;
            }
            return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6.getDefaultInstance();
          }
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_6 kafka_config_2_6 = 3[json_name = "kafkaConfig_2_6"];</code>
         */
        private com.google.protobuf.SingleFieldBuilderV3<
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6OrBuilder> 
            getKafkaConfig26FieldBuilder() {
          if (kafkaConfig26Builder_ == null) {
            if (!(kafkaConfigCase_ == 3)) {
              kafkaConfig_ = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6.getDefaultInstance();
            }
            kafkaConfig26Builder_ = new com.google.protobuf.SingleFieldBuilderV3<
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6OrBuilder>(
                    (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6) kafkaConfig_,
                    getParentForChildren(),
                    isClean());
            kafkaConfig_ = null;
          }
          kafkaConfigCase_ = 3;
          onChanged();;
          return kafkaConfig26Builder_;
        }

        private com.google.protobuf.SingleFieldBuilderV3<
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8OrBuilder> kafkaConfig28Builder_;
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4[json_name = "kafkaConfig_2_8"];</code>
         */
        public boolean hasKafkaConfig28() {
          return kafkaConfigCase_ == 4;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4[json_name = "kafkaConfig_2_8"];</code>
         */
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 getKafkaConfig28() {
          if (kafkaConfig28Builder_ == null) {
            if (kafkaConfigCase_ == 4) {
              return (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) kafkaConfig_;
            }
            return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.getDefaultInstance();
          } else {
            if (kafkaConfigCase_ == 4) {
              return kafkaConfig28Builder_.getMessage();
            }
            return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.getDefaultInstance();
          }
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4[json_name = "kafkaConfig_2_8"];</code>
         */
        public Builder setKafkaConfig28(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 value) {
          if (kafkaConfig28Builder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            kafkaConfig_ = value;
            onChanged();
          } else {
            kafkaConfig28Builder_.setMessage(value);
          }
          kafkaConfigCase_ = 4;
          return this;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4[json_name = "kafkaConfig_2_8"];</code>
         */
        public Builder setKafkaConfig28(
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.Builder builderForValue) {
          if (kafkaConfig28Builder_ == null) {
            kafkaConfig_ = builderForValue.build();
            onChanged();
          } else {
            kafkaConfig28Builder_.setMessage(builderForValue.build());
          }
          kafkaConfigCase_ = 4;
          return this;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4[json_name = "kafkaConfig_2_8"];</code>
         */
        public Builder mergeKafkaConfig28(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 value) {
          if (kafkaConfig28Builder_ == null) {
            if (kafkaConfigCase_ == 4 &&
                kafkaConfig_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.getDefaultInstance()) {
              kafkaConfig_ = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.newBuilder((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) kafkaConfig_)
                  .mergeFrom(value).buildPartial();
            } else {
              kafkaConfig_ = value;
            }
            onChanged();
          } else {
            if (kafkaConfigCase_ == 4) {
              kafkaConfig28Builder_.mergeFrom(value);
            }
            kafkaConfig28Builder_.setMessage(value);
          }
          kafkaConfigCase_ = 4;
          return this;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4[json_name = "kafkaConfig_2_8"];</code>
         */
        public Builder clearKafkaConfig28() {
          if (kafkaConfig28Builder_ == null) {
            if (kafkaConfigCase_ == 4) {
              kafkaConfigCase_ = 0;
              kafkaConfig_ = null;
              onChanged();
            }
          } else {
            if (kafkaConfigCase_ == 4) {
              kafkaConfigCase_ = 0;
              kafkaConfig_ = null;
            }
            kafkaConfig28Builder_.clear();
          }
          return this;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4[json_name = "kafkaConfig_2_8"];</code>
         */
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.Builder getKafkaConfig28Builder() {
          return getKafkaConfig28FieldBuilder().getBuilder();
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4[json_name = "kafkaConfig_2_8"];</code>
         */
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8OrBuilder getKafkaConfig28OrBuilder() {
          if ((kafkaConfigCase_ == 4) && (kafkaConfig28Builder_ != null)) {
            return kafkaConfig28Builder_.getMessageOrBuilder();
          } else {
            if (kafkaConfigCase_ == 4) {
              return (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) kafkaConfig_;
            }
            return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.getDefaultInstance();
          }
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4[json_name = "kafkaConfig_2_8"];</code>
         */
        private com.google.protobuf.SingleFieldBuilderV3<
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8OrBuilder> 
            getKafkaConfig28FieldBuilder() {
          if (kafkaConfig28Builder_ == null) {
            if (!(kafkaConfigCase_ == 4)) {
              kafkaConfig_ = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.getDefaultInstance();
            }
            kafkaConfig28Builder_ = new com.google.protobuf.SingleFieldBuilderV3<
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8OrBuilder>(
                    (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) kafkaConfig_,
                    getParentForChildren(),
                    isClean());
            kafkaConfig_ = null;
          }
          kafkaConfigCase_ = 4;
          onChanged();;
          return kafkaConfig28Builder_;
        }
        @java.lang.Override
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.setUnknownFieldsProto3(unknownFields);
        }

        @java.lang.Override
        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.mergeUnknownFields(unknownFields);
        }


        // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka)
      }

      // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka)
      private static final yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka();
      }

      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<Kafka>
          PARSER = new com.google.protobuf.AbstractParser<Kafka>() {
        @java.lang.Override
        public Kafka parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return new Kafka(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<Kafka> parser() {
        return PARSER;
      }

      @java.lang.Override
      public com.google.protobuf.Parser<Kafka> getParserForType() {
        return PARSER;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    public interface ZookeeperOrBuilder extends
        // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <pre>
       * Resources allocated to ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
       */
      boolean hasResources();
      /**
       * <pre>
       * Resources allocated to ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
       */
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources getResources();
      /**
       * <pre>
       * Resources allocated to ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
       */
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder getResourcesOrBuilder();
    }
    /**
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper}
     */
    public  static final class Zookeeper extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper)
        ZookeeperOrBuilder {
    private static final long serialVersionUID = 0L;
      // Use Zookeeper.newBuilder() to construct.
      private Zookeeper(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private Zookeeper() {
      }

      @java.lang.Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return this.unknownFields;
      }
      private Zookeeper(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        int mutable_bitField0_ = 0;
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
            com.google.protobuf.UnknownFieldSet.newBuilder();
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder subBuilder = null;
                if (resources_ != null) {
                  subBuilder = resources_.toBuilder();
                }
                resources_ = input.readMessage(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.parser(), extensionRegistry);
                if (subBuilder != null) {
                  subBuilder.mergeFrom(resources_);
                  resources_ = subBuilder.buildPartial();
                }

                break;
              }
              default: {
                if (!parseUnknownFieldProto3(
                    input, unknownFields, extensionRegistry, tag)) {
                  done = true;
                }
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          this.unknownFields = unknownFields.build();
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Zookeeper_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Zookeeper_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.Builder.class);
      }

      public static final int RESOURCES_FIELD_NUMBER = 1;
      private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources resources_;
      /**
       * <pre>
       * Resources allocated to ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
       */
      public boolean hasResources() {
        return resources_ != null;
      }
      /**
       * <pre>
       * Resources allocated to ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources getResources() {
        return resources_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.getDefaultInstance() : resources_;
      }
      /**
       * <pre>
       * Resources allocated to ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder getResourcesOrBuilder() {
        return getResources();
      }

      private byte memoizedIsInitialized = -1;
      @java.lang.Override
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      @java.lang.Override
      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (resources_ != null) {
          output.writeMessage(1, getResources());
        }
        unknownFields.writeTo(output);
      }

      @java.lang.Override
      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (resources_ != null) {
          size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(1, getResources());
        }
        size += unknownFields.getSerializedSize();
        memoizedSize = size;
        return size;
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper)) {
          return super.equals(obj);
        }
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper other = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper) obj;

        boolean result = true;
        result = result && (hasResources() == other.hasResources());
        if (hasResources()) {
          result = result && getResources()
              .equals(other.getResources());
        }
        result = result && unknownFields.equals(other.unknownFields);
        return result;
      }

      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptor().hashCode();
        if (hasResources()) {
          hash = (37 * hash) + RESOURCES_FIELD_NUMBER;
          hash = (53 * hash) + getResources().hashCode();
        }
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parseFrom(
          java.nio.ByteBuffer data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parseFrom(
          java.nio.ByteBuffer data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      @java.lang.Override
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      @java.lang.Override
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @java.lang.Override
      protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * Protobuf type {@code yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper)
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.ZookeeperOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Zookeeper_descriptor;
        }

        @java.lang.Override
        protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Zookeeper_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.Builder.class);
        }

        // Construct using yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
          }
        }
        @java.lang.Override
        public Builder clear() {
          super.clear();
          if (resourcesBuilder_ == null) {
            resources_ = null;
          } else {
            resources_ = null;
            resourcesBuilder_ = null;
          }
          return this;
        }

        @java.lang.Override
        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Zookeeper_descriptor;
        }

        @java.lang.Override
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper getDefaultInstanceForType() {
          return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.getDefaultInstance();
        }

        @java.lang.Override
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper build() {
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        @java.lang.Override
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper buildPartial() {
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper result = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper(this);
          if (resourcesBuilder_ == null) {
            result.resources_ = resources_;
          } else {
            result.resources_ = resourcesBuilder_.build();
          }
          onBuilt();
          return result;
        }

        @java.lang.Override
        public Builder clone() {
          return (Builder) super.clone();
        }
        @java.lang.Override
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return (Builder) super.setField(field, value);
        }
        @java.lang.Override
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return (Builder) super.clearField(field);
        }
        @java.lang.Override
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return (Builder) super.clearOneof(oneof);
        }
        @java.lang.Override
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, java.lang.Object value) {
          return (Builder) super.setRepeatedField(field, index, value);
        }
        @java.lang.Override
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return (Builder) super.addRepeatedField(field, value);
        }
        @java.lang.Override
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper) {
            return mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper other) {
          if (other == yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.getDefaultInstance()) return this;
          if (other.hasResources()) {
            mergeResources(other.getResources());
          }
          this.mergeUnknownFields(other.unknownFields);
          onChanged();
          return this;
        }

        @java.lang.Override
        public final boolean isInitialized() {
          return true;
        }

        @java.lang.Override
        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }

        private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources resources_ = null;
        private com.google.protobuf.SingleFieldBuilderV3<
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder> resourcesBuilder_;
        /**
         * <pre>
         * Resources allocated to ZooKeeper hosts.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public boolean hasResources() {
          return resourcesBuilder_ != null || resources_ != null;
        }
        /**
         * <pre>
         * Resources allocated to ZooKeeper hosts.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources getResources() {
          if (resourcesBuilder_ == null) {
            return resources_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.getDefaultInstance() : resources_;
          } else {
            return resourcesBuilder_.getMessage();
          }
        }
        /**
         * <pre>
         * Resources allocated to ZooKeeper hosts.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public Builder setResources(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources value) {
          if (resourcesBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            resources_ = value;
            onChanged();
          } else {
            resourcesBuilder_.setMessage(value);
          }

          return this;
        }
        /**
         * <pre>
         * Resources allocated to ZooKeeper hosts.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public Builder setResources(
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder builderForValue) {
          if (resourcesBuilder_ == null) {
            resources_ = builderForValue.build();
            onChanged();
          } else {
            resourcesBuilder_.setMessage(builderForValue.build());
          }

          return this;
        }
        /**
         * <pre>
         * Resources allocated to ZooKeeper hosts.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public Builder mergeResources(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources value) {
          if (resourcesBuilder_ == null) {
            if (resources_ != null) {
              resources_ =
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.newBuilder(resources_).mergeFrom(value).buildPartial();
            } else {
              resources_ = value;
            }
            onChanged();
          } else {
            resourcesBuilder_.mergeFrom(value);
          }

          return this;
        }
        /**
         * <pre>
         * Resources allocated to ZooKeeper hosts.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public Builder clearResources() {
          if (resourcesBuilder_ == null) {
            resources_ = null;
            onChanged();
          } else {
            resources_ = null;
            resourcesBuilder_ = null;
          }

          return this;
        }
        /**
         * <pre>
         * Resources allocated to ZooKeeper hosts.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder getResourcesBuilder() {
          
          onChanged();
          return getResourcesFieldBuilder().getBuilder();
        }
        /**
         * <pre>
         * Resources allocated to ZooKeeper hosts.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder getResourcesOrBuilder() {
          if (resourcesBuilder_ != null) {
            return resourcesBuilder_.getMessageOrBuilder();
          } else {
            return resources_ == null ?
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.getDefaultInstance() : resources_;
          }
        }
        /**
         * <pre>
         * Resources allocated to ZooKeeper hosts.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        private com.google.protobuf.SingleFieldBuilderV3<
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder> 
            getResourcesFieldBuilder() {
          if (resourcesBuilder_ == null) {
            resourcesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder>(
                    getResources(),
                    getParentForChildren(),
                    isClean());
            resources_ = null;
          }
          return resourcesBuilder_;
        }
        @java.lang.Override
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.setUnknownFieldsProto3(unknownFields);
        }

        @java.lang.Override
        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.mergeUnknownFields(unknownFields);
        }


        // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper)
      }

      // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper)
      private static final yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper();
      }

      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<Zookeeper>
          PARSER = new com.google.protobuf.AbstractParser<Zookeeper>() {
        @java.lang.Override
        public Zookeeper parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return new Zookeeper(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<Zookeeper> parser() {
        return PARSER;
      }

      @java.lang.Override
      public com.google.protobuf.Parser<Zookeeper> getParserForType() {
        return PARSER;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    private int bitField0_;
    public static final int VERSION_FIELD_NUMBER = 1;
    private volatile java.lang.Object version_;
    /**
     * <pre>
     * Version of Apache Kafka® used in the cluster. Possible values: `2.1`, `2.6`.
     * </pre>
     *
     * <code>string version = 1;</code>
     */
    public java.lang.String getVersion() {
      java.lang.Object ref = version_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        version_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Version of Apache Kafka® used in the cluster. Possible values: `2.1`, `2.6`.
     * </pre>
     *
     * <code>string version = 1;</code>
     */
    public com.google.protobuf.ByteString
        getVersionBytes() {
      java.lang.Object ref = version_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        version_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int KAFKA_FIELD_NUMBER = 2;
    private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka kafka_;
    /**
     * <pre>
     * Configuration and resource allocation for Kafka brokers.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
     */
    public boolean hasKafka() {
      return kafka_ != null;
    }
    /**
     * <pre>
     * Configuration and resource allocation for Kafka brokers.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka getKafka() {
      return kafka_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.getDefaultInstance() : kafka_;
    }
    /**
     * <pre>
     * Configuration and resource allocation for Kafka brokers.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.KafkaOrBuilder getKafkaOrBuilder() {
      return getKafka();
    }

    public static final int ZOOKEEPER_FIELD_NUMBER = 3;
    private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper zookeeper_;
    /**
     * <pre>
     * Configuration and resource allocation for ZooKeeper hosts.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
     */
    public boolean hasZookeeper() {
      return zookeeper_ != null;
    }
    /**
     * <pre>
     * Configuration and resource allocation for ZooKeeper hosts.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper getZookeeper() {
      return zookeeper_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.getDefaultInstance() : zookeeper_;
    }
    /**
     * <pre>
     * Configuration and resource allocation for ZooKeeper hosts.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.ZookeeperOrBuilder getZookeeperOrBuilder() {
      return getZookeeper();
    }

    public static final int ZONE_ID_FIELD_NUMBER = 4;
    private com.google.protobuf.LazyStringList zoneId_;
    /**
     * <pre>
     * IDs of availability zones where Kafka brokers reside.
     * </pre>
     *
     * <code>repeated string zone_id = 4;</code>
     */
    public com.google.protobuf.ProtocolStringList
        getZoneIdList() {
      return zoneId_;
    }
    /**
     * <pre>
     * IDs of availability zones where Kafka brokers reside.
     * </pre>
     *
     * <code>repeated string zone_id = 4;</code>
     */
    public int getZoneIdCount() {
      return zoneId_.size();
    }
    /**
     * <pre>
     * IDs of availability zones where Kafka brokers reside.
     * </pre>
     *
     * <code>repeated string zone_id = 4;</code>
     */
    public java.lang.String getZoneId(int index) {
      return zoneId_.get(index);
    }
    /**
     * <pre>
     * IDs of availability zones where Kafka brokers reside.
     * </pre>
     *
     * <code>repeated string zone_id = 4;</code>
     */
    public com.google.protobuf.ByteString
        getZoneIdBytes(int index) {
      return zoneId_.getByteString(index);
    }

    public static final int BROKERS_COUNT_FIELD_NUMBER = 5;
    private com.google.protobuf.Int64Value brokersCount_;
    /**
     * <pre>
     * The number of Kafka brokers deployed in each availability zone.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
     */
    public boolean hasBrokersCount() {
      return brokersCount_ != null;
    }
    /**
     * <pre>
     * The number of Kafka brokers deployed in each availability zone.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
     */
    public com.google.protobuf.Int64Value getBrokersCount() {
      return brokersCount_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : brokersCount_;
    }
    /**
     * <pre>
     * The number of Kafka brokers deployed in each availability zone.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getBrokersCountOrBuilder() {
      return getBrokersCount();
    }

    public static final int ASSIGN_PUBLIC_IP_FIELD_NUMBER = 6;
    private boolean assignPublicIp_;
    /**
     * <pre>
     * The flag that defines whether a public IP address is assigned to the cluster.
     * If the value is `true`, then Apache Kafka® cluster is available on the Internet via it's public IP address.
     * </pre>
     *
     * <code>bool assign_public_ip = 6;</code>
     */
    public boolean getAssignPublicIp() {
      return assignPublicIp_;
    }

    public static final int UNMANAGED_TOPICS_FIELD_NUMBER = 7;
    private boolean unmanagedTopics_;
    /**
     * <pre>
     * Allows to manage topics via AdminAPI
     * </pre>
     *
     * <code>bool unmanaged_topics = 7;</code>
     */
    public boolean getUnmanagedTopics() {
      return unmanagedTopics_;
    }

    public static final int SCHEMA_REGISTRY_FIELD_NUMBER = 8;
    private boolean schemaRegistry_;
    /**
     * <pre>
     * Enables managed schema registry on cluster
     * </pre>
     *
     * <code>bool schema_registry = 8;</code>
     */
    public boolean getSchemaRegistry() {
      return schemaRegistry_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!getVersionBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, version_);
      }
      if (kafka_ != null) {
        output.writeMessage(2, getKafka());
      }
      if (zookeeper_ != null) {
        output.writeMessage(3, getZookeeper());
      }
      for (int i = 0; i < zoneId_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 4, zoneId_.getRaw(i));
      }
      if (brokersCount_ != null) {
        output.writeMessage(5, getBrokersCount());
      }
      if (assignPublicIp_ != false) {
        output.writeBool(6, assignPublicIp_);
      }
      if (unmanagedTopics_ != false) {
        output.writeBool(7, unmanagedTopics_);
      }
      if (schemaRegistry_ != false) {
        output.writeBool(8, schemaRegistry_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!getVersionBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, version_);
      }
      if (kafka_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getKafka());
      }
      if (zookeeper_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getZookeeper());
      }
      {
        int dataSize = 0;
        for (int i = 0; i < zoneId_.size(); i++) {
          dataSize += computeStringSizeNoTag(zoneId_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getZoneIdList().size();
      }
      if (brokersCount_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getBrokersCount());
      }
      if (assignPublicIp_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(6, assignPublicIp_);
      }
      if (unmanagedTopics_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(7, unmanagedTopics_);
      }
      if (schemaRegistry_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(8, schemaRegistry_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec)) {
        return super.equals(obj);
      }
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec other = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec) obj;

      boolean result = true;
      result = result && getVersion()
          .equals(other.getVersion());
      result = result && (hasKafka() == other.hasKafka());
      if (hasKafka()) {
        result = result && getKafka()
            .equals(other.getKafka());
      }
      result = result && (hasZookeeper() == other.hasZookeeper());
      if (hasZookeeper()) {
        result = result && getZookeeper()
            .equals(other.getZookeeper());
      }
      result = result && getZoneIdList()
          .equals(other.getZoneIdList());
      result = result && (hasBrokersCount() == other.hasBrokersCount());
      if (hasBrokersCount()) {
        result = result && getBrokersCount()
            .equals(other.getBrokersCount());
      }
      result = result && (getAssignPublicIp()
          == other.getAssignPublicIp());
      result = result && (getUnmanagedTopics()
          == other.getUnmanagedTopics());
      result = result && (getSchemaRegistry()
          == other.getSchemaRegistry());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + VERSION_FIELD_NUMBER;
      hash = (53 * hash) + getVersion().hashCode();
      if (hasKafka()) {
        hash = (37 * hash) + KAFKA_FIELD_NUMBER;
        hash = (53 * hash) + getKafka().hashCode();
      }
      if (hasZookeeper()) {
        hash = (37 * hash) + ZOOKEEPER_FIELD_NUMBER;
        hash = (53 * hash) + getZookeeper().hashCode();
      }
      if (getZoneIdCount() > 0) {
        hash = (37 * hash) + ZONE_ID_FIELD_NUMBER;
        hash = (53 * hash) + getZoneIdList().hashCode();
      }
      if (hasBrokersCount()) {
        hash = (37 * hash) + BROKERS_COUNT_FIELD_NUMBER;
        hash = (53 * hash) + getBrokersCount().hashCode();
      }
      hash = (37 * hash) + ASSIGN_PUBLIC_IP_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getAssignPublicIp());
      hash = (37 * hash) + UNMANAGED_TOPICS_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getUnmanagedTopics());
      hash = (37 * hash) + SCHEMA_REGISTRY_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getSchemaRegistry());
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.ConfigSpec}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.ConfigSpec)
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpecOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Builder.class);
      }

      // Construct using yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        version_ = "";

        if (kafkaBuilder_ == null) {
          kafka_ = null;
        } else {
          kafka_ = null;
          kafkaBuilder_ = null;
        }
        if (zookeeperBuilder_ == null) {
          zookeeper_ = null;
        } else {
          zookeeper_ = null;
          zookeeperBuilder_ = null;
        }
        zoneId_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000008);
        if (brokersCountBuilder_ == null) {
          brokersCount_ = null;
        } else {
          brokersCount_ = null;
          brokersCountBuilder_ = null;
        }
        assignPublicIp_ = false;

        unmanagedTopics_ = false;

        schemaRegistry_ = false;

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec getDefaultInstanceForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec build() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec buildPartial() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec result = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        result.version_ = version_;
        if (kafkaBuilder_ == null) {
          result.kafka_ = kafka_;
        } else {
          result.kafka_ = kafkaBuilder_.build();
        }
        if (zookeeperBuilder_ == null) {
          result.zookeeper_ = zookeeper_;
        } else {
          result.zookeeper_ = zookeeperBuilder_.build();
        }
        if (((bitField0_ & 0x00000008) == 0x00000008)) {
          zoneId_ = zoneId_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000008);
        }
        result.zoneId_ = zoneId_;
        if (brokersCountBuilder_ == null) {
          result.brokersCount_ = brokersCount_;
        } else {
          result.brokersCount_ = brokersCountBuilder_.build();
        }
        result.assignPublicIp_ = assignPublicIp_;
        result.unmanagedTopics_ = unmanagedTopics_;
        result.schemaRegistry_ = schemaRegistry_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec) {
          return mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec other) {
        if (other == yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.getDefaultInstance()) return this;
        if (!other.getVersion().isEmpty()) {
          version_ = other.version_;
          onChanged();
        }
        if (other.hasKafka()) {
          mergeKafka(other.getKafka());
        }
        if (other.hasZookeeper()) {
          mergeZookeeper(other.getZookeeper());
        }
        if (!other.zoneId_.isEmpty()) {
          if (zoneId_.isEmpty()) {
            zoneId_ = other.zoneId_;
            bitField0_ = (bitField0_ & ~0x00000008);
          } else {
            ensureZoneIdIsMutable();
            zoneId_.addAll(other.zoneId_);
          }
          onChanged();
        }
        if (other.hasBrokersCount()) {
          mergeBrokersCount(other.getBrokersCount());
        }
        if (other.getAssignPublicIp() != false) {
          setAssignPublicIp(other.getAssignPublicIp());
        }
        if (other.getUnmanagedTopics() != false) {
          setUnmanagedTopics(other.getUnmanagedTopics());
        }
        if (other.getSchemaRegistry() != false) {
          setSchemaRegistry(other.getSchemaRegistry());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object version_ = "";
      /**
       * <pre>
       * Version of Apache Kafka® used in the cluster. Possible values: `2.1`, `2.6`.
       * </pre>
       *
       * <code>string version = 1;</code>
       */
      public java.lang.String getVersion() {
        java.lang.Object ref = version_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          version_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Version of Apache Kafka® used in the cluster. Possible values: `2.1`, `2.6`.
       * </pre>
       *
       * <code>string version = 1;</code>
       */
      public com.google.protobuf.ByteString
          getVersionBytes() {
        java.lang.Object ref = version_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          version_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Version of Apache Kafka® used in the cluster. Possible values: `2.1`, `2.6`.
       * </pre>
       *
       * <code>string version = 1;</code>
       */
      public Builder setVersion(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        version_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Version of Apache Kafka® used in the cluster. Possible values: `2.1`, `2.6`.
       * </pre>
       *
       * <code>string version = 1;</code>
       */
      public Builder clearVersion() {
        
        version_ = getDefaultInstance().getVersion();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Version of Apache Kafka® used in the cluster. Possible values: `2.1`, `2.6`.
       * </pre>
       *
       * <code>string version = 1;</code>
       */
      public Builder setVersionBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        version_ = value;
        onChanged();
        return this;
      }

      private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka kafka_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.KafkaOrBuilder> kafkaBuilder_;
      /**
       * <pre>
       * Configuration and resource allocation for Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
       */
      public boolean hasKafka() {
        return kafkaBuilder_ != null || kafka_ != null;
      }
      /**
       * <pre>
       * Configuration and resource allocation for Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka getKafka() {
        if (kafkaBuilder_ == null) {
          return kafka_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.getDefaultInstance() : kafka_;
        } else {
          return kafkaBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Configuration and resource allocation for Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
       */
      public Builder setKafka(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka value) {
        if (kafkaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          kafka_ = value;
          onChanged();
        } else {
          kafkaBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Configuration and resource allocation for Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
       */
      public Builder setKafka(
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.Builder builderForValue) {
        if (kafkaBuilder_ == null) {
          kafka_ = builderForValue.build();
          onChanged();
        } else {
          kafkaBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Configuration and resource allocation for Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
       */
      public Builder mergeKafka(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka value) {
        if (kafkaBuilder_ == null) {
          if (kafka_ != null) {
            kafka_ =
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.newBuilder(kafka_).mergeFrom(value).buildPartial();
          } else {
            kafka_ = value;
          }
          onChanged();
        } else {
          kafkaBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Configuration and resource allocation for Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
       */
      public Builder clearKafka() {
        if (kafkaBuilder_ == null) {
          kafka_ = null;
          onChanged();
        } else {
          kafka_ = null;
          kafkaBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Configuration and resource allocation for Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.Builder getKafkaBuilder() {
        
        onChanged();
        return getKafkaFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Configuration and resource allocation for Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.KafkaOrBuilder getKafkaOrBuilder() {
        if (kafkaBuilder_ != null) {
          return kafkaBuilder_.getMessageOrBuilder();
        } else {
          return kafka_ == null ?
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.getDefaultInstance() : kafka_;
        }
      }
      /**
       * <pre>
       * Configuration and resource allocation for Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.KafkaOrBuilder> 
          getKafkaFieldBuilder() {
        if (kafkaBuilder_ == null) {
          kafkaBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.KafkaOrBuilder>(
                  getKafka(),
                  getParentForChildren(),
                  isClean());
          kafka_ = null;
        }
        return kafkaBuilder_;
      }

      private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper zookeeper_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.ZookeeperOrBuilder> zookeeperBuilder_;
      /**
       * <pre>
       * Configuration and resource allocation for ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
       */
      public boolean hasZookeeper() {
        return zookeeperBuilder_ != null || zookeeper_ != null;
      }
      /**
       * <pre>
       * Configuration and resource allocation for ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper getZookeeper() {
        if (zookeeperBuilder_ == null) {
          return zookeeper_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.getDefaultInstance() : zookeeper_;
        } else {
          return zookeeperBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Configuration and resource allocation for ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
       */
      public Builder setZookeeper(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper value) {
        if (zookeeperBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          zookeeper_ = value;
          onChanged();
        } else {
          zookeeperBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Configuration and resource allocation for ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
       */
      public Builder setZookeeper(
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.Builder builderForValue) {
        if (zookeeperBuilder_ == null) {
          zookeeper_ = builderForValue.build();
          onChanged();
        } else {
          zookeeperBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Configuration and resource allocation for ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
       */
      public Builder mergeZookeeper(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper value) {
        if (zookeeperBuilder_ == null) {
          if (zookeeper_ != null) {
            zookeeper_ =
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.newBuilder(zookeeper_).mergeFrom(value).buildPartial();
          } else {
            zookeeper_ = value;
          }
          onChanged();
        } else {
          zookeeperBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Configuration and resource allocation for ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
       */
      public Builder clearZookeeper() {
        if (zookeeperBuilder_ == null) {
          zookeeper_ = null;
          onChanged();
        } else {
          zookeeper_ = null;
          zookeeperBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Configuration and resource allocation for ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.Builder getZookeeperBuilder() {
        
        onChanged();
        return getZookeeperFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Configuration and resource allocation for ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.ZookeeperOrBuilder getZookeeperOrBuilder() {
        if (zookeeperBuilder_ != null) {
          return zookeeperBuilder_.getMessageOrBuilder();
        } else {
          return zookeeper_ == null ?
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.getDefaultInstance() : zookeeper_;
        }
      }
      /**
       * <pre>
       * Configuration and resource allocation for ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.ZookeeperOrBuilder> 
          getZookeeperFieldBuilder() {
        if (zookeeperBuilder_ == null) {
          zookeeperBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.ZookeeperOrBuilder>(
                  getZookeeper(),
                  getParentForChildren(),
                  isClean());
          zookeeper_ = null;
        }
        return zookeeperBuilder_;
      }

      private com.google.protobuf.LazyStringList zoneId_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureZoneIdIsMutable() {
        if (!((bitField0_ & 0x00000008) == 0x00000008)) {
          zoneId_ = new com.google.protobuf.LazyStringArrayList(zoneId_);
          bitField0_ |= 0x00000008;
         }
      }
      /**
       * <pre>
       * IDs of availability zones where Kafka brokers reside.
       * </pre>
       *
       * <code>repeated string zone_id = 4;</code>
       */
      public com.google.protobuf.ProtocolStringList
          getZoneIdList() {
        return zoneId_.getUnmodifiableView();
      }
      /**
       * <pre>
       * IDs of availability zones where Kafka brokers reside.
       * </pre>
       *
       * <code>repeated string zone_id = 4;</code>
       */
      public int getZoneIdCount() {
        return zoneId_.size();
      }
      /**
       * <pre>
       * IDs of availability zones where Kafka brokers reside.
       * </pre>
       *
       * <code>repeated string zone_id = 4;</code>
       */
      public java.lang.String getZoneId(int index) {
        return zoneId_.get(index);
      }
      /**
       * <pre>
       * IDs of availability zones where Kafka brokers reside.
       * </pre>
       *
       * <code>repeated string zone_id = 4;</code>
       */
      public com.google.protobuf.ByteString
          getZoneIdBytes(int index) {
        return zoneId_.getByteString(index);
      }
      /**
       * <pre>
       * IDs of availability zones where Kafka brokers reside.
       * </pre>
       *
       * <code>repeated string zone_id = 4;</code>
       */
      public Builder setZoneId(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureZoneIdIsMutable();
        zoneId_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * IDs of availability zones where Kafka brokers reside.
       * </pre>
       *
       * <code>repeated string zone_id = 4;</code>
       */
      public Builder addZoneId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureZoneIdIsMutable();
        zoneId_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * IDs of availability zones where Kafka brokers reside.
       * </pre>
       *
       * <code>repeated string zone_id = 4;</code>
       */
      public Builder addAllZoneId(
          java.lang.Iterable<java.lang.String> values) {
        ensureZoneIdIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, zoneId_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * IDs of availability zones where Kafka brokers reside.
       * </pre>
       *
       * <code>repeated string zone_id = 4;</code>
       */
      public Builder clearZoneId() {
        zoneId_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000008);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * IDs of availability zones where Kafka brokers reside.
       * </pre>
       *
       * <code>repeated string zone_id = 4;</code>
       */
      public Builder addZoneIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensureZoneIdIsMutable();
        zoneId_.add(value);
        onChanged();
        return this;
      }

      private com.google.protobuf.Int64Value brokersCount_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> brokersCountBuilder_;
      /**
       * <pre>
       * The number of Kafka brokers deployed in each availability zone.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
       */
      public boolean hasBrokersCount() {
        return brokersCountBuilder_ != null || brokersCount_ != null;
      }
      /**
       * <pre>
       * The number of Kafka brokers deployed in each availability zone.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
       */
      public com.google.protobuf.Int64Value getBrokersCount() {
        if (brokersCountBuilder_ == null) {
          return brokersCount_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : brokersCount_;
        } else {
          return brokersCountBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of Kafka brokers deployed in each availability zone.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
       */
      public Builder setBrokersCount(com.google.protobuf.Int64Value value) {
        if (brokersCountBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          brokersCount_ = value;
          onChanged();
        } else {
          brokersCountBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of Kafka brokers deployed in each availability zone.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
       */
      public Builder setBrokersCount(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (brokersCountBuilder_ == null) {
          brokersCount_ = builderForValue.build();
          onChanged();
        } else {
          brokersCountBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of Kafka brokers deployed in each availability zone.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
       */
      public Builder mergeBrokersCount(com.google.protobuf.Int64Value value) {
        if (brokersCountBuilder_ == null) {
          if (brokersCount_ != null) {
            brokersCount_ =
              com.google.protobuf.Int64Value.newBuilder(brokersCount_).mergeFrom(value).buildPartial();
          } else {
            brokersCount_ = value;
          }
          onChanged();
        } else {
          brokersCountBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of Kafka brokers deployed in each availability zone.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
       */
      public Builder clearBrokersCount() {
        if (brokersCountBuilder_ == null) {
          brokersCount_ = null;
          onChanged();
        } else {
          brokersCount_ = null;
          brokersCountBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of Kafka brokers deployed in each availability zone.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
       */
      public com.google.protobuf.Int64Value.Builder getBrokersCountBuilder() {
        
        onChanged();
        return getBrokersCountFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of Kafka brokers deployed in each availability zone.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getBrokersCountOrBuilder() {
        if (brokersCountBuilder_ != null) {
          return brokersCountBuilder_.getMessageOrBuilder();
        } else {
          return brokersCount_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : brokersCount_;
        }
      }
      /**
       * <pre>
       * The number of Kafka brokers deployed in each availability zone.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getBrokersCountFieldBuilder() {
        if (brokersCountBuilder_ == null) {
          brokersCountBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getBrokersCount(),
                  getParentForChildren(),
                  isClean());
          brokersCount_ = null;
        }
        return brokersCountBuilder_;
      }

      private boolean assignPublicIp_ ;
      /**
       * <pre>
       * The flag that defines whether a public IP address is assigned to the cluster.
       * If the value is `true`, then Apache Kafka® cluster is available on the Internet via it's public IP address.
       * </pre>
       *
       * <code>bool assign_public_ip = 6;</code>
       */
      public boolean getAssignPublicIp() {
        return assignPublicIp_;
      }
      /**
       * <pre>
       * The flag that defines whether a public IP address is assigned to the cluster.
       * If the value is `true`, then Apache Kafka® cluster is available on the Internet via it's public IP address.
       * </pre>
       *
       * <code>bool assign_public_ip = 6;</code>
       */
      public Builder setAssignPublicIp(boolean value) {
        
        assignPublicIp_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The flag that defines whether a public IP address is assigned to the cluster.
       * If the value is `true`, then Apache Kafka® cluster is available on the Internet via it's public IP address.
       * </pre>
       *
       * <code>bool assign_public_ip = 6;</code>
       */
      public Builder clearAssignPublicIp() {
        
        assignPublicIp_ = false;
        onChanged();
        return this;
      }

      private boolean unmanagedTopics_ ;
      /**
       * <pre>
       * Allows to manage topics via AdminAPI
       * </pre>
       *
       * <code>bool unmanaged_topics = 7;</code>
       */
      public boolean getUnmanagedTopics() {
        return unmanagedTopics_;
      }
      /**
       * <pre>
       * Allows to manage topics via AdminAPI
       * </pre>
       *
       * <code>bool unmanaged_topics = 7;</code>
       */
      public Builder setUnmanagedTopics(boolean value) {
        
        unmanagedTopics_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Allows to manage topics via AdminAPI
       * </pre>
       *
       * <code>bool unmanaged_topics = 7;</code>
       */
      public Builder clearUnmanagedTopics() {
        
        unmanagedTopics_ = false;
        onChanged();
        return this;
      }

      private boolean schemaRegistry_ ;
      /**
       * <pre>
       * Enables managed schema registry on cluster
       * </pre>
       *
       * <code>bool schema_registry = 8;</code>
       */
      public boolean getSchemaRegistry() {
        return schemaRegistry_;
      }
      /**
       * <pre>
       * Enables managed schema registry on cluster
       * </pre>
       *
       * <code>bool schema_registry = 8;</code>
       */
      public Builder setSchemaRegistry(boolean value) {
        
        schemaRegistry_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Enables managed schema registry on cluster
       * </pre>
       *
       * <code>bool schema_registry = 8;</code>
       */
      public Builder clearSchemaRegistry() {
        
        schemaRegistry_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.ConfigSpec)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.ConfigSpec)
    private static final yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec();
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ConfigSpec>
        PARSER = new com.google.protobuf.AbstractParser<ConfigSpec>() {
      @java.lang.Override
      public ConfigSpec parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ConfigSpec(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ConfigSpec> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ConfigSpec> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ResourcesOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.Resources)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * ID of the preset for computational resources available to a host (CPU, memory, etc.).
     * All available presets are listed in the [documentation](/docs/managed-kafka/concepts/instance-types).
     * </pre>
     *
     * <code>string resource_preset_id = 1;</code>
     */
    java.lang.String getResourcePresetId();
    /**
     * <pre>
     * ID of the preset for computational resources available to a host (CPU, memory, etc.).
     * All available presets are listed in the [documentation](/docs/managed-kafka/concepts/instance-types).
     * </pre>
     *
     * <code>string resource_preset_id = 1;</code>
     */
    com.google.protobuf.ByteString
        getResourcePresetIdBytes();

    /**
     * <pre>
     * Volume of the storage available to a host, in bytes.
     * </pre>
     *
     * <code>int64 disk_size = 2;</code>
     */
    long getDiskSize();

    /**
     * <pre>
     * Type of the storage environment for the host.
     * </pre>
     *
     * <code>string disk_type_id = 3;</code>
     */
    java.lang.String getDiskTypeId();
    /**
     * <pre>
     * Type of the storage environment for the host.
     * </pre>
     *
     * <code>string disk_type_id = 3;</code>
     */
    com.google.protobuf.ByteString
        getDiskTypeIdBytes();
  }
  /**
   * Protobuf type {@code yandex.cloud.mdb.kafka.v1.Resources}
   */
  public  static final class Resources extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.Resources)
      ResourcesOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Resources.newBuilder() to construct.
    private Resources(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Resources() {
      resourcePresetId_ = "";
      diskSize_ = 0L;
      diskTypeId_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private Resources(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              resourcePresetId_ = s;
              break;
            }
            case 16: {

              diskSize_ = input.readInt64();
              break;
            }
            case 26: {
              java.lang.String s = input.readStringRequireUtf8();

              diskTypeId_ = s;
              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Resources_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Resources_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder.class);
    }

    public static final int RESOURCE_PRESET_ID_FIELD_NUMBER = 1;
    private volatile java.lang.Object resourcePresetId_;
    /**
     * <pre>
     * ID of the preset for computational resources available to a host (CPU, memory, etc.).
     * All available presets are listed in the [documentation](/docs/managed-kafka/concepts/instance-types).
     * </pre>
     *
     * <code>string resource_preset_id = 1;</code>
     */
    public java.lang.String getResourcePresetId() {
      java.lang.Object ref = resourcePresetId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        resourcePresetId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of the preset for computational resources available to a host (CPU, memory, etc.).
     * All available presets are listed in the [documentation](/docs/managed-kafka/concepts/instance-types).
     * </pre>
     *
     * <code>string resource_preset_id = 1;</code>
     */
    public com.google.protobuf.ByteString
        getResourcePresetIdBytes() {
      java.lang.Object ref = resourcePresetId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        resourcePresetId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int DISK_SIZE_FIELD_NUMBER = 2;
    private long diskSize_;
    /**
     * <pre>
     * Volume of the storage available to a host, in bytes.
     * </pre>
     *
     * <code>int64 disk_size = 2;</code>
     */
    public long getDiskSize() {
      return diskSize_;
    }

    public static final int DISK_TYPE_ID_FIELD_NUMBER = 3;
    private volatile java.lang.Object diskTypeId_;
    /**
     * <pre>
     * Type of the storage environment for the host.
     * </pre>
     *
     * <code>string disk_type_id = 3;</code>
     */
    public java.lang.String getDiskTypeId() {
      java.lang.Object ref = diskTypeId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        diskTypeId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Type of the storage environment for the host.
     * </pre>
     *
     * <code>string disk_type_id = 3;</code>
     */
    public com.google.protobuf.ByteString
        getDiskTypeIdBytes() {
      java.lang.Object ref = diskTypeId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        diskTypeId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!getResourcePresetIdBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, resourcePresetId_);
      }
      if (diskSize_ != 0L) {
        output.writeInt64(2, diskSize_);
      }
      if (!getDiskTypeIdBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, diskTypeId_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!getResourcePresetIdBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, resourcePresetId_);
      }
      if (diskSize_ != 0L) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(2, diskSize_);
      }
      if (!getDiskTypeIdBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, diskTypeId_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources)) {
        return super.equals(obj);
      }
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources other = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources) obj;

      boolean result = true;
      result = result && getResourcePresetId()
          .equals(other.getResourcePresetId());
      result = result && (getDiskSize()
          == other.getDiskSize());
      result = result && getDiskTypeId()
          .equals(other.getDiskTypeId());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + RESOURCE_PRESET_ID_FIELD_NUMBER;
      hash = (53 * hash) + getResourcePresetId().hashCode();
      hash = (37 * hash) + DISK_SIZE_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
          getDiskSize());
      hash = (37 * hash) + DISK_TYPE_ID_FIELD_NUMBER;
      hash = (53 * hash) + getDiskTypeId().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.Resources}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.Resources)
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Resources_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Resources_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder.class);
      }

      // Construct using yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        resourcePresetId_ = "";

        diskSize_ = 0L;

        diskTypeId_ = "";

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Resources_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources getDefaultInstanceForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources build() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources buildPartial() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources result = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources(this);
        result.resourcePresetId_ = resourcePresetId_;
        result.diskSize_ = diskSize_;
        result.diskTypeId_ = diskTypeId_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources) {
          return mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources other) {
        if (other == yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.getDefaultInstance()) return this;
        if (!other.getResourcePresetId().isEmpty()) {
          resourcePresetId_ = other.resourcePresetId_;
          onChanged();
        }
        if (other.getDiskSize() != 0L) {
          setDiskSize(other.getDiskSize());
        }
        if (!other.getDiskTypeId().isEmpty()) {
          diskTypeId_ = other.diskTypeId_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private java.lang.Object resourcePresetId_ = "";
      /**
       * <pre>
       * ID of the preset for computational resources available to a host (CPU, memory, etc.).
       * All available presets are listed in the [documentation](/docs/managed-kafka/concepts/instance-types).
       * </pre>
       *
       * <code>string resource_preset_id = 1;</code>
       */
      public java.lang.String getResourcePresetId() {
        java.lang.Object ref = resourcePresetId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          resourcePresetId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of the preset for computational resources available to a host (CPU, memory, etc.).
       * All available presets are listed in the [documentation](/docs/managed-kafka/concepts/instance-types).
       * </pre>
       *
       * <code>string resource_preset_id = 1;</code>
       */
      public com.google.protobuf.ByteString
          getResourcePresetIdBytes() {
        java.lang.Object ref = resourcePresetId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          resourcePresetId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of the preset for computational resources available to a host (CPU, memory, etc.).
       * All available presets are listed in the [documentation](/docs/managed-kafka/concepts/instance-types).
       * </pre>
       *
       * <code>string resource_preset_id = 1;</code>
       */
      public Builder setResourcePresetId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        resourcePresetId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the preset for computational resources available to a host (CPU, memory, etc.).
       * All available presets are listed in the [documentation](/docs/managed-kafka/concepts/instance-types).
       * </pre>
       *
       * <code>string resource_preset_id = 1;</code>
       */
      public Builder clearResourcePresetId() {
        
        resourcePresetId_ = getDefaultInstance().getResourcePresetId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the preset for computational resources available to a host (CPU, memory, etc.).
       * All available presets are listed in the [documentation](/docs/managed-kafka/concepts/instance-types).
       * </pre>
       *
       * <code>string resource_preset_id = 1;</code>
       */
      public Builder setResourcePresetIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        resourcePresetId_ = value;
        onChanged();
        return this;
      }

      private long diskSize_ ;
      /**
       * <pre>
       * Volume of the storage available to a host, in bytes.
       * </pre>
       *
       * <code>int64 disk_size = 2;</code>
       */
      public long getDiskSize() {
        return diskSize_;
      }
      /**
       * <pre>
       * Volume of the storage available to a host, in bytes.
       * </pre>
       *
       * <code>int64 disk_size = 2;</code>
       */
      public Builder setDiskSize(long value) {
        
        diskSize_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Volume of the storage available to a host, in bytes.
       * </pre>
       *
       * <code>int64 disk_size = 2;</code>
       */
      public Builder clearDiskSize() {
        
        diskSize_ = 0L;
        onChanged();
        return this;
      }

      private java.lang.Object diskTypeId_ = "";
      /**
       * <pre>
       * Type of the storage environment for the host.
       * </pre>
       *
       * <code>string disk_type_id = 3;</code>
       */
      public java.lang.String getDiskTypeId() {
        java.lang.Object ref = diskTypeId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          diskTypeId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Type of the storage environment for the host.
       * </pre>
       *
       * <code>string disk_type_id = 3;</code>
       */
      public com.google.protobuf.ByteString
          getDiskTypeIdBytes() {
        java.lang.Object ref = diskTypeId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          diskTypeId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Type of the storage environment for the host.
       * </pre>
       *
       * <code>string disk_type_id = 3;</code>
       */
      public Builder setDiskTypeId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        diskTypeId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Type of the storage environment for the host.
       * </pre>
       *
       * <code>string disk_type_id = 3;</code>
       */
      public Builder clearDiskTypeId() {
        
        diskTypeId_ = getDefaultInstance().getDiskTypeId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Type of the storage environment for the host.
       * </pre>
       *
       * <code>string disk_type_id = 3;</code>
       */
      public Builder setDiskTypeIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        diskTypeId_ = value;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.Resources)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.Resources)
    private static final yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources();
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<Resources>
        PARSER = new com.google.protobuf.AbstractParser<Resources>() {
      @java.lang.Override
      public Resources parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Resources(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<Resources> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Resources> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface KafkaConfig2_1OrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.KafkaConfig2_1)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Cluster topics compression type.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
     */
    int getCompressionTypeValue();
    /**
     * <pre>
     * Cluster topics compression type.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.Common.CompressionType getCompressionType();

    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     */
    boolean hasLogFlushIntervalMessages();
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     */
    com.google.protobuf.Int64Value getLogFlushIntervalMessages();
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMessagesOrBuilder();

    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     */
    boolean hasLogFlushIntervalMs();
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     */
    com.google.protobuf.Int64Value getLogFlushIntervalMs();
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMsOrBuilder();

    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     */
    boolean hasLogFlushSchedulerIntervalMs();
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     */
    com.google.protobuf.Int64Value getLogFlushSchedulerIntervalMs();
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogFlushSchedulerIntervalMsOrBuilder();

    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_1.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     */
    boolean hasLogRetentionBytes();
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_1.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     */
    com.google.protobuf.Int64Value getLogRetentionBytes();
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_1.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogRetentionBytesOrBuilder();

    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     */
    boolean hasLogRetentionHours();
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     */
    com.google.protobuf.Int64Value getLogRetentionHours();
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogRetentionHoursOrBuilder();

    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     */
    boolean hasLogRetentionMinutes();
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     */
    com.google.protobuf.Int64Value getLogRetentionMinutes();
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogRetentionMinutesOrBuilder();

    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     */
    boolean hasLogRetentionMs();
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     */
    com.google.protobuf.Int64Value getLogRetentionMs();
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogRetentionMsOrBuilder();

    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     */
    boolean hasLogSegmentBytes();
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     */
    com.google.protobuf.Int64Value getLogSegmentBytes();
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogSegmentBytesOrBuilder();

    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     */
    boolean hasLogPreallocate();
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     */
    com.google.protobuf.BoolValue getLogPreallocate();
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     */
    com.google.protobuf.BoolValueOrBuilder getLogPreallocateOrBuilder();

    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     */
    boolean hasSocketSendBufferBytes();
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     */
    com.google.protobuf.Int64Value getSocketSendBufferBytes();
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getSocketSendBufferBytesOrBuilder();

    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     */
    boolean hasSocketReceiveBufferBytes();
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     */
    com.google.protobuf.Int64Value getSocketReceiveBufferBytes();
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getSocketReceiveBufferBytesOrBuilder();

    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     */
    boolean hasAutoCreateTopicsEnable();
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     */
    com.google.protobuf.BoolValue getAutoCreateTopicsEnable();
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     */
    com.google.protobuf.BoolValueOrBuilder getAutoCreateTopicsEnableOrBuilder();

    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     */
    boolean hasNumPartitions();
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     */
    com.google.protobuf.Int64Value getNumPartitions();
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getNumPartitionsOrBuilder();

    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     */
    boolean hasDefaultReplicationFactor();
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     */
    com.google.protobuf.Int64Value getDefaultReplicationFactor();
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getDefaultReplicationFactorOrBuilder();
  }
  /**
   * <pre>
   * Kafka version 2.1 broker configuration.
   * </pre>
   *
   * Protobuf type {@code yandex.cloud.mdb.kafka.v1.KafkaConfig2_1}
   */
  public  static final class KafkaConfig2_1 extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.KafkaConfig2_1)
      KafkaConfig2_1OrBuilder {
  private static final long serialVersionUID = 0L;
    // Use KafkaConfig2_1.newBuilder() to construct.
    private KafkaConfig2_1(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private KafkaConfig2_1() {
      compressionType_ = 0;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private KafkaConfig2_1(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              int rawValue = input.readEnum();

              compressionType_ = rawValue;
              break;
            }
            case 18: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logFlushIntervalMessages_ != null) {
                subBuilder = logFlushIntervalMessages_.toBuilder();
              }
              logFlushIntervalMessages_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logFlushIntervalMessages_);
                logFlushIntervalMessages_ = subBuilder.buildPartial();
              }

              break;
            }
            case 26: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logFlushIntervalMs_ != null) {
                subBuilder = logFlushIntervalMs_.toBuilder();
              }
              logFlushIntervalMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logFlushIntervalMs_);
                logFlushIntervalMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 34: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logFlushSchedulerIntervalMs_ != null) {
                subBuilder = logFlushSchedulerIntervalMs_.toBuilder();
              }
              logFlushSchedulerIntervalMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logFlushSchedulerIntervalMs_);
                logFlushSchedulerIntervalMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 42: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logRetentionBytes_ != null) {
                subBuilder = logRetentionBytes_.toBuilder();
              }
              logRetentionBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logRetentionBytes_);
                logRetentionBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 50: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logRetentionHours_ != null) {
                subBuilder = logRetentionHours_.toBuilder();
              }
              logRetentionHours_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logRetentionHours_);
                logRetentionHours_ = subBuilder.buildPartial();
              }

              break;
            }
            case 58: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logRetentionMinutes_ != null) {
                subBuilder = logRetentionMinutes_.toBuilder();
              }
              logRetentionMinutes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logRetentionMinutes_);
                logRetentionMinutes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 66: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logRetentionMs_ != null) {
                subBuilder = logRetentionMs_.toBuilder();
              }
              logRetentionMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logRetentionMs_);
                logRetentionMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 74: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logSegmentBytes_ != null) {
                subBuilder = logSegmentBytes_.toBuilder();
              }
              logSegmentBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logSegmentBytes_);
                logSegmentBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 82: {
              com.google.protobuf.BoolValue.Builder subBuilder = null;
              if (logPreallocate_ != null) {
                subBuilder = logPreallocate_.toBuilder();
              }
              logPreallocate_ = input.readMessage(com.google.protobuf.BoolValue.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logPreallocate_);
                logPreallocate_ = subBuilder.buildPartial();
              }

              break;
            }
            case 90: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (socketSendBufferBytes_ != null) {
                subBuilder = socketSendBufferBytes_.toBuilder();
              }
              socketSendBufferBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(socketSendBufferBytes_);
                socketSendBufferBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 98: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (socketReceiveBufferBytes_ != null) {
                subBuilder = socketReceiveBufferBytes_.toBuilder();
              }
              socketReceiveBufferBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(socketReceiveBufferBytes_);
                socketReceiveBufferBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 106: {
              com.google.protobuf.BoolValue.Builder subBuilder = null;
              if (autoCreateTopicsEnable_ != null) {
                subBuilder = autoCreateTopicsEnable_.toBuilder();
              }
              autoCreateTopicsEnable_ = input.readMessage(com.google.protobuf.BoolValue.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(autoCreateTopicsEnable_);
                autoCreateTopicsEnable_ = subBuilder.buildPartial();
              }

              break;
            }
            case 114: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (numPartitions_ != null) {
                subBuilder = numPartitions_.toBuilder();
              }
              numPartitions_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(numPartitions_);
                numPartitions_ = subBuilder.buildPartial();
              }

              break;
            }
            case 122: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (defaultReplicationFactor_ != null) {
                subBuilder = defaultReplicationFactor_.toBuilder();
              }
              defaultReplicationFactor_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(defaultReplicationFactor_);
                defaultReplicationFactor_ = subBuilder.buildPartial();
              }

              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_1_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_1_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1.Builder.class);
    }

    public static final int COMPRESSION_TYPE_FIELD_NUMBER = 1;
    private int compressionType_;
    /**
     * <pre>
     * Cluster topics compression type.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
     */
    public int getCompressionTypeValue() {
      return compressionType_;
    }
    /**
     * <pre>
     * Cluster topics compression type.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.Common.CompressionType getCompressionType() {
      @SuppressWarnings("deprecation")
      yandex.cloud.api.mdb.kafka.v1.Common.CompressionType result = yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.valueOf(compressionType_);
      return result == null ? yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.UNRECOGNIZED : result;
    }

    public static final int LOG_FLUSH_INTERVAL_MESSAGES_FIELD_NUMBER = 2;
    private com.google.protobuf.Int64Value logFlushIntervalMessages_;
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     */
    public boolean hasLogFlushIntervalMessages() {
      return logFlushIntervalMessages_ != null;
    }
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     */
    public com.google.protobuf.Int64Value getLogFlushIntervalMessages() {
      return logFlushIntervalMessages_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMessages_;
    }
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMessagesOrBuilder() {
      return getLogFlushIntervalMessages();
    }

    public static final int LOG_FLUSH_INTERVAL_MS_FIELD_NUMBER = 3;
    private com.google.protobuf.Int64Value logFlushIntervalMs_;
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     */
    public boolean hasLogFlushIntervalMs() {
      return logFlushIntervalMs_ != null;
    }
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     */
    public com.google.protobuf.Int64Value getLogFlushIntervalMs() {
      return logFlushIntervalMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMs_;
    }
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMsOrBuilder() {
      return getLogFlushIntervalMs();
    }

    public static final int LOG_FLUSH_SCHEDULER_INTERVAL_MS_FIELD_NUMBER = 4;
    private com.google.protobuf.Int64Value logFlushSchedulerIntervalMs_;
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     */
    public boolean hasLogFlushSchedulerIntervalMs() {
      return logFlushSchedulerIntervalMs_ != null;
    }
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     */
    public com.google.protobuf.Int64Value getLogFlushSchedulerIntervalMs() {
      return logFlushSchedulerIntervalMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushSchedulerIntervalMs_;
    }
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getLogFlushSchedulerIntervalMsOrBuilder() {
      return getLogFlushSchedulerIntervalMs();
    }

    public static final int LOG_RETENTION_BYTES_FIELD_NUMBER = 5;
    private com.google.protobuf.Int64Value logRetentionBytes_;
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_1.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     */
    public boolean hasLogRetentionBytes() {
      return logRetentionBytes_ != null;
    }
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_1.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     */
    public com.google.protobuf.Int64Value getLogRetentionBytes() {
      return logRetentionBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionBytes_;
    }
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_1.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getLogRetentionBytesOrBuilder() {
      return getLogRetentionBytes();
    }

    public static final int LOG_RETENTION_HOURS_FIELD_NUMBER = 6;
    private com.google.protobuf.Int64Value logRetentionHours_;
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     */
    public boolean hasLogRetentionHours() {
      return logRetentionHours_ != null;
    }
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     */
    public com.google.protobuf.Int64Value getLogRetentionHours() {
      return logRetentionHours_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionHours_;
    }
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getLogRetentionHoursOrBuilder() {
      return getLogRetentionHours();
    }

    public static final int LOG_RETENTION_MINUTES_FIELD_NUMBER = 7;
    private com.google.protobuf.Int64Value logRetentionMinutes_;
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     */
    public boolean hasLogRetentionMinutes() {
      return logRetentionMinutes_ != null;
    }
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     */
    public com.google.protobuf.Int64Value getLogRetentionMinutes() {
      return logRetentionMinutes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMinutes_;
    }
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getLogRetentionMinutesOrBuilder() {
      return getLogRetentionMinutes();
    }

    public static final int LOG_RETENTION_MS_FIELD_NUMBER = 8;
    private com.google.protobuf.Int64Value logRetentionMs_;
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     */
    public boolean hasLogRetentionMs() {
      return logRetentionMs_ != null;
    }
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     */
    public com.google.protobuf.Int64Value getLogRetentionMs() {
      return logRetentionMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMs_;
    }
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getLogRetentionMsOrBuilder() {
      return getLogRetentionMs();
    }

    public static final int LOG_SEGMENT_BYTES_FIELD_NUMBER = 9;
    private com.google.protobuf.Int64Value logSegmentBytes_;
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     */
    public boolean hasLogSegmentBytes() {
      return logSegmentBytes_ != null;
    }
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     */
    public com.google.protobuf.Int64Value getLogSegmentBytes() {
      return logSegmentBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logSegmentBytes_;
    }
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getLogSegmentBytesOrBuilder() {
      return getLogSegmentBytes();
    }

    public static final int LOG_PREALLOCATE_FIELD_NUMBER = 10;
    private com.google.protobuf.BoolValue logPreallocate_;
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     */
    public boolean hasLogPreallocate() {
      return logPreallocate_ != null;
    }
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     */
    public com.google.protobuf.BoolValue getLogPreallocate() {
      return logPreallocate_ == null ? com.google.protobuf.BoolValue.getDefaultInstance() : logPreallocate_;
    }
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     */
    public com.google.protobuf.BoolValueOrBuilder getLogPreallocateOrBuilder() {
      return getLogPreallocate();
    }

    public static final int SOCKET_SEND_BUFFER_BYTES_FIELD_NUMBER = 11;
    private com.google.protobuf.Int64Value socketSendBufferBytes_;
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     */
    public boolean hasSocketSendBufferBytes() {
      return socketSendBufferBytes_ != null;
    }
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     */
    public com.google.protobuf.Int64Value getSocketSendBufferBytes() {
      return socketSendBufferBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : socketSendBufferBytes_;
    }
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getSocketSendBufferBytesOrBuilder() {
      return getSocketSendBufferBytes();
    }

    public static final int SOCKET_RECEIVE_BUFFER_BYTES_FIELD_NUMBER = 12;
    private com.google.protobuf.Int64Value socketReceiveBufferBytes_;
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     */
    public boolean hasSocketReceiveBufferBytes() {
      return socketReceiveBufferBytes_ != null;
    }
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     */
    public com.google.protobuf.Int64Value getSocketReceiveBufferBytes() {
      return socketReceiveBufferBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : socketReceiveBufferBytes_;
    }
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getSocketReceiveBufferBytesOrBuilder() {
      return getSocketReceiveBufferBytes();
    }

    public static final int AUTO_CREATE_TOPICS_ENABLE_FIELD_NUMBER = 13;
    private com.google.protobuf.BoolValue autoCreateTopicsEnable_;
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     */
    public boolean hasAutoCreateTopicsEnable() {
      return autoCreateTopicsEnable_ != null;
    }
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     */
    public com.google.protobuf.BoolValue getAutoCreateTopicsEnable() {
      return autoCreateTopicsEnable_ == null ? com.google.protobuf.BoolValue.getDefaultInstance() : autoCreateTopicsEnable_;
    }
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     */
    public com.google.protobuf.BoolValueOrBuilder getAutoCreateTopicsEnableOrBuilder() {
      return getAutoCreateTopicsEnable();
    }

    public static final int NUM_PARTITIONS_FIELD_NUMBER = 14;
    private com.google.protobuf.Int64Value numPartitions_;
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     */
    public boolean hasNumPartitions() {
      return numPartitions_ != null;
    }
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     */
    public com.google.protobuf.Int64Value getNumPartitions() {
      return numPartitions_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : numPartitions_;
    }
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getNumPartitionsOrBuilder() {
      return getNumPartitions();
    }

    public static final int DEFAULT_REPLICATION_FACTOR_FIELD_NUMBER = 15;
    private com.google.protobuf.Int64Value defaultReplicationFactor_;
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     */
    public boolean hasDefaultReplicationFactor() {
      return defaultReplicationFactor_ != null;
    }
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     */
    public com.google.protobuf.Int64Value getDefaultReplicationFactor() {
      return defaultReplicationFactor_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : defaultReplicationFactor_;
    }
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getDefaultReplicationFactorOrBuilder() {
      return getDefaultReplicationFactor();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (compressionType_ != yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.COMPRESSION_TYPE_UNSPECIFIED.getNumber()) {
        output.writeEnum(1, compressionType_);
      }
      if (logFlushIntervalMessages_ != null) {
        output.writeMessage(2, getLogFlushIntervalMessages());
      }
      if (logFlushIntervalMs_ != null) {
        output.writeMessage(3, getLogFlushIntervalMs());
      }
      if (logFlushSchedulerIntervalMs_ != null) {
        output.writeMessage(4, getLogFlushSchedulerIntervalMs());
      }
      if (logRetentionBytes_ != null) {
        output.writeMessage(5, getLogRetentionBytes());
      }
      if (logRetentionHours_ != null) {
        output.writeMessage(6, getLogRetentionHours());
      }
      if (logRetentionMinutes_ != null) {
        output.writeMessage(7, getLogRetentionMinutes());
      }
      if (logRetentionMs_ != null) {
        output.writeMessage(8, getLogRetentionMs());
      }
      if (logSegmentBytes_ != null) {
        output.writeMessage(9, getLogSegmentBytes());
      }
      if (logPreallocate_ != null) {
        output.writeMessage(10, getLogPreallocate());
      }
      if (socketSendBufferBytes_ != null) {
        output.writeMessage(11, getSocketSendBufferBytes());
      }
      if (socketReceiveBufferBytes_ != null) {
        output.writeMessage(12, getSocketReceiveBufferBytes());
      }
      if (autoCreateTopicsEnable_ != null) {
        output.writeMessage(13, getAutoCreateTopicsEnable());
      }
      if (numPartitions_ != null) {
        output.writeMessage(14, getNumPartitions());
      }
      if (defaultReplicationFactor_ != null) {
        output.writeMessage(15, getDefaultReplicationFactor());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (compressionType_ != yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.COMPRESSION_TYPE_UNSPECIFIED.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, compressionType_);
      }
      if (logFlushIntervalMessages_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getLogFlushIntervalMessages());
      }
      if (logFlushIntervalMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getLogFlushIntervalMs());
      }
      if (logFlushSchedulerIntervalMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getLogFlushSchedulerIntervalMs());
      }
      if (logRetentionBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getLogRetentionBytes());
      }
      if (logRetentionHours_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, getLogRetentionHours());
      }
      if (logRetentionMinutes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, getLogRetentionMinutes());
      }
      if (logRetentionMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(8, getLogRetentionMs());
      }
      if (logSegmentBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(9, getLogSegmentBytes());
      }
      if (logPreallocate_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(10, getLogPreallocate());
      }
      if (socketSendBufferBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(11, getSocketSendBufferBytes());
      }
      if (socketReceiveBufferBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(12, getSocketReceiveBufferBytes());
      }
      if (autoCreateTopicsEnable_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(13, getAutoCreateTopicsEnable());
      }
      if (numPartitions_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(14, getNumPartitions());
      }
      if (defaultReplicationFactor_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(15, getDefaultReplicationFactor());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1)) {
        return super.equals(obj);
      }
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 other = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1) obj;

      boolean result = true;
      result = result && compressionType_ == other.compressionType_;
      result = result && (hasLogFlushIntervalMessages() == other.hasLogFlushIntervalMessages());
      if (hasLogFlushIntervalMessages()) {
        result = result && getLogFlushIntervalMessages()
            .equals(other.getLogFlushIntervalMessages());
      }
      result = result && (hasLogFlushIntervalMs() == other.hasLogFlushIntervalMs());
      if (hasLogFlushIntervalMs()) {
        result = result && getLogFlushIntervalMs()
            .equals(other.getLogFlushIntervalMs());
      }
      result = result && (hasLogFlushSchedulerIntervalMs() == other.hasLogFlushSchedulerIntervalMs());
      if (hasLogFlushSchedulerIntervalMs()) {
        result = result && getLogFlushSchedulerIntervalMs()
            .equals(other.getLogFlushSchedulerIntervalMs());
      }
      result = result && (hasLogRetentionBytes() == other.hasLogRetentionBytes());
      if (hasLogRetentionBytes()) {
        result = result && getLogRetentionBytes()
            .equals(other.getLogRetentionBytes());
      }
      result = result && (hasLogRetentionHours() == other.hasLogRetentionHours());
      if (hasLogRetentionHours()) {
        result = result && getLogRetentionHours()
            .equals(other.getLogRetentionHours());
      }
      result = result && (hasLogRetentionMinutes() == other.hasLogRetentionMinutes());
      if (hasLogRetentionMinutes()) {
        result = result && getLogRetentionMinutes()
            .equals(other.getLogRetentionMinutes());
      }
      result = result && (hasLogRetentionMs() == other.hasLogRetentionMs());
      if (hasLogRetentionMs()) {
        result = result && getLogRetentionMs()
            .equals(other.getLogRetentionMs());
      }
      result = result && (hasLogSegmentBytes() == other.hasLogSegmentBytes());
      if (hasLogSegmentBytes()) {
        result = result && getLogSegmentBytes()
            .equals(other.getLogSegmentBytes());
      }
      result = result && (hasLogPreallocate() == other.hasLogPreallocate());
      if (hasLogPreallocate()) {
        result = result && getLogPreallocate()
            .equals(other.getLogPreallocate());
      }
      result = result && (hasSocketSendBufferBytes() == other.hasSocketSendBufferBytes());
      if (hasSocketSendBufferBytes()) {
        result = result && getSocketSendBufferBytes()
            .equals(other.getSocketSendBufferBytes());
      }
      result = result && (hasSocketReceiveBufferBytes() == other.hasSocketReceiveBufferBytes());
      if (hasSocketReceiveBufferBytes()) {
        result = result && getSocketReceiveBufferBytes()
            .equals(other.getSocketReceiveBufferBytes());
      }
      result = result && (hasAutoCreateTopicsEnable() == other.hasAutoCreateTopicsEnable());
      if (hasAutoCreateTopicsEnable()) {
        result = result && getAutoCreateTopicsEnable()
            .equals(other.getAutoCreateTopicsEnable());
      }
      result = result && (hasNumPartitions() == other.hasNumPartitions());
      if (hasNumPartitions()) {
        result = result && getNumPartitions()
            .equals(other.getNumPartitions());
      }
      result = result && (hasDefaultReplicationFactor() == other.hasDefaultReplicationFactor());
      if (hasDefaultReplicationFactor()) {
        result = result && getDefaultReplicationFactor()
            .equals(other.getDefaultReplicationFactor());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + COMPRESSION_TYPE_FIELD_NUMBER;
      hash = (53 * hash) + compressionType_;
      if (hasLogFlushIntervalMessages()) {
        hash = (37 * hash) + LOG_FLUSH_INTERVAL_MESSAGES_FIELD_NUMBER;
        hash = (53 * hash) + getLogFlushIntervalMessages().hashCode();
      }
      if (hasLogFlushIntervalMs()) {
        hash = (37 * hash) + LOG_FLUSH_INTERVAL_MS_FIELD_NUMBER;
        hash = (53 * hash) + getLogFlushIntervalMs().hashCode();
      }
      if (hasLogFlushSchedulerIntervalMs()) {
        hash = (37 * hash) + LOG_FLUSH_SCHEDULER_INTERVAL_MS_FIELD_NUMBER;
        hash = (53 * hash) + getLogFlushSchedulerIntervalMs().hashCode();
      }
      if (hasLogRetentionBytes()) {
        hash = (37 * hash) + LOG_RETENTION_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getLogRetentionBytes().hashCode();
      }
      if (hasLogRetentionHours()) {
        hash = (37 * hash) + LOG_RETENTION_HOURS_FIELD_NUMBER;
        hash = (53 * hash) + getLogRetentionHours().hashCode();
      }
      if (hasLogRetentionMinutes()) {
        hash = (37 * hash) + LOG_RETENTION_MINUTES_FIELD_NUMBER;
        hash = (53 * hash) + getLogRetentionMinutes().hashCode();
      }
      if (hasLogRetentionMs()) {
        hash = (37 * hash) + LOG_RETENTION_MS_FIELD_NUMBER;
        hash = (53 * hash) + getLogRetentionMs().hashCode();
      }
      if (hasLogSegmentBytes()) {
        hash = (37 * hash) + LOG_SEGMENT_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getLogSegmentBytes().hashCode();
      }
      if (hasLogPreallocate()) {
        hash = (37 * hash) + LOG_PREALLOCATE_FIELD_NUMBER;
        hash = (53 * hash) + getLogPreallocate().hashCode();
      }
      if (hasSocketSendBufferBytes()) {
        hash = (37 * hash) + SOCKET_SEND_BUFFER_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getSocketSendBufferBytes().hashCode();
      }
      if (hasSocketReceiveBufferBytes()) {
        hash = (37 * hash) + SOCKET_RECEIVE_BUFFER_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getSocketReceiveBufferBytes().hashCode();
      }
      if (hasAutoCreateTopicsEnable()) {
        hash = (37 * hash) + AUTO_CREATE_TOPICS_ENABLE_FIELD_NUMBER;
        hash = (53 * hash) + getAutoCreateTopicsEnable().hashCode();
      }
      if (hasNumPartitions()) {
        hash = (37 * hash) + NUM_PARTITIONS_FIELD_NUMBER;
        hash = (53 * hash) + getNumPartitions().hashCode();
      }
      if (hasDefaultReplicationFactor()) {
        hash = (37 * hash) + DEFAULT_REPLICATION_FACTOR_FIELD_NUMBER;
        hash = (53 * hash) + getDefaultReplicationFactor().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Kafka version 2.1 broker configuration.
     * </pre>
     *
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.KafkaConfig2_1}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.KafkaConfig2_1)
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1OrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_1_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_1_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1.Builder.class);
      }

      // Construct using yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        compressionType_ = 0;

        if (logFlushIntervalMessagesBuilder_ == null) {
          logFlushIntervalMessages_ = null;
        } else {
          logFlushIntervalMessages_ = null;
          logFlushIntervalMessagesBuilder_ = null;
        }
        if (logFlushIntervalMsBuilder_ == null) {
          logFlushIntervalMs_ = null;
        } else {
          logFlushIntervalMs_ = null;
          logFlushIntervalMsBuilder_ = null;
        }
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          logFlushSchedulerIntervalMs_ = null;
        } else {
          logFlushSchedulerIntervalMs_ = null;
          logFlushSchedulerIntervalMsBuilder_ = null;
        }
        if (logRetentionBytesBuilder_ == null) {
          logRetentionBytes_ = null;
        } else {
          logRetentionBytes_ = null;
          logRetentionBytesBuilder_ = null;
        }
        if (logRetentionHoursBuilder_ == null) {
          logRetentionHours_ = null;
        } else {
          logRetentionHours_ = null;
          logRetentionHoursBuilder_ = null;
        }
        if (logRetentionMinutesBuilder_ == null) {
          logRetentionMinutes_ = null;
        } else {
          logRetentionMinutes_ = null;
          logRetentionMinutesBuilder_ = null;
        }
        if (logRetentionMsBuilder_ == null) {
          logRetentionMs_ = null;
        } else {
          logRetentionMs_ = null;
          logRetentionMsBuilder_ = null;
        }
        if (logSegmentBytesBuilder_ == null) {
          logSegmentBytes_ = null;
        } else {
          logSegmentBytes_ = null;
          logSegmentBytesBuilder_ = null;
        }
        if (logPreallocateBuilder_ == null) {
          logPreallocate_ = null;
        } else {
          logPreallocate_ = null;
          logPreallocateBuilder_ = null;
        }
        if (socketSendBufferBytesBuilder_ == null) {
          socketSendBufferBytes_ = null;
        } else {
          socketSendBufferBytes_ = null;
          socketSendBufferBytesBuilder_ = null;
        }
        if (socketReceiveBufferBytesBuilder_ == null) {
          socketReceiveBufferBytes_ = null;
        } else {
          socketReceiveBufferBytes_ = null;
          socketReceiveBufferBytesBuilder_ = null;
        }
        if (autoCreateTopicsEnableBuilder_ == null) {
          autoCreateTopicsEnable_ = null;
        } else {
          autoCreateTopicsEnable_ = null;
          autoCreateTopicsEnableBuilder_ = null;
        }
        if (numPartitionsBuilder_ == null) {
          numPartitions_ = null;
        } else {
          numPartitions_ = null;
          numPartitionsBuilder_ = null;
        }
        if (defaultReplicationFactorBuilder_ == null) {
          defaultReplicationFactor_ = null;
        } else {
          defaultReplicationFactor_ = null;
          defaultReplicationFactorBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_1_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 getDefaultInstanceForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 build() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 buildPartial() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 result = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1(this);
        result.compressionType_ = compressionType_;
        if (logFlushIntervalMessagesBuilder_ == null) {
          result.logFlushIntervalMessages_ = logFlushIntervalMessages_;
        } else {
          result.logFlushIntervalMessages_ = logFlushIntervalMessagesBuilder_.build();
        }
        if (logFlushIntervalMsBuilder_ == null) {
          result.logFlushIntervalMs_ = logFlushIntervalMs_;
        } else {
          result.logFlushIntervalMs_ = logFlushIntervalMsBuilder_.build();
        }
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          result.logFlushSchedulerIntervalMs_ = logFlushSchedulerIntervalMs_;
        } else {
          result.logFlushSchedulerIntervalMs_ = logFlushSchedulerIntervalMsBuilder_.build();
        }
        if (logRetentionBytesBuilder_ == null) {
          result.logRetentionBytes_ = logRetentionBytes_;
        } else {
          result.logRetentionBytes_ = logRetentionBytesBuilder_.build();
        }
        if (logRetentionHoursBuilder_ == null) {
          result.logRetentionHours_ = logRetentionHours_;
        } else {
          result.logRetentionHours_ = logRetentionHoursBuilder_.build();
        }
        if (logRetentionMinutesBuilder_ == null) {
          result.logRetentionMinutes_ = logRetentionMinutes_;
        } else {
          result.logRetentionMinutes_ = logRetentionMinutesBuilder_.build();
        }
        if (logRetentionMsBuilder_ == null) {
          result.logRetentionMs_ = logRetentionMs_;
        } else {
          result.logRetentionMs_ = logRetentionMsBuilder_.build();
        }
        if (logSegmentBytesBuilder_ == null) {
          result.logSegmentBytes_ = logSegmentBytes_;
        } else {
          result.logSegmentBytes_ = logSegmentBytesBuilder_.build();
        }
        if (logPreallocateBuilder_ == null) {
          result.logPreallocate_ = logPreallocate_;
        } else {
          result.logPreallocate_ = logPreallocateBuilder_.build();
        }
        if (socketSendBufferBytesBuilder_ == null) {
          result.socketSendBufferBytes_ = socketSendBufferBytes_;
        } else {
          result.socketSendBufferBytes_ = socketSendBufferBytesBuilder_.build();
        }
        if (socketReceiveBufferBytesBuilder_ == null) {
          result.socketReceiveBufferBytes_ = socketReceiveBufferBytes_;
        } else {
          result.socketReceiveBufferBytes_ = socketReceiveBufferBytesBuilder_.build();
        }
        if (autoCreateTopicsEnableBuilder_ == null) {
          result.autoCreateTopicsEnable_ = autoCreateTopicsEnable_;
        } else {
          result.autoCreateTopicsEnable_ = autoCreateTopicsEnableBuilder_.build();
        }
        if (numPartitionsBuilder_ == null) {
          result.numPartitions_ = numPartitions_;
        } else {
          result.numPartitions_ = numPartitionsBuilder_.build();
        }
        if (defaultReplicationFactorBuilder_ == null) {
          result.defaultReplicationFactor_ = defaultReplicationFactor_;
        } else {
          result.defaultReplicationFactor_ = defaultReplicationFactorBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1) {
          return mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 other) {
        if (other == yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1.getDefaultInstance()) return this;
        if (other.compressionType_ != 0) {
          setCompressionTypeValue(other.getCompressionTypeValue());
        }
        if (other.hasLogFlushIntervalMessages()) {
          mergeLogFlushIntervalMessages(other.getLogFlushIntervalMessages());
        }
        if (other.hasLogFlushIntervalMs()) {
          mergeLogFlushIntervalMs(other.getLogFlushIntervalMs());
        }
        if (other.hasLogFlushSchedulerIntervalMs()) {
          mergeLogFlushSchedulerIntervalMs(other.getLogFlushSchedulerIntervalMs());
        }
        if (other.hasLogRetentionBytes()) {
          mergeLogRetentionBytes(other.getLogRetentionBytes());
        }
        if (other.hasLogRetentionHours()) {
          mergeLogRetentionHours(other.getLogRetentionHours());
        }
        if (other.hasLogRetentionMinutes()) {
          mergeLogRetentionMinutes(other.getLogRetentionMinutes());
        }
        if (other.hasLogRetentionMs()) {
          mergeLogRetentionMs(other.getLogRetentionMs());
        }
        if (other.hasLogSegmentBytes()) {
          mergeLogSegmentBytes(other.getLogSegmentBytes());
        }
        if (other.hasLogPreallocate()) {
          mergeLogPreallocate(other.getLogPreallocate());
        }
        if (other.hasSocketSendBufferBytes()) {
          mergeSocketSendBufferBytes(other.getSocketSendBufferBytes());
        }
        if (other.hasSocketReceiveBufferBytes()) {
          mergeSocketReceiveBufferBytes(other.getSocketReceiveBufferBytes());
        }
        if (other.hasAutoCreateTopicsEnable()) {
          mergeAutoCreateTopicsEnable(other.getAutoCreateTopicsEnable());
        }
        if (other.hasNumPartitions()) {
          mergeNumPartitions(other.getNumPartitions());
        }
        if (other.hasDefaultReplicationFactor()) {
          mergeDefaultReplicationFactor(other.getDefaultReplicationFactor());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private int compressionType_ = 0;
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       */
      public int getCompressionTypeValue() {
        return compressionType_;
      }
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       */
      public Builder setCompressionTypeValue(int value) {
        compressionType_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.Common.CompressionType getCompressionType() {
        @SuppressWarnings("deprecation")
        yandex.cloud.api.mdb.kafka.v1.Common.CompressionType result = yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.valueOf(compressionType_);
        return result == null ? yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       */
      public Builder setCompressionType(yandex.cloud.api.mdb.kafka.v1.Common.CompressionType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        
        compressionType_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       */
      public Builder clearCompressionType() {
        
        compressionType_ = 0;
        onChanged();
        return this;
      }

      private com.google.protobuf.Int64Value logFlushIntervalMessages_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logFlushIntervalMessagesBuilder_;
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public boolean hasLogFlushIntervalMessages() {
        return logFlushIntervalMessagesBuilder_ != null || logFlushIntervalMessages_ != null;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public com.google.protobuf.Int64Value getLogFlushIntervalMessages() {
        if (logFlushIntervalMessagesBuilder_ == null) {
          return logFlushIntervalMessages_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMessages_;
        } else {
          return logFlushIntervalMessagesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public Builder setLogFlushIntervalMessages(com.google.protobuf.Int64Value value) {
        if (logFlushIntervalMessagesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logFlushIntervalMessages_ = value;
          onChanged();
        } else {
          logFlushIntervalMessagesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public Builder setLogFlushIntervalMessages(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logFlushIntervalMessagesBuilder_ == null) {
          logFlushIntervalMessages_ = builderForValue.build();
          onChanged();
        } else {
          logFlushIntervalMessagesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public Builder mergeLogFlushIntervalMessages(com.google.protobuf.Int64Value value) {
        if (logFlushIntervalMessagesBuilder_ == null) {
          if (logFlushIntervalMessages_ != null) {
            logFlushIntervalMessages_ =
              com.google.protobuf.Int64Value.newBuilder(logFlushIntervalMessages_).mergeFrom(value).buildPartial();
          } else {
            logFlushIntervalMessages_ = value;
          }
          onChanged();
        } else {
          logFlushIntervalMessagesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public Builder clearLogFlushIntervalMessages() {
        if (logFlushIntervalMessagesBuilder_ == null) {
          logFlushIntervalMessages_ = null;
          onChanged();
        } else {
          logFlushIntervalMessages_ = null;
          logFlushIntervalMessagesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogFlushIntervalMessagesBuilder() {
        
        onChanged();
        return getLogFlushIntervalMessagesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMessagesOrBuilder() {
        if (logFlushIntervalMessagesBuilder_ != null) {
          return logFlushIntervalMessagesBuilder_.getMessageOrBuilder();
        } else {
          return logFlushIntervalMessages_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMessages_;
        }
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogFlushIntervalMessagesFieldBuilder() {
        if (logFlushIntervalMessagesBuilder_ == null) {
          logFlushIntervalMessagesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogFlushIntervalMessages(),
                  getParentForChildren(),
                  isClean());
          logFlushIntervalMessages_ = null;
        }
        return logFlushIntervalMessagesBuilder_;
      }

      private com.google.protobuf.Int64Value logFlushIntervalMs_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logFlushIntervalMsBuilder_;
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public boolean hasLogFlushIntervalMs() {
        return logFlushIntervalMsBuilder_ != null || logFlushIntervalMs_ != null;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public com.google.protobuf.Int64Value getLogFlushIntervalMs() {
        if (logFlushIntervalMsBuilder_ == null) {
          return logFlushIntervalMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMs_;
        } else {
          return logFlushIntervalMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public Builder setLogFlushIntervalMs(com.google.protobuf.Int64Value value) {
        if (logFlushIntervalMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logFlushIntervalMs_ = value;
          onChanged();
        } else {
          logFlushIntervalMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public Builder setLogFlushIntervalMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logFlushIntervalMsBuilder_ == null) {
          logFlushIntervalMs_ = builderForValue.build();
          onChanged();
        } else {
          logFlushIntervalMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public Builder mergeLogFlushIntervalMs(com.google.protobuf.Int64Value value) {
        if (logFlushIntervalMsBuilder_ == null) {
          if (logFlushIntervalMs_ != null) {
            logFlushIntervalMs_ =
              com.google.protobuf.Int64Value.newBuilder(logFlushIntervalMs_).mergeFrom(value).buildPartial();
          } else {
            logFlushIntervalMs_ = value;
          }
          onChanged();
        } else {
          logFlushIntervalMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public Builder clearLogFlushIntervalMs() {
        if (logFlushIntervalMsBuilder_ == null) {
          logFlushIntervalMs_ = null;
          onChanged();
        } else {
          logFlushIntervalMs_ = null;
          logFlushIntervalMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogFlushIntervalMsBuilder() {
        
        onChanged();
        return getLogFlushIntervalMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMsOrBuilder() {
        if (logFlushIntervalMsBuilder_ != null) {
          return logFlushIntervalMsBuilder_.getMessageOrBuilder();
        } else {
          return logFlushIntervalMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMs_;
        }
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogFlushIntervalMsFieldBuilder() {
        if (logFlushIntervalMsBuilder_ == null) {
          logFlushIntervalMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogFlushIntervalMs(),
                  getParentForChildren(),
                  isClean());
          logFlushIntervalMs_ = null;
        }
        return logFlushIntervalMsBuilder_;
      }

      private com.google.protobuf.Int64Value logFlushSchedulerIntervalMs_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logFlushSchedulerIntervalMsBuilder_;
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public boolean hasLogFlushSchedulerIntervalMs() {
        return logFlushSchedulerIntervalMsBuilder_ != null || logFlushSchedulerIntervalMs_ != null;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public com.google.protobuf.Int64Value getLogFlushSchedulerIntervalMs() {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          return logFlushSchedulerIntervalMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushSchedulerIntervalMs_;
        } else {
          return logFlushSchedulerIntervalMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public Builder setLogFlushSchedulerIntervalMs(com.google.protobuf.Int64Value value) {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logFlushSchedulerIntervalMs_ = value;
          onChanged();
        } else {
          logFlushSchedulerIntervalMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public Builder setLogFlushSchedulerIntervalMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          logFlushSchedulerIntervalMs_ = builderForValue.build();
          onChanged();
        } else {
          logFlushSchedulerIntervalMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public Builder mergeLogFlushSchedulerIntervalMs(com.google.protobuf.Int64Value value) {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          if (logFlushSchedulerIntervalMs_ != null) {
            logFlushSchedulerIntervalMs_ =
              com.google.protobuf.Int64Value.newBuilder(logFlushSchedulerIntervalMs_).mergeFrom(value).buildPartial();
          } else {
            logFlushSchedulerIntervalMs_ = value;
          }
          onChanged();
        } else {
          logFlushSchedulerIntervalMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public Builder clearLogFlushSchedulerIntervalMs() {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          logFlushSchedulerIntervalMs_ = null;
          onChanged();
        } else {
          logFlushSchedulerIntervalMs_ = null;
          logFlushSchedulerIntervalMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogFlushSchedulerIntervalMsBuilder() {
        
        onChanged();
        return getLogFlushSchedulerIntervalMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogFlushSchedulerIntervalMsOrBuilder() {
        if (logFlushSchedulerIntervalMsBuilder_ != null) {
          return logFlushSchedulerIntervalMsBuilder_.getMessageOrBuilder();
        } else {
          return logFlushSchedulerIntervalMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logFlushSchedulerIntervalMs_;
        }
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogFlushSchedulerIntervalMsFieldBuilder() {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          logFlushSchedulerIntervalMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogFlushSchedulerIntervalMs(),
                  getParentForChildren(),
                  isClean());
          logFlushSchedulerIntervalMs_ = null;
        }
        return logFlushSchedulerIntervalMsBuilder_;
      }

      private com.google.protobuf.Int64Value logRetentionBytes_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logRetentionBytesBuilder_;
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_1.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public boolean hasLogRetentionBytes() {
        return logRetentionBytesBuilder_ != null || logRetentionBytes_ != null;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_1.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public com.google.protobuf.Int64Value getLogRetentionBytes() {
        if (logRetentionBytesBuilder_ == null) {
          return logRetentionBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionBytes_;
        } else {
          return logRetentionBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_1.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public Builder setLogRetentionBytes(com.google.protobuf.Int64Value value) {
        if (logRetentionBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logRetentionBytes_ = value;
          onChanged();
        } else {
          logRetentionBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_1.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public Builder setLogRetentionBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logRetentionBytesBuilder_ == null) {
          logRetentionBytes_ = builderForValue.build();
          onChanged();
        } else {
          logRetentionBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_1.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public Builder mergeLogRetentionBytes(com.google.protobuf.Int64Value value) {
        if (logRetentionBytesBuilder_ == null) {
          if (logRetentionBytes_ != null) {
            logRetentionBytes_ =
              com.google.protobuf.Int64Value.newBuilder(logRetentionBytes_).mergeFrom(value).buildPartial();
          } else {
            logRetentionBytes_ = value;
          }
          onChanged();
        } else {
          logRetentionBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_1.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public Builder clearLogRetentionBytes() {
        if (logRetentionBytesBuilder_ == null) {
          logRetentionBytes_ = null;
          onChanged();
        } else {
          logRetentionBytes_ = null;
          logRetentionBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_1.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogRetentionBytesBuilder() {
        
        onChanged();
        return getLogRetentionBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_1.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogRetentionBytesOrBuilder() {
        if (logRetentionBytesBuilder_ != null) {
          return logRetentionBytesBuilder_.getMessageOrBuilder();
        } else {
          return logRetentionBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionBytes_;
        }
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_1.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogRetentionBytesFieldBuilder() {
        if (logRetentionBytesBuilder_ == null) {
          logRetentionBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogRetentionBytes(),
                  getParentForChildren(),
                  isClean());
          logRetentionBytes_ = null;
        }
        return logRetentionBytesBuilder_;
      }

      private com.google.protobuf.Int64Value logRetentionHours_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logRetentionHoursBuilder_;
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public boolean hasLogRetentionHours() {
        return logRetentionHoursBuilder_ != null || logRetentionHours_ != null;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public com.google.protobuf.Int64Value getLogRetentionHours() {
        if (logRetentionHoursBuilder_ == null) {
          return logRetentionHours_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionHours_;
        } else {
          return logRetentionHoursBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public Builder setLogRetentionHours(com.google.protobuf.Int64Value value) {
        if (logRetentionHoursBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logRetentionHours_ = value;
          onChanged();
        } else {
          logRetentionHoursBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public Builder setLogRetentionHours(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logRetentionHoursBuilder_ == null) {
          logRetentionHours_ = builderForValue.build();
          onChanged();
        } else {
          logRetentionHoursBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public Builder mergeLogRetentionHours(com.google.protobuf.Int64Value value) {
        if (logRetentionHoursBuilder_ == null) {
          if (logRetentionHours_ != null) {
            logRetentionHours_ =
              com.google.protobuf.Int64Value.newBuilder(logRetentionHours_).mergeFrom(value).buildPartial();
          } else {
            logRetentionHours_ = value;
          }
          onChanged();
        } else {
          logRetentionHoursBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public Builder clearLogRetentionHours() {
        if (logRetentionHoursBuilder_ == null) {
          logRetentionHours_ = null;
          onChanged();
        } else {
          logRetentionHours_ = null;
          logRetentionHoursBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogRetentionHoursBuilder() {
        
        onChanged();
        return getLogRetentionHoursFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogRetentionHoursOrBuilder() {
        if (logRetentionHoursBuilder_ != null) {
          return logRetentionHoursBuilder_.getMessageOrBuilder();
        } else {
          return logRetentionHours_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionHours_;
        }
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogRetentionHoursFieldBuilder() {
        if (logRetentionHoursBuilder_ == null) {
          logRetentionHoursBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogRetentionHours(),
                  getParentForChildren(),
                  isClean());
          logRetentionHours_ = null;
        }
        return logRetentionHoursBuilder_;
      }

      private com.google.protobuf.Int64Value logRetentionMinutes_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logRetentionMinutesBuilder_;
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public boolean hasLogRetentionMinutes() {
        return logRetentionMinutesBuilder_ != null || logRetentionMinutes_ != null;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public com.google.protobuf.Int64Value getLogRetentionMinutes() {
        if (logRetentionMinutesBuilder_ == null) {
          return logRetentionMinutes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMinutes_;
        } else {
          return logRetentionMinutesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public Builder setLogRetentionMinutes(com.google.protobuf.Int64Value value) {
        if (logRetentionMinutesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logRetentionMinutes_ = value;
          onChanged();
        } else {
          logRetentionMinutesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public Builder setLogRetentionMinutes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logRetentionMinutesBuilder_ == null) {
          logRetentionMinutes_ = builderForValue.build();
          onChanged();
        } else {
          logRetentionMinutesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public Builder mergeLogRetentionMinutes(com.google.protobuf.Int64Value value) {
        if (logRetentionMinutesBuilder_ == null) {
          if (logRetentionMinutes_ != null) {
            logRetentionMinutes_ =
              com.google.protobuf.Int64Value.newBuilder(logRetentionMinutes_).mergeFrom(value).buildPartial();
          } else {
            logRetentionMinutes_ = value;
          }
          onChanged();
        } else {
          logRetentionMinutesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public Builder clearLogRetentionMinutes() {
        if (logRetentionMinutesBuilder_ == null) {
          logRetentionMinutes_ = null;
          onChanged();
        } else {
          logRetentionMinutes_ = null;
          logRetentionMinutesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogRetentionMinutesBuilder() {
        
        onChanged();
        return getLogRetentionMinutesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogRetentionMinutesOrBuilder() {
        if (logRetentionMinutesBuilder_ != null) {
          return logRetentionMinutesBuilder_.getMessageOrBuilder();
        } else {
          return logRetentionMinutes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMinutes_;
        }
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogRetentionMinutesFieldBuilder() {
        if (logRetentionMinutesBuilder_ == null) {
          logRetentionMinutesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogRetentionMinutes(),
                  getParentForChildren(),
                  isClean());
          logRetentionMinutes_ = null;
        }
        return logRetentionMinutesBuilder_;
      }

      private com.google.protobuf.Int64Value logRetentionMs_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logRetentionMsBuilder_;
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public boolean hasLogRetentionMs() {
        return logRetentionMsBuilder_ != null || logRetentionMs_ != null;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public com.google.protobuf.Int64Value getLogRetentionMs() {
        if (logRetentionMsBuilder_ == null) {
          return logRetentionMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMs_;
        } else {
          return logRetentionMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public Builder setLogRetentionMs(com.google.protobuf.Int64Value value) {
        if (logRetentionMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logRetentionMs_ = value;
          onChanged();
        } else {
          logRetentionMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public Builder setLogRetentionMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logRetentionMsBuilder_ == null) {
          logRetentionMs_ = builderForValue.build();
          onChanged();
        } else {
          logRetentionMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public Builder mergeLogRetentionMs(com.google.protobuf.Int64Value value) {
        if (logRetentionMsBuilder_ == null) {
          if (logRetentionMs_ != null) {
            logRetentionMs_ =
              com.google.protobuf.Int64Value.newBuilder(logRetentionMs_).mergeFrom(value).buildPartial();
          } else {
            logRetentionMs_ = value;
          }
          onChanged();
        } else {
          logRetentionMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public Builder clearLogRetentionMs() {
        if (logRetentionMsBuilder_ == null) {
          logRetentionMs_ = null;
          onChanged();
        } else {
          logRetentionMs_ = null;
          logRetentionMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogRetentionMsBuilder() {
        
        onChanged();
        return getLogRetentionMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogRetentionMsOrBuilder() {
        if (logRetentionMsBuilder_ != null) {
          return logRetentionMsBuilder_.getMessageOrBuilder();
        } else {
          return logRetentionMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMs_;
        }
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogRetentionMsFieldBuilder() {
        if (logRetentionMsBuilder_ == null) {
          logRetentionMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogRetentionMs(),
                  getParentForChildren(),
                  isClean());
          logRetentionMs_ = null;
        }
        return logRetentionMsBuilder_;
      }

      private com.google.protobuf.Int64Value logSegmentBytes_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logSegmentBytesBuilder_;
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public boolean hasLogSegmentBytes() {
        return logSegmentBytesBuilder_ != null || logSegmentBytes_ != null;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public com.google.protobuf.Int64Value getLogSegmentBytes() {
        if (logSegmentBytesBuilder_ == null) {
          return logSegmentBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logSegmentBytes_;
        } else {
          return logSegmentBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public Builder setLogSegmentBytes(com.google.protobuf.Int64Value value) {
        if (logSegmentBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logSegmentBytes_ = value;
          onChanged();
        } else {
          logSegmentBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public Builder setLogSegmentBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logSegmentBytesBuilder_ == null) {
          logSegmentBytes_ = builderForValue.build();
          onChanged();
        } else {
          logSegmentBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public Builder mergeLogSegmentBytes(com.google.protobuf.Int64Value value) {
        if (logSegmentBytesBuilder_ == null) {
          if (logSegmentBytes_ != null) {
            logSegmentBytes_ =
              com.google.protobuf.Int64Value.newBuilder(logSegmentBytes_).mergeFrom(value).buildPartial();
          } else {
            logSegmentBytes_ = value;
          }
          onChanged();
        } else {
          logSegmentBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public Builder clearLogSegmentBytes() {
        if (logSegmentBytesBuilder_ == null) {
          logSegmentBytes_ = null;
          onChanged();
        } else {
          logSegmentBytes_ = null;
          logSegmentBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogSegmentBytesBuilder() {
        
        onChanged();
        return getLogSegmentBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogSegmentBytesOrBuilder() {
        if (logSegmentBytesBuilder_ != null) {
          return logSegmentBytesBuilder_.getMessageOrBuilder();
        } else {
          return logSegmentBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logSegmentBytes_;
        }
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogSegmentBytesFieldBuilder() {
        if (logSegmentBytesBuilder_ == null) {
          logSegmentBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogSegmentBytes(),
                  getParentForChildren(),
                  isClean());
          logSegmentBytes_ = null;
        }
        return logSegmentBytesBuilder_;
      }

      private com.google.protobuf.BoolValue logPreallocate_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder> logPreallocateBuilder_;
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public boolean hasLogPreallocate() {
        return logPreallocateBuilder_ != null || logPreallocate_ != null;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public com.google.protobuf.BoolValue getLogPreallocate() {
        if (logPreallocateBuilder_ == null) {
          return logPreallocate_ == null ? com.google.protobuf.BoolValue.getDefaultInstance() : logPreallocate_;
        } else {
          return logPreallocateBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public Builder setLogPreallocate(com.google.protobuf.BoolValue value) {
        if (logPreallocateBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logPreallocate_ = value;
          onChanged();
        } else {
          logPreallocateBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public Builder setLogPreallocate(
          com.google.protobuf.BoolValue.Builder builderForValue) {
        if (logPreallocateBuilder_ == null) {
          logPreallocate_ = builderForValue.build();
          onChanged();
        } else {
          logPreallocateBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public Builder mergeLogPreallocate(com.google.protobuf.BoolValue value) {
        if (logPreallocateBuilder_ == null) {
          if (logPreallocate_ != null) {
            logPreallocate_ =
              com.google.protobuf.BoolValue.newBuilder(logPreallocate_).mergeFrom(value).buildPartial();
          } else {
            logPreallocate_ = value;
          }
          onChanged();
        } else {
          logPreallocateBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public Builder clearLogPreallocate() {
        if (logPreallocateBuilder_ == null) {
          logPreallocate_ = null;
          onChanged();
        } else {
          logPreallocate_ = null;
          logPreallocateBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public com.google.protobuf.BoolValue.Builder getLogPreallocateBuilder() {
        
        onChanged();
        return getLogPreallocateFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public com.google.protobuf.BoolValueOrBuilder getLogPreallocateOrBuilder() {
        if (logPreallocateBuilder_ != null) {
          return logPreallocateBuilder_.getMessageOrBuilder();
        } else {
          return logPreallocate_ == null ?
              com.google.protobuf.BoolValue.getDefaultInstance() : logPreallocate_;
        }
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_1.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder> 
          getLogPreallocateFieldBuilder() {
        if (logPreallocateBuilder_ == null) {
          logPreallocateBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder>(
                  getLogPreallocate(),
                  getParentForChildren(),
                  isClean());
          logPreallocate_ = null;
        }
        return logPreallocateBuilder_;
      }

      private com.google.protobuf.Int64Value socketSendBufferBytes_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> socketSendBufferBytesBuilder_;
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public boolean hasSocketSendBufferBytes() {
        return socketSendBufferBytesBuilder_ != null || socketSendBufferBytes_ != null;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public com.google.protobuf.Int64Value getSocketSendBufferBytes() {
        if (socketSendBufferBytesBuilder_ == null) {
          return socketSendBufferBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : socketSendBufferBytes_;
        } else {
          return socketSendBufferBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public Builder setSocketSendBufferBytes(com.google.protobuf.Int64Value value) {
        if (socketSendBufferBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          socketSendBufferBytes_ = value;
          onChanged();
        } else {
          socketSendBufferBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public Builder setSocketSendBufferBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (socketSendBufferBytesBuilder_ == null) {
          socketSendBufferBytes_ = builderForValue.build();
          onChanged();
        } else {
          socketSendBufferBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public Builder mergeSocketSendBufferBytes(com.google.protobuf.Int64Value value) {
        if (socketSendBufferBytesBuilder_ == null) {
          if (socketSendBufferBytes_ != null) {
            socketSendBufferBytes_ =
              com.google.protobuf.Int64Value.newBuilder(socketSendBufferBytes_).mergeFrom(value).buildPartial();
          } else {
            socketSendBufferBytes_ = value;
          }
          onChanged();
        } else {
          socketSendBufferBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public Builder clearSocketSendBufferBytes() {
        if (socketSendBufferBytesBuilder_ == null) {
          socketSendBufferBytes_ = null;
          onChanged();
        } else {
          socketSendBufferBytes_ = null;
          socketSendBufferBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public com.google.protobuf.Int64Value.Builder getSocketSendBufferBytesBuilder() {
        
        onChanged();
        return getSocketSendBufferBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getSocketSendBufferBytesOrBuilder() {
        if (socketSendBufferBytesBuilder_ != null) {
          return socketSendBufferBytesBuilder_.getMessageOrBuilder();
        } else {
          return socketSendBufferBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : socketSendBufferBytes_;
        }
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getSocketSendBufferBytesFieldBuilder() {
        if (socketSendBufferBytesBuilder_ == null) {
          socketSendBufferBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getSocketSendBufferBytes(),
                  getParentForChildren(),
                  isClean());
          socketSendBufferBytes_ = null;
        }
        return socketSendBufferBytesBuilder_;
      }

      private com.google.protobuf.Int64Value socketReceiveBufferBytes_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> socketReceiveBufferBytesBuilder_;
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public boolean hasSocketReceiveBufferBytes() {
        return socketReceiveBufferBytesBuilder_ != null || socketReceiveBufferBytes_ != null;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public com.google.protobuf.Int64Value getSocketReceiveBufferBytes() {
        if (socketReceiveBufferBytesBuilder_ == null) {
          return socketReceiveBufferBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : socketReceiveBufferBytes_;
        } else {
          return socketReceiveBufferBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public Builder setSocketReceiveBufferBytes(com.google.protobuf.Int64Value value) {
        if (socketReceiveBufferBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          socketReceiveBufferBytes_ = value;
          onChanged();
        } else {
          socketReceiveBufferBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public Builder setSocketReceiveBufferBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (socketReceiveBufferBytesBuilder_ == null) {
          socketReceiveBufferBytes_ = builderForValue.build();
          onChanged();
        } else {
          socketReceiveBufferBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public Builder mergeSocketReceiveBufferBytes(com.google.protobuf.Int64Value value) {
        if (socketReceiveBufferBytesBuilder_ == null) {
          if (socketReceiveBufferBytes_ != null) {
            socketReceiveBufferBytes_ =
              com.google.protobuf.Int64Value.newBuilder(socketReceiveBufferBytes_).mergeFrom(value).buildPartial();
          } else {
            socketReceiveBufferBytes_ = value;
          }
          onChanged();
        } else {
          socketReceiveBufferBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public Builder clearSocketReceiveBufferBytes() {
        if (socketReceiveBufferBytesBuilder_ == null) {
          socketReceiveBufferBytes_ = null;
          onChanged();
        } else {
          socketReceiveBufferBytes_ = null;
          socketReceiveBufferBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public com.google.protobuf.Int64Value.Builder getSocketReceiveBufferBytesBuilder() {
        
        onChanged();
        return getSocketReceiveBufferBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getSocketReceiveBufferBytesOrBuilder() {
        if (socketReceiveBufferBytesBuilder_ != null) {
          return socketReceiveBufferBytesBuilder_.getMessageOrBuilder();
        } else {
          return socketReceiveBufferBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : socketReceiveBufferBytes_;
        }
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getSocketReceiveBufferBytesFieldBuilder() {
        if (socketReceiveBufferBytesBuilder_ == null) {
          socketReceiveBufferBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getSocketReceiveBufferBytes(),
                  getParentForChildren(),
                  isClean());
          socketReceiveBufferBytes_ = null;
        }
        return socketReceiveBufferBytesBuilder_;
      }

      private com.google.protobuf.BoolValue autoCreateTopicsEnable_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder> autoCreateTopicsEnableBuilder_;
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public boolean hasAutoCreateTopicsEnable() {
        return autoCreateTopicsEnableBuilder_ != null || autoCreateTopicsEnable_ != null;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public com.google.protobuf.BoolValue getAutoCreateTopicsEnable() {
        if (autoCreateTopicsEnableBuilder_ == null) {
          return autoCreateTopicsEnable_ == null ? com.google.protobuf.BoolValue.getDefaultInstance() : autoCreateTopicsEnable_;
        } else {
          return autoCreateTopicsEnableBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public Builder setAutoCreateTopicsEnable(com.google.protobuf.BoolValue value) {
        if (autoCreateTopicsEnableBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          autoCreateTopicsEnable_ = value;
          onChanged();
        } else {
          autoCreateTopicsEnableBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public Builder setAutoCreateTopicsEnable(
          com.google.protobuf.BoolValue.Builder builderForValue) {
        if (autoCreateTopicsEnableBuilder_ == null) {
          autoCreateTopicsEnable_ = builderForValue.build();
          onChanged();
        } else {
          autoCreateTopicsEnableBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public Builder mergeAutoCreateTopicsEnable(com.google.protobuf.BoolValue value) {
        if (autoCreateTopicsEnableBuilder_ == null) {
          if (autoCreateTopicsEnable_ != null) {
            autoCreateTopicsEnable_ =
              com.google.protobuf.BoolValue.newBuilder(autoCreateTopicsEnable_).mergeFrom(value).buildPartial();
          } else {
            autoCreateTopicsEnable_ = value;
          }
          onChanged();
        } else {
          autoCreateTopicsEnableBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public Builder clearAutoCreateTopicsEnable() {
        if (autoCreateTopicsEnableBuilder_ == null) {
          autoCreateTopicsEnable_ = null;
          onChanged();
        } else {
          autoCreateTopicsEnable_ = null;
          autoCreateTopicsEnableBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public com.google.protobuf.BoolValue.Builder getAutoCreateTopicsEnableBuilder() {
        
        onChanged();
        return getAutoCreateTopicsEnableFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public com.google.protobuf.BoolValueOrBuilder getAutoCreateTopicsEnableOrBuilder() {
        if (autoCreateTopicsEnableBuilder_ != null) {
          return autoCreateTopicsEnableBuilder_.getMessageOrBuilder();
        } else {
          return autoCreateTopicsEnable_ == null ?
              com.google.protobuf.BoolValue.getDefaultInstance() : autoCreateTopicsEnable_;
        }
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder> 
          getAutoCreateTopicsEnableFieldBuilder() {
        if (autoCreateTopicsEnableBuilder_ == null) {
          autoCreateTopicsEnableBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder>(
                  getAutoCreateTopicsEnable(),
                  getParentForChildren(),
                  isClean());
          autoCreateTopicsEnable_ = null;
        }
        return autoCreateTopicsEnableBuilder_;
      }

      private com.google.protobuf.Int64Value numPartitions_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> numPartitionsBuilder_;
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public boolean hasNumPartitions() {
        return numPartitionsBuilder_ != null || numPartitions_ != null;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public com.google.protobuf.Int64Value getNumPartitions() {
        if (numPartitionsBuilder_ == null) {
          return numPartitions_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : numPartitions_;
        } else {
          return numPartitionsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public Builder setNumPartitions(com.google.protobuf.Int64Value value) {
        if (numPartitionsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          numPartitions_ = value;
          onChanged();
        } else {
          numPartitionsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public Builder setNumPartitions(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (numPartitionsBuilder_ == null) {
          numPartitions_ = builderForValue.build();
          onChanged();
        } else {
          numPartitionsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public Builder mergeNumPartitions(com.google.protobuf.Int64Value value) {
        if (numPartitionsBuilder_ == null) {
          if (numPartitions_ != null) {
            numPartitions_ =
              com.google.protobuf.Int64Value.newBuilder(numPartitions_).mergeFrom(value).buildPartial();
          } else {
            numPartitions_ = value;
          }
          onChanged();
        } else {
          numPartitionsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public Builder clearNumPartitions() {
        if (numPartitionsBuilder_ == null) {
          numPartitions_ = null;
          onChanged();
        } else {
          numPartitions_ = null;
          numPartitionsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public com.google.protobuf.Int64Value.Builder getNumPartitionsBuilder() {
        
        onChanged();
        return getNumPartitionsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getNumPartitionsOrBuilder() {
        if (numPartitionsBuilder_ != null) {
          return numPartitionsBuilder_.getMessageOrBuilder();
        } else {
          return numPartitions_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : numPartitions_;
        }
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getNumPartitionsFieldBuilder() {
        if (numPartitionsBuilder_ == null) {
          numPartitionsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getNumPartitions(),
                  getParentForChildren(),
                  isClean());
          numPartitions_ = null;
        }
        return numPartitionsBuilder_;
      }

      private com.google.protobuf.Int64Value defaultReplicationFactor_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> defaultReplicationFactorBuilder_;
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public boolean hasDefaultReplicationFactor() {
        return defaultReplicationFactorBuilder_ != null || defaultReplicationFactor_ != null;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public com.google.protobuf.Int64Value getDefaultReplicationFactor() {
        if (defaultReplicationFactorBuilder_ == null) {
          return defaultReplicationFactor_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : defaultReplicationFactor_;
        } else {
          return defaultReplicationFactorBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public Builder setDefaultReplicationFactor(com.google.protobuf.Int64Value value) {
        if (defaultReplicationFactorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          defaultReplicationFactor_ = value;
          onChanged();
        } else {
          defaultReplicationFactorBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public Builder setDefaultReplicationFactor(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (defaultReplicationFactorBuilder_ == null) {
          defaultReplicationFactor_ = builderForValue.build();
          onChanged();
        } else {
          defaultReplicationFactorBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public Builder mergeDefaultReplicationFactor(com.google.protobuf.Int64Value value) {
        if (defaultReplicationFactorBuilder_ == null) {
          if (defaultReplicationFactor_ != null) {
            defaultReplicationFactor_ =
              com.google.protobuf.Int64Value.newBuilder(defaultReplicationFactor_).mergeFrom(value).buildPartial();
          } else {
            defaultReplicationFactor_ = value;
          }
          onChanged();
        } else {
          defaultReplicationFactorBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public Builder clearDefaultReplicationFactor() {
        if (defaultReplicationFactorBuilder_ == null) {
          defaultReplicationFactor_ = null;
          onChanged();
        } else {
          defaultReplicationFactor_ = null;
          defaultReplicationFactorBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public com.google.protobuf.Int64Value.Builder getDefaultReplicationFactorBuilder() {
        
        onChanged();
        return getDefaultReplicationFactorFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getDefaultReplicationFactorOrBuilder() {
        if (defaultReplicationFactorBuilder_ != null) {
          return defaultReplicationFactorBuilder_.getMessageOrBuilder();
        } else {
          return defaultReplicationFactor_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : defaultReplicationFactor_;
        }
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getDefaultReplicationFactorFieldBuilder() {
        if (defaultReplicationFactorBuilder_ == null) {
          defaultReplicationFactorBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getDefaultReplicationFactor(),
                  getParentForChildren(),
                  isClean());
          defaultReplicationFactor_ = null;
        }
        return defaultReplicationFactorBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.KafkaConfig2_1)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.KafkaConfig2_1)
    private static final yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1();
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<KafkaConfig2_1>
        PARSER = new com.google.protobuf.AbstractParser<KafkaConfig2_1>() {
      @java.lang.Override
      public KafkaConfig2_1 parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new KafkaConfig2_1(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<KafkaConfig2_1> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<KafkaConfig2_1> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_1 getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface KafkaConfig2_6OrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.KafkaConfig2_6)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Cluster topics compression type.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
     */
    int getCompressionTypeValue();
    /**
     * <pre>
     * Cluster topics compression type.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.Common.CompressionType getCompressionType();

    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     */
    boolean hasLogFlushIntervalMessages();
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     */
    com.google.protobuf.Int64Value getLogFlushIntervalMessages();
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMessagesOrBuilder();

    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     */
    boolean hasLogFlushIntervalMs();
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     */
    com.google.protobuf.Int64Value getLogFlushIntervalMs();
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMsOrBuilder();

    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     */
    boolean hasLogFlushSchedulerIntervalMs();
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     */
    com.google.protobuf.Int64Value getLogFlushSchedulerIntervalMs();
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogFlushSchedulerIntervalMsOrBuilder();

    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_6.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     */
    boolean hasLogRetentionBytes();
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_6.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     */
    com.google.protobuf.Int64Value getLogRetentionBytes();
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_6.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogRetentionBytesOrBuilder();

    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     */
    boolean hasLogRetentionHours();
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     */
    com.google.protobuf.Int64Value getLogRetentionHours();
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogRetentionHoursOrBuilder();

    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     */
    boolean hasLogRetentionMinutes();
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     */
    com.google.protobuf.Int64Value getLogRetentionMinutes();
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogRetentionMinutesOrBuilder();

    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     */
    boolean hasLogRetentionMs();
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     */
    com.google.protobuf.Int64Value getLogRetentionMs();
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogRetentionMsOrBuilder();

    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     */
    boolean hasLogSegmentBytes();
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     */
    com.google.protobuf.Int64Value getLogSegmentBytes();
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogSegmentBytesOrBuilder();

    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     */
    boolean hasLogPreallocate();
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     */
    com.google.protobuf.BoolValue getLogPreallocate();
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     */
    com.google.protobuf.BoolValueOrBuilder getLogPreallocateOrBuilder();

    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     */
    boolean hasSocketSendBufferBytes();
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     */
    com.google.protobuf.Int64Value getSocketSendBufferBytes();
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getSocketSendBufferBytesOrBuilder();

    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     */
    boolean hasSocketReceiveBufferBytes();
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     */
    com.google.protobuf.Int64Value getSocketReceiveBufferBytes();
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getSocketReceiveBufferBytesOrBuilder();

    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     */
    boolean hasAutoCreateTopicsEnable();
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     */
    com.google.protobuf.BoolValue getAutoCreateTopicsEnable();
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     */
    com.google.protobuf.BoolValueOrBuilder getAutoCreateTopicsEnableOrBuilder();

    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     */
    boolean hasNumPartitions();
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     */
    com.google.protobuf.Int64Value getNumPartitions();
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getNumPartitionsOrBuilder();

    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     */
    boolean hasDefaultReplicationFactor();
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     */
    com.google.protobuf.Int64Value getDefaultReplicationFactor();
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getDefaultReplicationFactorOrBuilder();
  }
  /**
   * <pre>
   * Kafka version 2.6 broker configuration.
   * </pre>
   *
   * Protobuf type {@code yandex.cloud.mdb.kafka.v1.KafkaConfig2_6}
   */
  public  static final class KafkaConfig2_6 extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.KafkaConfig2_6)
      KafkaConfig2_6OrBuilder {
  private static final long serialVersionUID = 0L;
    // Use KafkaConfig2_6.newBuilder() to construct.
    private KafkaConfig2_6(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private KafkaConfig2_6() {
      compressionType_ = 0;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private KafkaConfig2_6(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              int rawValue = input.readEnum();

              compressionType_ = rawValue;
              break;
            }
            case 18: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logFlushIntervalMessages_ != null) {
                subBuilder = logFlushIntervalMessages_.toBuilder();
              }
              logFlushIntervalMessages_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logFlushIntervalMessages_);
                logFlushIntervalMessages_ = subBuilder.buildPartial();
              }

              break;
            }
            case 26: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logFlushIntervalMs_ != null) {
                subBuilder = logFlushIntervalMs_.toBuilder();
              }
              logFlushIntervalMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logFlushIntervalMs_);
                logFlushIntervalMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 34: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logFlushSchedulerIntervalMs_ != null) {
                subBuilder = logFlushSchedulerIntervalMs_.toBuilder();
              }
              logFlushSchedulerIntervalMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logFlushSchedulerIntervalMs_);
                logFlushSchedulerIntervalMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 42: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logRetentionBytes_ != null) {
                subBuilder = logRetentionBytes_.toBuilder();
              }
              logRetentionBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logRetentionBytes_);
                logRetentionBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 50: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logRetentionHours_ != null) {
                subBuilder = logRetentionHours_.toBuilder();
              }
              logRetentionHours_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logRetentionHours_);
                logRetentionHours_ = subBuilder.buildPartial();
              }

              break;
            }
            case 58: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logRetentionMinutes_ != null) {
                subBuilder = logRetentionMinutes_.toBuilder();
              }
              logRetentionMinutes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logRetentionMinutes_);
                logRetentionMinutes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 66: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logRetentionMs_ != null) {
                subBuilder = logRetentionMs_.toBuilder();
              }
              logRetentionMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logRetentionMs_);
                logRetentionMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 74: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logSegmentBytes_ != null) {
                subBuilder = logSegmentBytes_.toBuilder();
              }
              logSegmentBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logSegmentBytes_);
                logSegmentBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 82: {
              com.google.protobuf.BoolValue.Builder subBuilder = null;
              if (logPreallocate_ != null) {
                subBuilder = logPreallocate_.toBuilder();
              }
              logPreallocate_ = input.readMessage(com.google.protobuf.BoolValue.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logPreallocate_);
                logPreallocate_ = subBuilder.buildPartial();
              }

              break;
            }
            case 90: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (socketSendBufferBytes_ != null) {
                subBuilder = socketSendBufferBytes_.toBuilder();
              }
              socketSendBufferBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(socketSendBufferBytes_);
                socketSendBufferBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 98: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (socketReceiveBufferBytes_ != null) {
                subBuilder = socketReceiveBufferBytes_.toBuilder();
              }
              socketReceiveBufferBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(socketReceiveBufferBytes_);
                socketReceiveBufferBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 106: {
              com.google.protobuf.BoolValue.Builder subBuilder = null;
              if (autoCreateTopicsEnable_ != null) {
                subBuilder = autoCreateTopicsEnable_.toBuilder();
              }
              autoCreateTopicsEnable_ = input.readMessage(com.google.protobuf.BoolValue.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(autoCreateTopicsEnable_);
                autoCreateTopicsEnable_ = subBuilder.buildPartial();
              }

              break;
            }
            case 114: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (numPartitions_ != null) {
                subBuilder = numPartitions_.toBuilder();
              }
              numPartitions_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(numPartitions_);
                numPartitions_ = subBuilder.buildPartial();
              }

              break;
            }
            case 122: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (defaultReplicationFactor_ != null) {
                subBuilder = defaultReplicationFactor_.toBuilder();
              }
              defaultReplicationFactor_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(defaultReplicationFactor_);
                defaultReplicationFactor_ = subBuilder.buildPartial();
              }

              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_6_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_6_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6.Builder.class);
    }

    public static final int COMPRESSION_TYPE_FIELD_NUMBER = 1;
    private int compressionType_;
    /**
     * <pre>
     * Cluster topics compression type.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
     */
    public int getCompressionTypeValue() {
      return compressionType_;
    }
    /**
     * <pre>
     * Cluster topics compression type.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.Common.CompressionType getCompressionType() {
      @SuppressWarnings("deprecation")
      yandex.cloud.api.mdb.kafka.v1.Common.CompressionType result = yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.valueOf(compressionType_);
      return result == null ? yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.UNRECOGNIZED : result;
    }

    public static final int LOG_FLUSH_INTERVAL_MESSAGES_FIELD_NUMBER = 2;
    private com.google.protobuf.Int64Value logFlushIntervalMessages_;
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     */
    public boolean hasLogFlushIntervalMessages() {
      return logFlushIntervalMessages_ != null;
    }
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     */
    public com.google.protobuf.Int64Value getLogFlushIntervalMessages() {
      return logFlushIntervalMessages_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMessages_;
    }
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMessagesOrBuilder() {
      return getLogFlushIntervalMessages();
    }

    public static final int LOG_FLUSH_INTERVAL_MS_FIELD_NUMBER = 3;
    private com.google.protobuf.Int64Value logFlushIntervalMs_;
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     */
    public boolean hasLogFlushIntervalMs() {
      return logFlushIntervalMs_ != null;
    }
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     */
    public com.google.protobuf.Int64Value getLogFlushIntervalMs() {
      return logFlushIntervalMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMs_;
    }
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMsOrBuilder() {
      return getLogFlushIntervalMs();
    }

    public static final int LOG_FLUSH_SCHEDULER_INTERVAL_MS_FIELD_NUMBER = 4;
    private com.google.protobuf.Int64Value logFlushSchedulerIntervalMs_;
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     */
    public boolean hasLogFlushSchedulerIntervalMs() {
      return logFlushSchedulerIntervalMs_ != null;
    }
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     */
    public com.google.protobuf.Int64Value getLogFlushSchedulerIntervalMs() {
      return logFlushSchedulerIntervalMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushSchedulerIntervalMs_;
    }
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getLogFlushSchedulerIntervalMsOrBuilder() {
      return getLogFlushSchedulerIntervalMs();
    }

    public static final int LOG_RETENTION_BYTES_FIELD_NUMBER = 5;
    private com.google.protobuf.Int64Value logRetentionBytes_;
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_6.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     */
    public boolean hasLogRetentionBytes() {
      return logRetentionBytes_ != null;
    }
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_6.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     */
    public com.google.protobuf.Int64Value getLogRetentionBytes() {
      return logRetentionBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionBytes_;
    }
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_6.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getLogRetentionBytesOrBuilder() {
      return getLogRetentionBytes();
    }

    public static final int LOG_RETENTION_HOURS_FIELD_NUMBER = 6;
    private com.google.protobuf.Int64Value logRetentionHours_;
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     */
    public boolean hasLogRetentionHours() {
      return logRetentionHours_ != null;
    }
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     */
    public com.google.protobuf.Int64Value getLogRetentionHours() {
      return logRetentionHours_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionHours_;
    }
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getLogRetentionHoursOrBuilder() {
      return getLogRetentionHours();
    }

    public static final int LOG_RETENTION_MINUTES_FIELD_NUMBER = 7;
    private com.google.protobuf.Int64Value logRetentionMinutes_;
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     */
    public boolean hasLogRetentionMinutes() {
      return logRetentionMinutes_ != null;
    }
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     */
    public com.google.protobuf.Int64Value getLogRetentionMinutes() {
      return logRetentionMinutes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMinutes_;
    }
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getLogRetentionMinutesOrBuilder() {
      return getLogRetentionMinutes();
    }

    public static final int LOG_RETENTION_MS_FIELD_NUMBER = 8;
    private com.google.protobuf.Int64Value logRetentionMs_;
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     */
    public boolean hasLogRetentionMs() {
      return logRetentionMs_ != null;
    }
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     */
    public com.google.protobuf.Int64Value getLogRetentionMs() {
      return logRetentionMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMs_;
    }
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getLogRetentionMsOrBuilder() {
      return getLogRetentionMs();
    }

    public static final int LOG_SEGMENT_BYTES_FIELD_NUMBER = 9;
    private com.google.protobuf.Int64Value logSegmentBytes_;
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     */
    public boolean hasLogSegmentBytes() {
      return logSegmentBytes_ != null;
    }
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     */
    public com.google.protobuf.Int64Value getLogSegmentBytes() {
      return logSegmentBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logSegmentBytes_;
    }
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getLogSegmentBytesOrBuilder() {
      return getLogSegmentBytes();
    }

    public static final int LOG_PREALLOCATE_FIELD_NUMBER = 10;
    private com.google.protobuf.BoolValue logPreallocate_;
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     */
    public boolean hasLogPreallocate() {
      return logPreallocate_ != null;
    }
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     */
    public com.google.protobuf.BoolValue getLogPreallocate() {
      return logPreallocate_ == null ? com.google.protobuf.BoolValue.getDefaultInstance() : logPreallocate_;
    }
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     */
    public com.google.protobuf.BoolValueOrBuilder getLogPreallocateOrBuilder() {
      return getLogPreallocate();
    }

    public static final int SOCKET_SEND_BUFFER_BYTES_FIELD_NUMBER = 11;
    private com.google.protobuf.Int64Value socketSendBufferBytes_;
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     */
    public boolean hasSocketSendBufferBytes() {
      return socketSendBufferBytes_ != null;
    }
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     */
    public com.google.protobuf.Int64Value getSocketSendBufferBytes() {
      return socketSendBufferBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : socketSendBufferBytes_;
    }
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getSocketSendBufferBytesOrBuilder() {
      return getSocketSendBufferBytes();
    }

    public static final int SOCKET_RECEIVE_BUFFER_BYTES_FIELD_NUMBER = 12;
    private com.google.protobuf.Int64Value socketReceiveBufferBytes_;
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     */
    public boolean hasSocketReceiveBufferBytes() {
      return socketReceiveBufferBytes_ != null;
    }
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     */
    public com.google.protobuf.Int64Value getSocketReceiveBufferBytes() {
      return socketReceiveBufferBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : socketReceiveBufferBytes_;
    }
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getSocketReceiveBufferBytesOrBuilder() {
      return getSocketReceiveBufferBytes();
    }

    public static final int AUTO_CREATE_TOPICS_ENABLE_FIELD_NUMBER = 13;
    private com.google.protobuf.BoolValue autoCreateTopicsEnable_;
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     */
    public boolean hasAutoCreateTopicsEnable() {
      return autoCreateTopicsEnable_ != null;
    }
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     */
    public com.google.protobuf.BoolValue getAutoCreateTopicsEnable() {
      return autoCreateTopicsEnable_ == null ? com.google.protobuf.BoolValue.getDefaultInstance() : autoCreateTopicsEnable_;
    }
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     */
    public com.google.protobuf.BoolValueOrBuilder getAutoCreateTopicsEnableOrBuilder() {
      return getAutoCreateTopicsEnable();
    }

    public static final int NUM_PARTITIONS_FIELD_NUMBER = 14;
    private com.google.protobuf.Int64Value numPartitions_;
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     */
    public boolean hasNumPartitions() {
      return numPartitions_ != null;
    }
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     */
    public com.google.protobuf.Int64Value getNumPartitions() {
      return numPartitions_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : numPartitions_;
    }
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getNumPartitionsOrBuilder() {
      return getNumPartitions();
    }

    public static final int DEFAULT_REPLICATION_FACTOR_FIELD_NUMBER = 15;
    private com.google.protobuf.Int64Value defaultReplicationFactor_;
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     */
    public boolean hasDefaultReplicationFactor() {
      return defaultReplicationFactor_ != null;
    }
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     */
    public com.google.protobuf.Int64Value getDefaultReplicationFactor() {
      return defaultReplicationFactor_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : defaultReplicationFactor_;
    }
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getDefaultReplicationFactorOrBuilder() {
      return getDefaultReplicationFactor();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (compressionType_ != yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.COMPRESSION_TYPE_UNSPECIFIED.getNumber()) {
        output.writeEnum(1, compressionType_);
      }
      if (logFlushIntervalMessages_ != null) {
        output.writeMessage(2, getLogFlushIntervalMessages());
      }
      if (logFlushIntervalMs_ != null) {
        output.writeMessage(3, getLogFlushIntervalMs());
      }
      if (logFlushSchedulerIntervalMs_ != null) {
        output.writeMessage(4, getLogFlushSchedulerIntervalMs());
      }
      if (logRetentionBytes_ != null) {
        output.writeMessage(5, getLogRetentionBytes());
      }
      if (logRetentionHours_ != null) {
        output.writeMessage(6, getLogRetentionHours());
      }
      if (logRetentionMinutes_ != null) {
        output.writeMessage(7, getLogRetentionMinutes());
      }
      if (logRetentionMs_ != null) {
        output.writeMessage(8, getLogRetentionMs());
      }
      if (logSegmentBytes_ != null) {
        output.writeMessage(9, getLogSegmentBytes());
      }
      if (logPreallocate_ != null) {
        output.writeMessage(10, getLogPreallocate());
      }
      if (socketSendBufferBytes_ != null) {
        output.writeMessage(11, getSocketSendBufferBytes());
      }
      if (socketReceiveBufferBytes_ != null) {
        output.writeMessage(12, getSocketReceiveBufferBytes());
      }
      if (autoCreateTopicsEnable_ != null) {
        output.writeMessage(13, getAutoCreateTopicsEnable());
      }
      if (numPartitions_ != null) {
        output.writeMessage(14, getNumPartitions());
      }
      if (defaultReplicationFactor_ != null) {
        output.writeMessage(15, getDefaultReplicationFactor());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (compressionType_ != yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.COMPRESSION_TYPE_UNSPECIFIED.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, compressionType_);
      }
      if (logFlushIntervalMessages_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getLogFlushIntervalMessages());
      }
      if (logFlushIntervalMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getLogFlushIntervalMs());
      }
      if (logFlushSchedulerIntervalMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getLogFlushSchedulerIntervalMs());
      }
      if (logRetentionBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getLogRetentionBytes());
      }
      if (logRetentionHours_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, getLogRetentionHours());
      }
      if (logRetentionMinutes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, getLogRetentionMinutes());
      }
      if (logRetentionMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(8, getLogRetentionMs());
      }
      if (logSegmentBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(9, getLogSegmentBytes());
      }
      if (logPreallocate_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(10, getLogPreallocate());
      }
      if (socketSendBufferBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(11, getSocketSendBufferBytes());
      }
      if (socketReceiveBufferBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(12, getSocketReceiveBufferBytes());
      }
      if (autoCreateTopicsEnable_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(13, getAutoCreateTopicsEnable());
      }
      if (numPartitions_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(14, getNumPartitions());
      }
      if (defaultReplicationFactor_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(15, getDefaultReplicationFactor());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6)) {
        return super.equals(obj);
      }
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 other = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6) obj;

      boolean result = true;
      result = result && compressionType_ == other.compressionType_;
      result = result && (hasLogFlushIntervalMessages() == other.hasLogFlushIntervalMessages());
      if (hasLogFlushIntervalMessages()) {
        result = result && getLogFlushIntervalMessages()
            .equals(other.getLogFlushIntervalMessages());
      }
      result = result && (hasLogFlushIntervalMs() == other.hasLogFlushIntervalMs());
      if (hasLogFlushIntervalMs()) {
        result = result && getLogFlushIntervalMs()
            .equals(other.getLogFlushIntervalMs());
      }
      result = result && (hasLogFlushSchedulerIntervalMs() == other.hasLogFlushSchedulerIntervalMs());
      if (hasLogFlushSchedulerIntervalMs()) {
        result = result && getLogFlushSchedulerIntervalMs()
            .equals(other.getLogFlushSchedulerIntervalMs());
      }
      result = result && (hasLogRetentionBytes() == other.hasLogRetentionBytes());
      if (hasLogRetentionBytes()) {
        result = result && getLogRetentionBytes()
            .equals(other.getLogRetentionBytes());
      }
      result = result && (hasLogRetentionHours() == other.hasLogRetentionHours());
      if (hasLogRetentionHours()) {
        result = result && getLogRetentionHours()
            .equals(other.getLogRetentionHours());
      }
      result = result && (hasLogRetentionMinutes() == other.hasLogRetentionMinutes());
      if (hasLogRetentionMinutes()) {
        result = result && getLogRetentionMinutes()
            .equals(other.getLogRetentionMinutes());
      }
      result = result && (hasLogRetentionMs() == other.hasLogRetentionMs());
      if (hasLogRetentionMs()) {
        result = result && getLogRetentionMs()
            .equals(other.getLogRetentionMs());
      }
      result = result && (hasLogSegmentBytes() == other.hasLogSegmentBytes());
      if (hasLogSegmentBytes()) {
        result = result && getLogSegmentBytes()
            .equals(other.getLogSegmentBytes());
      }
      result = result && (hasLogPreallocate() == other.hasLogPreallocate());
      if (hasLogPreallocate()) {
        result = result && getLogPreallocate()
            .equals(other.getLogPreallocate());
      }
      result = result && (hasSocketSendBufferBytes() == other.hasSocketSendBufferBytes());
      if (hasSocketSendBufferBytes()) {
        result = result && getSocketSendBufferBytes()
            .equals(other.getSocketSendBufferBytes());
      }
      result = result && (hasSocketReceiveBufferBytes() == other.hasSocketReceiveBufferBytes());
      if (hasSocketReceiveBufferBytes()) {
        result = result && getSocketReceiveBufferBytes()
            .equals(other.getSocketReceiveBufferBytes());
      }
      result = result && (hasAutoCreateTopicsEnable() == other.hasAutoCreateTopicsEnable());
      if (hasAutoCreateTopicsEnable()) {
        result = result && getAutoCreateTopicsEnable()
            .equals(other.getAutoCreateTopicsEnable());
      }
      result = result && (hasNumPartitions() == other.hasNumPartitions());
      if (hasNumPartitions()) {
        result = result && getNumPartitions()
            .equals(other.getNumPartitions());
      }
      result = result && (hasDefaultReplicationFactor() == other.hasDefaultReplicationFactor());
      if (hasDefaultReplicationFactor()) {
        result = result && getDefaultReplicationFactor()
            .equals(other.getDefaultReplicationFactor());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + COMPRESSION_TYPE_FIELD_NUMBER;
      hash = (53 * hash) + compressionType_;
      if (hasLogFlushIntervalMessages()) {
        hash = (37 * hash) + LOG_FLUSH_INTERVAL_MESSAGES_FIELD_NUMBER;
        hash = (53 * hash) + getLogFlushIntervalMessages().hashCode();
      }
      if (hasLogFlushIntervalMs()) {
        hash = (37 * hash) + LOG_FLUSH_INTERVAL_MS_FIELD_NUMBER;
        hash = (53 * hash) + getLogFlushIntervalMs().hashCode();
      }
      if (hasLogFlushSchedulerIntervalMs()) {
        hash = (37 * hash) + LOG_FLUSH_SCHEDULER_INTERVAL_MS_FIELD_NUMBER;
        hash = (53 * hash) + getLogFlushSchedulerIntervalMs().hashCode();
      }
      if (hasLogRetentionBytes()) {
        hash = (37 * hash) + LOG_RETENTION_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getLogRetentionBytes().hashCode();
      }
      if (hasLogRetentionHours()) {
        hash = (37 * hash) + LOG_RETENTION_HOURS_FIELD_NUMBER;
        hash = (53 * hash) + getLogRetentionHours().hashCode();
      }
      if (hasLogRetentionMinutes()) {
        hash = (37 * hash) + LOG_RETENTION_MINUTES_FIELD_NUMBER;
        hash = (53 * hash) + getLogRetentionMinutes().hashCode();
      }
      if (hasLogRetentionMs()) {
        hash = (37 * hash) + LOG_RETENTION_MS_FIELD_NUMBER;
        hash = (53 * hash) + getLogRetentionMs().hashCode();
      }
      if (hasLogSegmentBytes()) {
        hash = (37 * hash) + LOG_SEGMENT_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getLogSegmentBytes().hashCode();
      }
      if (hasLogPreallocate()) {
        hash = (37 * hash) + LOG_PREALLOCATE_FIELD_NUMBER;
        hash = (53 * hash) + getLogPreallocate().hashCode();
      }
      if (hasSocketSendBufferBytes()) {
        hash = (37 * hash) + SOCKET_SEND_BUFFER_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getSocketSendBufferBytes().hashCode();
      }
      if (hasSocketReceiveBufferBytes()) {
        hash = (37 * hash) + SOCKET_RECEIVE_BUFFER_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getSocketReceiveBufferBytes().hashCode();
      }
      if (hasAutoCreateTopicsEnable()) {
        hash = (37 * hash) + AUTO_CREATE_TOPICS_ENABLE_FIELD_NUMBER;
        hash = (53 * hash) + getAutoCreateTopicsEnable().hashCode();
      }
      if (hasNumPartitions()) {
        hash = (37 * hash) + NUM_PARTITIONS_FIELD_NUMBER;
        hash = (53 * hash) + getNumPartitions().hashCode();
      }
      if (hasDefaultReplicationFactor()) {
        hash = (37 * hash) + DEFAULT_REPLICATION_FACTOR_FIELD_NUMBER;
        hash = (53 * hash) + getDefaultReplicationFactor().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Kafka version 2.6 broker configuration.
     * </pre>
     *
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.KafkaConfig2_6}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.KafkaConfig2_6)
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6OrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_6_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_6_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6.Builder.class);
      }

      // Construct using yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        compressionType_ = 0;

        if (logFlushIntervalMessagesBuilder_ == null) {
          logFlushIntervalMessages_ = null;
        } else {
          logFlushIntervalMessages_ = null;
          logFlushIntervalMessagesBuilder_ = null;
        }
        if (logFlushIntervalMsBuilder_ == null) {
          logFlushIntervalMs_ = null;
        } else {
          logFlushIntervalMs_ = null;
          logFlushIntervalMsBuilder_ = null;
        }
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          logFlushSchedulerIntervalMs_ = null;
        } else {
          logFlushSchedulerIntervalMs_ = null;
          logFlushSchedulerIntervalMsBuilder_ = null;
        }
        if (logRetentionBytesBuilder_ == null) {
          logRetentionBytes_ = null;
        } else {
          logRetentionBytes_ = null;
          logRetentionBytesBuilder_ = null;
        }
        if (logRetentionHoursBuilder_ == null) {
          logRetentionHours_ = null;
        } else {
          logRetentionHours_ = null;
          logRetentionHoursBuilder_ = null;
        }
        if (logRetentionMinutesBuilder_ == null) {
          logRetentionMinutes_ = null;
        } else {
          logRetentionMinutes_ = null;
          logRetentionMinutesBuilder_ = null;
        }
        if (logRetentionMsBuilder_ == null) {
          logRetentionMs_ = null;
        } else {
          logRetentionMs_ = null;
          logRetentionMsBuilder_ = null;
        }
        if (logSegmentBytesBuilder_ == null) {
          logSegmentBytes_ = null;
        } else {
          logSegmentBytes_ = null;
          logSegmentBytesBuilder_ = null;
        }
        if (logPreallocateBuilder_ == null) {
          logPreallocate_ = null;
        } else {
          logPreallocate_ = null;
          logPreallocateBuilder_ = null;
        }
        if (socketSendBufferBytesBuilder_ == null) {
          socketSendBufferBytes_ = null;
        } else {
          socketSendBufferBytes_ = null;
          socketSendBufferBytesBuilder_ = null;
        }
        if (socketReceiveBufferBytesBuilder_ == null) {
          socketReceiveBufferBytes_ = null;
        } else {
          socketReceiveBufferBytes_ = null;
          socketReceiveBufferBytesBuilder_ = null;
        }
        if (autoCreateTopicsEnableBuilder_ == null) {
          autoCreateTopicsEnable_ = null;
        } else {
          autoCreateTopicsEnable_ = null;
          autoCreateTopicsEnableBuilder_ = null;
        }
        if (numPartitionsBuilder_ == null) {
          numPartitions_ = null;
        } else {
          numPartitions_ = null;
          numPartitionsBuilder_ = null;
        }
        if (defaultReplicationFactorBuilder_ == null) {
          defaultReplicationFactor_ = null;
        } else {
          defaultReplicationFactor_ = null;
          defaultReplicationFactorBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_6_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 getDefaultInstanceForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 build() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 buildPartial() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 result = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6(this);
        result.compressionType_ = compressionType_;
        if (logFlushIntervalMessagesBuilder_ == null) {
          result.logFlushIntervalMessages_ = logFlushIntervalMessages_;
        } else {
          result.logFlushIntervalMessages_ = logFlushIntervalMessagesBuilder_.build();
        }
        if (logFlushIntervalMsBuilder_ == null) {
          result.logFlushIntervalMs_ = logFlushIntervalMs_;
        } else {
          result.logFlushIntervalMs_ = logFlushIntervalMsBuilder_.build();
        }
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          result.logFlushSchedulerIntervalMs_ = logFlushSchedulerIntervalMs_;
        } else {
          result.logFlushSchedulerIntervalMs_ = logFlushSchedulerIntervalMsBuilder_.build();
        }
        if (logRetentionBytesBuilder_ == null) {
          result.logRetentionBytes_ = logRetentionBytes_;
        } else {
          result.logRetentionBytes_ = logRetentionBytesBuilder_.build();
        }
        if (logRetentionHoursBuilder_ == null) {
          result.logRetentionHours_ = logRetentionHours_;
        } else {
          result.logRetentionHours_ = logRetentionHoursBuilder_.build();
        }
        if (logRetentionMinutesBuilder_ == null) {
          result.logRetentionMinutes_ = logRetentionMinutes_;
        } else {
          result.logRetentionMinutes_ = logRetentionMinutesBuilder_.build();
        }
        if (logRetentionMsBuilder_ == null) {
          result.logRetentionMs_ = logRetentionMs_;
        } else {
          result.logRetentionMs_ = logRetentionMsBuilder_.build();
        }
        if (logSegmentBytesBuilder_ == null) {
          result.logSegmentBytes_ = logSegmentBytes_;
        } else {
          result.logSegmentBytes_ = logSegmentBytesBuilder_.build();
        }
        if (logPreallocateBuilder_ == null) {
          result.logPreallocate_ = logPreallocate_;
        } else {
          result.logPreallocate_ = logPreallocateBuilder_.build();
        }
        if (socketSendBufferBytesBuilder_ == null) {
          result.socketSendBufferBytes_ = socketSendBufferBytes_;
        } else {
          result.socketSendBufferBytes_ = socketSendBufferBytesBuilder_.build();
        }
        if (socketReceiveBufferBytesBuilder_ == null) {
          result.socketReceiveBufferBytes_ = socketReceiveBufferBytes_;
        } else {
          result.socketReceiveBufferBytes_ = socketReceiveBufferBytesBuilder_.build();
        }
        if (autoCreateTopicsEnableBuilder_ == null) {
          result.autoCreateTopicsEnable_ = autoCreateTopicsEnable_;
        } else {
          result.autoCreateTopicsEnable_ = autoCreateTopicsEnableBuilder_.build();
        }
        if (numPartitionsBuilder_ == null) {
          result.numPartitions_ = numPartitions_;
        } else {
          result.numPartitions_ = numPartitionsBuilder_.build();
        }
        if (defaultReplicationFactorBuilder_ == null) {
          result.defaultReplicationFactor_ = defaultReplicationFactor_;
        } else {
          result.defaultReplicationFactor_ = defaultReplicationFactorBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6) {
          return mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 other) {
        if (other == yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6.getDefaultInstance()) return this;
        if (other.compressionType_ != 0) {
          setCompressionTypeValue(other.getCompressionTypeValue());
        }
        if (other.hasLogFlushIntervalMessages()) {
          mergeLogFlushIntervalMessages(other.getLogFlushIntervalMessages());
        }
        if (other.hasLogFlushIntervalMs()) {
          mergeLogFlushIntervalMs(other.getLogFlushIntervalMs());
        }
        if (other.hasLogFlushSchedulerIntervalMs()) {
          mergeLogFlushSchedulerIntervalMs(other.getLogFlushSchedulerIntervalMs());
        }
        if (other.hasLogRetentionBytes()) {
          mergeLogRetentionBytes(other.getLogRetentionBytes());
        }
        if (other.hasLogRetentionHours()) {
          mergeLogRetentionHours(other.getLogRetentionHours());
        }
        if (other.hasLogRetentionMinutes()) {
          mergeLogRetentionMinutes(other.getLogRetentionMinutes());
        }
        if (other.hasLogRetentionMs()) {
          mergeLogRetentionMs(other.getLogRetentionMs());
        }
        if (other.hasLogSegmentBytes()) {
          mergeLogSegmentBytes(other.getLogSegmentBytes());
        }
        if (other.hasLogPreallocate()) {
          mergeLogPreallocate(other.getLogPreallocate());
        }
        if (other.hasSocketSendBufferBytes()) {
          mergeSocketSendBufferBytes(other.getSocketSendBufferBytes());
        }
        if (other.hasSocketReceiveBufferBytes()) {
          mergeSocketReceiveBufferBytes(other.getSocketReceiveBufferBytes());
        }
        if (other.hasAutoCreateTopicsEnable()) {
          mergeAutoCreateTopicsEnable(other.getAutoCreateTopicsEnable());
        }
        if (other.hasNumPartitions()) {
          mergeNumPartitions(other.getNumPartitions());
        }
        if (other.hasDefaultReplicationFactor()) {
          mergeDefaultReplicationFactor(other.getDefaultReplicationFactor());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private int compressionType_ = 0;
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       */
      public int getCompressionTypeValue() {
        return compressionType_;
      }
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       */
      public Builder setCompressionTypeValue(int value) {
        compressionType_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.Common.CompressionType getCompressionType() {
        @SuppressWarnings("deprecation")
        yandex.cloud.api.mdb.kafka.v1.Common.CompressionType result = yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.valueOf(compressionType_);
        return result == null ? yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       */
      public Builder setCompressionType(yandex.cloud.api.mdb.kafka.v1.Common.CompressionType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        
        compressionType_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       */
      public Builder clearCompressionType() {
        
        compressionType_ = 0;
        onChanged();
        return this;
      }

      private com.google.protobuf.Int64Value logFlushIntervalMessages_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logFlushIntervalMessagesBuilder_;
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public boolean hasLogFlushIntervalMessages() {
        return logFlushIntervalMessagesBuilder_ != null || logFlushIntervalMessages_ != null;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public com.google.protobuf.Int64Value getLogFlushIntervalMessages() {
        if (logFlushIntervalMessagesBuilder_ == null) {
          return logFlushIntervalMessages_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMessages_;
        } else {
          return logFlushIntervalMessagesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public Builder setLogFlushIntervalMessages(com.google.protobuf.Int64Value value) {
        if (logFlushIntervalMessagesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logFlushIntervalMessages_ = value;
          onChanged();
        } else {
          logFlushIntervalMessagesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public Builder setLogFlushIntervalMessages(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logFlushIntervalMessagesBuilder_ == null) {
          logFlushIntervalMessages_ = builderForValue.build();
          onChanged();
        } else {
          logFlushIntervalMessagesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public Builder mergeLogFlushIntervalMessages(com.google.protobuf.Int64Value value) {
        if (logFlushIntervalMessagesBuilder_ == null) {
          if (logFlushIntervalMessages_ != null) {
            logFlushIntervalMessages_ =
              com.google.protobuf.Int64Value.newBuilder(logFlushIntervalMessages_).mergeFrom(value).buildPartial();
          } else {
            logFlushIntervalMessages_ = value;
          }
          onChanged();
        } else {
          logFlushIntervalMessagesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public Builder clearLogFlushIntervalMessages() {
        if (logFlushIntervalMessagesBuilder_ == null) {
          logFlushIntervalMessages_ = null;
          onChanged();
        } else {
          logFlushIntervalMessages_ = null;
          logFlushIntervalMessagesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogFlushIntervalMessagesBuilder() {
        
        onChanged();
        return getLogFlushIntervalMessagesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMessagesOrBuilder() {
        if (logFlushIntervalMessagesBuilder_ != null) {
          return logFlushIntervalMessagesBuilder_.getMessageOrBuilder();
        } else {
          return logFlushIntervalMessages_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMessages_;
        }
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogFlushIntervalMessagesFieldBuilder() {
        if (logFlushIntervalMessagesBuilder_ == null) {
          logFlushIntervalMessagesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogFlushIntervalMessages(),
                  getParentForChildren(),
                  isClean());
          logFlushIntervalMessages_ = null;
        }
        return logFlushIntervalMessagesBuilder_;
      }

      private com.google.protobuf.Int64Value logFlushIntervalMs_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logFlushIntervalMsBuilder_;
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public boolean hasLogFlushIntervalMs() {
        return logFlushIntervalMsBuilder_ != null || logFlushIntervalMs_ != null;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public com.google.protobuf.Int64Value getLogFlushIntervalMs() {
        if (logFlushIntervalMsBuilder_ == null) {
          return logFlushIntervalMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMs_;
        } else {
          return logFlushIntervalMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public Builder setLogFlushIntervalMs(com.google.protobuf.Int64Value value) {
        if (logFlushIntervalMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logFlushIntervalMs_ = value;
          onChanged();
        } else {
          logFlushIntervalMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public Builder setLogFlushIntervalMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logFlushIntervalMsBuilder_ == null) {
          logFlushIntervalMs_ = builderForValue.build();
          onChanged();
        } else {
          logFlushIntervalMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public Builder mergeLogFlushIntervalMs(com.google.protobuf.Int64Value value) {
        if (logFlushIntervalMsBuilder_ == null) {
          if (logFlushIntervalMs_ != null) {
            logFlushIntervalMs_ =
              com.google.protobuf.Int64Value.newBuilder(logFlushIntervalMs_).mergeFrom(value).buildPartial();
          } else {
            logFlushIntervalMs_ = value;
          }
          onChanged();
        } else {
          logFlushIntervalMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public Builder clearLogFlushIntervalMs() {
        if (logFlushIntervalMsBuilder_ == null) {
          logFlushIntervalMs_ = null;
          onChanged();
        } else {
          logFlushIntervalMs_ = null;
          logFlushIntervalMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogFlushIntervalMsBuilder() {
        
        onChanged();
        return getLogFlushIntervalMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMsOrBuilder() {
        if (logFlushIntervalMsBuilder_ != null) {
          return logFlushIntervalMsBuilder_.getMessageOrBuilder();
        } else {
          return logFlushIntervalMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMs_;
        }
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogFlushIntervalMsFieldBuilder() {
        if (logFlushIntervalMsBuilder_ == null) {
          logFlushIntervalMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogFlushIntervalMs(),
                  getParentForChildren(),
                  isClean());
          logFlushIntervalMs_ = null;
        }
        return logFlushIntervalMsBuilder_;
      }

      private com.google.protobuf.Int64Value logFlushSchedulerIntervalMs_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logFlushSchedulerIntervalMsBuilder_;
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public boolean hasLogFlushSchedulerIntervalMs() {
        return logFlushSchedulerIntervalMsBuilder_ != null || logFlushSchedulerIntervalMs_ != null;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public com.google.protobuf.Int64Value getLogFlushSchedulerIntervalMs() {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          return logFlushSchedulerIntervalMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushSchedulerIntervalMs_;
        } else {
          return logFlushSchedulerIntervalMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public Builder setLogFlushSchedulerIntervalMs(com.google.protobuf.Int64Value value) {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logFlushSchedulerIntervalMs_ = value;
          onChanged();
        } else {
          logFlushSchedulerIntervalMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public Builder setLogFlushSchedulerIntervalMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          logFlushSchedulerIntervalMs_ = builderForValue.build();
          onChanged();
        } else {
          logFlushSchedulerIntervalMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public Builder mergeLogFlushSchedulerIntervalMs(com.google.protobuf.Int64Value value) {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          if (logFlushSchedulerIntervalMs_ != null) {
            logFlushSchedulerIntervalMs_ =
              com.google.protobuf.Int64Value.newBuilder(logFlushSchedulerIntervalMs_).mergeFrom(value).buildPartial();
          } else {
            logFlushSchedulerIntervalMs_ = value;
          }
          onChanged();
        } else {
          logFlushSchedulerIntervalMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public Builder clearLogFlushSchedulerIntervalMs() {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          logFlushSchedulerIntervalMs_ = null;
          onChanged();
        } else {
          logFlushSchedulerIntervalMs_ = null;
          logFlushSchedulerIntervalMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogFlushSchedulerIntervalMsBuilder() {
        
        onChanged();
        return getLogFlushSchedulerIntervalMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogFlushSchedulerIntervalMsOrBuilder() {
        if (logFlushSchedulerIntervalMsBuilder_ != null) {
          return logFlushSchedulerIntervalMsBuilder_.getMessageOrBuilder();
        } else {
          return logFlushSchedulerIntervalMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logFlushSchedulerIntervalMs_;
        }
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogFlushSchedulerIntervalMsFieldBuilder() {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          logFlushSchedulerIntervalMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogFlushSchedulerIntervalMs(),
                  getParentForChildren(),
                  isClean());
          logFlushSchedulerIntervalMs_ = null;
        }
        return logFlushSchedulerIntervalMsBuilder_;
      }

      private com.google.protobuf.Int64Value logRetentionBytes_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logRetentionBytesBuilder_;
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_6.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public boolean hasLogRetentionBytes() {
        return logRetentionBytesBuilder_ != null || logRetentionBytes_ != null;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_6.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public com.google.protobuf.Int64Value getLogRetentionBytes() {
        if (logRetentionBytesBuilder_ == null) {
          return logRetentionBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionBytes_;
        } else {
          return logRetentionBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_6.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public Builder setLogRetentionBytes(com.google.protobuf.Int64Value value) {
        if (logRetentionBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logRetentionBytes_ = value;
          onChanged();
        } else {
          logRetentionBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_6.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public Builder setLogRetentionBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logRetentionBytesBuilder_ == null) {
          logRetentionBytes_ = builderForValue.build();
          onChanged();
        } else {
          logRetentionBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_6.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public Builder mergeLogRetentionBytes(com.google.protobuf.Int64Value value) {
        if (logRetentionBytesBuilder_ == null) {
          if (logRetentionBytes_ != null) {
            logRetentionBytes_ =
              com.google.protobuf.Int64Value.newBuilder(logRetentionBytes_).mergeFrom(value).buildPartial();
          } else {
            logRetentionBytes_ = value;
          }
          onChanged();
        } else {
          logRetentionBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_6.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public Builder clearLogRetentionBytes() {
        if (logRetentionBytesBuilder_ == null) {
          logRetentionBytes_ = null;
          onChanged();
        } else {
          logRetentionBytes_ = null;
          logRetentionBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_6.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogRetentionBytesBuilder() {
        
        onChanged();
        return getLogRetentionBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_6.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogRetentionBytesOrBuilder() {
        if (logRetentionBytesBuilder_ != null) {
          return logRetentionBytesBuilder_.getMessageOrBuilder();
        } else {
          return logRetentionBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionBytes_;
        }
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_6.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogRetentionBytesFieldBuilder() {
        if (logRetentionBytesBuilder_ == null) {
          logRetentionBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogRetentionBytes(),
                  getParentForChildren(),
                  isClean());
          logRetentionBytes_ = null;
        }
        return logRetentionBytesBuilder_;
      }

      private com.google.protobuf.Int64Value logRetentionHours_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logRetentionHoursBuilder_;
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public boolean hasLogRetentionHours() {
        return logRetentionHoursBuilder_ != null || logRetentionHours_ != null;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public com.google.protobuf.Int64Value getLogRetentionHours() {
        if (logRetentionHoursBuilder_ == null) {
          return logRetentionHours_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionHours_;
        } else {
          return logRetentionHoursBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public Builder setLogRetentionHours(com.google.protobuf.Int64Value value) {
        if (logRetentionHoursBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logRetentionHours_ = value;
          onChanged();
        } else {
          logRetentionHoursBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public Builder setLogRetentionHours(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logRetentionHoursBuilder_ == null) {
          logRetentionHours_ = builderForValue.build();
          onChanged();
        } else {
          logRetentionHoursBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public Builder mergeLogRetentionHours(com.google.protobuf.Int64Value value) {
        if (logRetentionHoursBuilder_ == null) {
          if (logRetentionHours_ != null) {
            logRetentionHours_ =
              com.google.protobuf.Int64Value.newBuilder(logRetentionHours_).mergeFrom(value).buildPartial();
          } else {
            logRetentionHours_ = value;
          }
          onChanged();
        } else {
          logRetentionHoursBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public Builder clearLogRetentionHours() {
        if (logRetentionHoursBuilder_ == null) {
          logRetentionHours_ = null;
          onChanged();
        } else {
          logRetentionHours_ = null;
          logRetentionHoursBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogRetentionHoursBuilder() {
        
        onChanged();
        return getLogRetentionHoursFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogRetentionHoursOrBuilder() {
        if (logRetentionHoursBuilder_ != null) {
          return logRetentionHoursBuilder_.getMessageOrBuilder();
        } else {
          return logRetentionHours_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionHours_;
        }
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogRetentionHoursFieldBuilder() {
        if (logRetentionHoursBuilder_ == null) {
          logRetentionHoursBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogRetentionHours(),
                  getParentForChildren(),
                  isClean());
          logRetentionHours_ = null;
        }
        return logRetentionHoursBuilder_;
      }

      private com.google.protobuf.Int64Value logRetentionMinutes_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logRetentionMinutesBuilder_;
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public boolean hasLogRetentionMinutes() {
        return logRetentionMinutesBuilder_ != null || logRetentionMinutes_ != null;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public com.google.protobuf.Int64Value getLogRetentionMinutes() {
        if (logRetentionMinutesBuilder_ == null) {
          return logRetentionMinutes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMinutes_;
        } else {
          return logRetentionMinutesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public Builder setLogRetentionMinutes(com.google.protobuf.Int64Value value) {
        if (logRetentionMinutesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logRetentionMinutes_ = value;
          onChanged();
        } else {
          logRetentionMinutesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public Builder setLogRetentionMinutes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logRetentionMinutesBuilder_ == null) {
          logRetentionMinutes_ = builderForValue.build();
          onChanged();
        } else {
          logRetentionMinutesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public Builder mergeLogRetentionMinutes(com.google.protobuf.Int64Value value) {
        if (logRetentionMinutesBuilder_ == null) {
          if (logRetentionMinutes_ != null) {
            logRetentionMinutes_ =
              com.google.protobuf.Int64Value.newBuilder(logRetentionMinutes_).mergeFrom(value).buildPartial();
          } else {
            logRetentionMinutes_ = value;
          }
          onChanged();
        } else {
          logRetentionMinutesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public Builder clearLogRetentionMinutes() {
        if (logRetentionMinutesBuilder_ == null) {
          logRetentionMinutes_ = null;
          onChanged();
        } else {
          logRetentionMinutes_ = null;
          logRetentionMinutesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogRetentionMinutesBuilder() {
        
        onChanged();
        return getLogRetentionMinutesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogRetentionMinutesOrBuilder() {
        if (logRetentionMinutesBuilder_ != null) {
          return logRetentionMinutesBuilder_.getMessageOrBuilder();
        } else {
          return logRetentionMinutes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMinutes_;
        }
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogRetentionMinutesFieldBuilder() {
        if (logRetentionMinutesBuilder_ == null) {
          logRetentionMinutesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogRetentionMinutes(),
                  getParentForChildren(),
                  isClean());
          logRetentionMinutes_ = null;
        }
        return logRetentionMinutesBuilder_;
      }

      private com.google.protobuf.Int64Value logRetentionMs_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logRetentionMsBuilder_;
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public boolean hasLogRetentionMs() {
        return logRetentionMsBuilder_ != null || logRetentionMs_ != null;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public com.google.protobuf.Int64Value getLogRetentionMs() {
        if (logRetentionMsBuilder_ == null) {
          return logRetentionMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMs_;
        } else {
          return logRetentionMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public Builder setLogRetentionMs(com.google.protobuf.Int64Value value) {
        if (logRetentionMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logRetentionMs_ = value;
          onChanged();
        } else {
          logRetentionMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public Builder setLogRetentionMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logRetentionMsBuilder_ == null) {
          logRetentionMs_ = builderForValue.build();
          onChanged();
        } else {
          logRetentionMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public Builder mergeLogRetentionMs(com.google.protobuf.Int64Value value) {
        if (logRetentionMsBuilder_ == null) {
          if (logRetentionMs_ != null) {
            logRetentionMs_ =
              com.google.protobuf.Int64Value.newBuilder(logRetentionMs_).mergeFrom(value).buildPartial();
          } else {
            logRetentionMs_ = value;
          }
          onChanged();
        } else {
          logRetentionMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public Builder clearLogRetentionMs() {
        if (logRetentionMsBuilder_ == null) {
          logRetentionMs_ = null;
          onChanged();
        } else {
          logRetentionMs_ = null;
          logRetentionMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogRetentionMsBuilder() {
        
        onChanged();
        return getLogRetentionMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogRetentionMsOrBuilder() {
        if (logRetentionMsBuilder_ != null) {
          return logRetentionMsBuilder_.getMessageOrBuilder();
        } else {
          return logRetentionMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMs_;
        }
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogRetentionMsFieldBuilder() {
        if (logRetentionMsBuilder_ == null) {
          logRetentionMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogRetentionMs(),
                  getParentForChildren(),
                  isClean());
          logRetentionMs_ = null;
        }
        return logRetentionMsBuilder_;
      }

      private com.google.protobuf.Int64Value logSegmentBytes_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logSegmentBytesBuilder_;
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public boolean hasLogSegmentBytes() {
        return logSegmentBytesBuilder_ != null || logSegmentBytes_ != null;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public com.google.protobuf.Int64Value getLogSegmentBytes() {
        if (logSegmentBytesBuilder_ == null) {
          return logSegmentBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logSegmentBytes_;
        } else {
          return logSegmentBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public Builder setLogSegmentBytes(com.google.protobuf.Int64Value value) {
        if (logSegmentBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logSegmentBytes_ = value;
          onChanged();
        } else {
          logSegmentBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public Builder setLogSegmentBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logSegmentBytesBuilder_ == null) {
          logSegmentBytes_ = builderForValue.build();
          onChanged();
        } else {
          logSegmentBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public Builder mergeLogSegmentBytes(com.google.protobuf.Int64Value value) {
        if (logSegmentBytesBuilder_ == null) {
          if (logSegmentBytes_ != null) {
            logSegmentBytes_ =
              com.google.protobuf.Int64Value.newBuilder(logSegmentBytes_).mergeFrom(value).buildPartial();
          } else {
            logSegmentBytes_ = value;
          }
          onChanged();
        } else {
          logSegmentBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public Builder clearLogSegmentBytes() {
        if (logSegmentBytesBuilder_ == null) {
          logSegmentBytes_ = null;
          onChanged();
        } else {
          logSegmentBytes_ = null;
          logSegmentBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogSegmentBytesBuilder() {
        
        onChanged();
        return getLogSegmentBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogSegmentBytesOrBuilder() {
        if (logSegmentBytesBuilder_ != null) {
          return logSegmentBytesBuilder_.getMessageOrBuilder();
        } else {
          return logSegmentBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logSegmentBytes_;
        }
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogSegmentBytesFieldBuilder() {
        if (logSegmentBytesBuilder_ == null) {
          logSegmentBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogSegmentBytes(),
                  getParentForChildren(),
                  isClean());
          logSegmentBytes_ = null;
        }
        return logSegmentBytesBuilder_;
      }

      private com.google.protobuf.BoolValue logPreallocate_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder> logPreallocateBuilder_;
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public boolean hasLogPreallocate() {
        return logPreallocateBuilder_ != null || logPreallocate_ != null;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public com.google.protobuf.BoolValue getLogPreallocate() {
        if (logPreallocateBuilder_ == null) {
          return logPreallocate_ == null ? com.google.protobuf.BoolValue.getDefaultInstance() : logPreallocate_;
        } else {
          return logPreallocateBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public Builder setLogPreallocate(com.google.protobuf.BoolValue value) {
        if (logPreallocateBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logPreallocate_ = value;
          onChanged();
        } else {
          logPreallocateBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public Builder setLogPreallocate(
          com.google.protobuf.BoolValue.Builder builderForValue) {
        if (logPreallocateBuilder_ == null) {
          logPreallocate_ = builderForValue.build();
          onChanged();
        } else {
          logPreallocateBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public Builder mergeLogPreallocate(com.google.protobuf.BoolValue value) {
        if (logPreallocateBuilder_ == null) {
          if (logPreallocate_ != null) {
            logPreallocate_ =
              com.google.protobuf.BoolValue.newBuilder(logPreallocate_).mergeFrom(value).buildPartial();
          } else {
            logPreallocate_ = value;
          }
          onChanged();
        } else {
          logPreallocateBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public Builder clearLogPreallocate() {
        if (logPreallocateBuilder_ == null) {
          logPreallocate_ = null;
          onChanged();
        } else {
          logPreallocate_ = null;
          logPreallocateBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public com.google.protobuf.BoolValue.Builder getLogPreallocateBuilder() {
        
        onChanged();
        return getLogPreallocateFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public com.google.protobuf.BoolValueOrBuilder getLogPreallocateOrBuilder() {
        if (logPreallocateBuilder_ != null) {
          return logPreallocateBuilder_.getMessageOrBuilder();
        } else {
          return logPreallocate_ == null ?
              com.google.protobuf.BoolValue.getDefaultInstance() : logPreallocate_;
        }
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_6.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder> 
          getLogPreallocateFieldBuilder() {
        if (logPreallocateBuilder_ == null) {
          logPreallocateBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder>(
                  getLogPreallocate(),
                  getParentForChildren(),
                  isClean());
          logPreallocate_ = null;
        }
        return logPreallocateBuilder_;
      }

      private com.google.protobuf.Int64Value socketSendBufferBytes_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> socketSendBufferBytesBuilder_;
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public boolean hasSocketSendBufferBytes() {
        return socketSendBufferBytesBuilder_ != null || socketSendBufferBytes_ != null;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public com.google.protobuf.Int64Value getSocketSendBufferBytes() {
        if (socketSendBufferBytesBuilder_ == null) {
          return socketSendBufferBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : socketSendBufferBytes_;
        } else {
          return socketSendBufferBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public Builder setSocketSendBufferBytes(com.google.protobuf.Int64Value value) {
        if (socketSendBufferBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          socketSendBufferBytes_ = value;
          onChanged();
        } else {
          socketSendBufferBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public Builder setSocketSendBufferBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (socketSendBufferBytesBuilder_ == null) {
          socketSendBufferBytes_ = builderForValue.build();
          onChanged();
        } else {
          socketSendBufferBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public Builder mergeSocketSendBufferBytes(com.google.protobuf.Int64Value value) {
        if (socketSendBufferBytesBuilder_ == null) {
          if (socketSendBufferBytes_ != null) {
            socketSendBufferBytes_ =
              com.google.protobuf.Int64Value.newBuilder(socketSendBufferBytes_).mergeFrom(value).buildPartial();
          } else {
            socketSendBufferBytes_ = value;
          }
          onChanged();
        } else {
          socketSendBufferBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public Builder clearSocketSendBufferBytes() {
        if (socketSendBufferBytesBuilder_ == null) {
          socketSendBufferBytes_ = null;
          onChanged();
        } else {
          socketSendBufferBytes_ = null;
          socketSendBufferBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public com.google.protobuf.Int64Value.Builder getSocketSendBufferBytesBuilder() {
        
        onChanged();
        return getSocketSendBufferBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getSocketSendBufferBytesOrBuilder() {
        if (socketSendBufferBytesBuilder_ != null) {
          return socketSendBufferBytesBuilder_.getMessageOrBuilder();
        } else {
          return socketSendBufferBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : socketSendBufferBytes_;
        }
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getSocketSendBufferBytesFieldBuilder() {
        if (socketSendBufferBytesBuilder_ == null) {
          socketSendBufferBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getSocketSendBufferBytes(),
                  getParentForChildren(),
                  isClean());
          socketSendBufferBytes_ = null;
        }
        return socketSendBufferBytesBuilder_;
      }

      private com.google.protobuf.Int64Value socketReceiveBufferBytes_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> socketReceiveBufferBytesBuilder_;
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public boolean hasSocketReceiveBufferBytes() {
        return socketReceiveBufferBytesBuilder_ != null || socketReceiveBufferBytes_ != null;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public com.google.protobuf.Int64Value getSocketReceiveBufferBytes() {
        if (socketReceiveBufferBytesBuilder_ == null) {
          return socketReceiveBufferBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : socketReceiveBufferBytes_;
        } else {
          return socketReceiveBufferBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public Builder setSocketReceiveBufferBytes(com.google.protobuf.Int64Value value) {
        if (socketReceiveBufferBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          socketReceiveBufferBytes_ = value;
          onChanged();
        } else {
          socketReceiveBufferBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public Builder setSocketReceiveBufferBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (socketReceiveBufferBytesBuilder_ == null) {
          socketReceiveBufferBytes_ = builderForValue.build();
          onChanged();
        } else {
          socketReceiveBufferBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public Builder mergeSocketReceiveBufferBytes(com.google.protobuf.Int64Value value) {
        if (socketReceiveBufferBytesBuilder_ == null) {
          if (socketReceiveBufferBytes_ != null) {
            socketReceiveBufferBytes_ =
              com.google.protobuf.Int64Value.newBuilder(socketReceiveBufferBytes_).mergeFrom(value).buildPartial();
          } else {
            socketReceiveBufferBytes_ = value;
          }
          onChanged();
        } else {
          socketReceiveBufferBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public Builder clearSocketReceiveBufferBytes() {
        if (socketReceiveBufferBytesBuilder_ == null) {
          socketReceiveBufferBytes_ = null;
          onChanged();
        } else {
          socketReceiveBufferBytes_ = null;
          socketReceiveBufferBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public com.google.protobuf.Int64Value.Builder getSocketReceiveBufferBytesBuilder() {
        
        onChanged();
        return getSocketReceiveBufferBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getSocketReceiveBufferBytesOrBuilder() {
        if (socketReceiveBufferBytesBuilder_ != null) {
          return socketReceiveBufferBytesBuilder_.getMessageOrBuilder();
        } else {
          return socketReceiveBufferBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : socketReceiveBufferBytes_;
        }
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getSocketReceiveBufferBytesFieldBuilder() {
        if (socketReceiveBufferBytesBuilder_ == null) {
          socketReceiveBufferBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getSocketReceiveBufferBytes(),
                  getParentForChildren(),
                  isClean());
          socketReceiveBufferBytes_ = null;
        }
        return socketReceiveBufferBytesBuilder_;
      }

      private com.google.protobuf.BoolValue autoCreateTopicsEnable_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder> autoCreateTopicsEnableBuilder_;
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public boolean hasAutoCreateTopicsEnable() {
        return autoCreateTopicsEnableBuilder_ != null || autoCreateTopicsEnable_ != null;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public com.google.protobuf.BoolValue getAutoCreateTopicsEnable() {
        if (autoCreateTopicsEnableBuilder_ == null) {
          return autoCreateTopicsEnable_ == null ? com.google.protobuf.BoolValue.getDefaultInstance() : autoCreateTopicsEnable_;
        } else {
          return autoCreateTopicsEnableBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public Builder setAutoCreateTopicsEnable(com.google.protobuf.BoolValue value) {
        if (autoCreateTopicsEnableBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          autoCreateTopicsEnable_ = value;
          onChanged();
        } else {
          autoCreateTopicsEnableBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public Builder setAutoCreateTopicsEnable(
          com.google.protobuf.BoolValue.Builder builderForValue) {
        if (autoCreateTopicsEnableBuilder_ == null) {
          autoCreateTopicsEnable_ = builderForValue.build();
          onChanged();
        } else {
          autoCreateTopicsEnableBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public Builder mergeAutoCreateTopicsEnable(com.google.protobuf.BoolValue value) {
        if (autoCreateTopicsEnableBuilder_ == null) {
          if (autoCreateTopicsEnable_ != null) {
            autoCreateTopicsEnable_ =
              com.google.protobuf.BoolValue.newBuilder(autoCreateTopicsEnable_).mergeFrom(value).buildPartial();
          } else {
            autoCreateTopicsEnable_ = value;
          }
          onChanged();
        } else {
          autoCreateTopicsEnableBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public Builder clearAutoCreateTopicsEnable() {
        if (autoCreateTopicsEnableBuilder_ == null) {
          autoCreateTopicsEnable_ = null;
          onChanged();
        } else {
          autoCreateTopicsEnable_ = null;
          autoCreateTopicsEnableBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public com.google.protobuf.BoolValue.Builder getAutoCreateTopicsEnableBuilder() {
        
        onChanged();
        return getAutoCreateTopicsEnableFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public com.google.protobuf.BoolValueOrBuilder getAutoCreateTopicsEnableOrBuilder() {
        if (autoCreateTopicsEnableBuilder_ != null) {
          return autoCreateTopicsEnableBuilder_.getMessageOrBuilder();
        } else {
          return autoCreateTopicsEnable_ == null ?
              com.google.protobuf.BoolValue.getDefaultInstance() : autoCreateTopicsEnable_;
        }
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder> 
          getAutoCreateTopicsEnableFieldBuilder() {
        if (autoCreateTopicsEnableBuilder_ == null) {
          autoCreateTopicsEnableBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder>(
                  getAutoCreateTopicsEnable(),
                  getParentForChildren(),
                  isClean());
          autoCreateTopicsEnable_ = null;
        }
        return autoCreateTopicsEnableBuilder_;
      }

      private com.google.protobuf.Int64Value numPartitions_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> numPartitionsBuilder_;
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public boolean hasNumPartitions() {
        return numPartitionsBuilder_ != null || numPartitions_ != null;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public com.google.protobuf.Int64Value getNumPartitions() {
        if (numPartitionsBuilder_ == null) {
          return numPartitions_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : numPartitions_;
        } else {
          return numPartitionsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public Builder setNumPartitions(com.google.protobuf.Int64Value value) {
        if (numPartitionsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          numPartitions_ = value;
          onChanged();
        } else {
          numPartitionsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public Builder setNumPartitions(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (numPartitionsBuilder_ == null) {
          numPartitions_ = builderForValue.build();
          onChanged();
        } else {
          numPartitionsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public Builder mergeNumPartitions(com.google.protobuf.Int64Value value) {
        if (numPartitionsBuilder_ == null) {
          if (numPartitions_ != null) {
            numPartitions_ =
              com.google.protobuf.Int64Value.newBuilder(numPartitions_).mergeFrom(value).buildPartial();
          } else {
            numPartitions_ = value;
          }
          onChanged();
        } else {
          numPartitionsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public Builder clearNumPartitions() {
        if (numPartitionsBuilder_ == null) {
          numPartitions_ = null;
          onChanged();
        } else {
          numPartitions_ = null;
          numPartitionsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public com.google.protobuf.Int64Value.Builder getNumPartitionsBuilder() {
        
        onChanged();
        return getNumPartitionsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getNumPartitionsOrBuilder() {
        if (numPartitionsBuilder_ != null) {
          return numPartitionsBuilder_.getMessageOrBuilder();
        } else {
          return numPartitions_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : numPartitions_;
        }
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getNumPartitionsFieldBuilder() {
        if (numPartitionsBuilder_ == null) {
          numPartitionsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getNumPartitions(),
                  getParentForChildren(),
                  isClean());
          numPartitions_ = null;
        }
        return numPartitionsBuilder_;
      }

      private com.google.protobuf.Int64Value defaultReplicationFactor_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> defaultReplicationFactorBuilder_;
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public boolean hasDefaultReplicationFactor() {
        return defaultReplicationFactorBuilder_ != null || defaultReplicationFactor_ != null;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public com.google.protobuf.Int64Value getDefaultReplicationFactor() {
        if (defaultReplicationFactorBuilder_ == null) {
          return defaultReplicationFactor_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : defaultReplicationFactor_;
        } else {
          return defaultReplicationFactorBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public Builder setDefaultReplicationFactor(com.google.protobuf.Int64Value value) {
        if (defaultReplicationFactorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          defaultReplicationFactor_ = value;
          onChanged();
        } else {
          defaultReplicationFactorBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public Builder setDefaultReplicationFactor(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (defaultReplicationFactorBuilder_ == null) {
          defaultReplicationFactor_ = builderForValue.build();
          onChanged();
        } else {
          defaultReplicationFactorBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public Builder mergeDefaultReplicationFactor(com.google.protobuf.Int64Value value) {
        if (defaultReplicationFactorBuilder_ == null) {
          if (defaultReplicationFactor_ != null) {
            defaultReplicationFactor_ =
              com.google.protobuf.Int64Value.newBuilder(defaultReplicationFactor_).mergeFrom(value).buildPartial();
          } else {
            defaultReplicationFactor_ = value;
          }
          onChanged();
        } else {
          defaultReplicationFactorBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public Builder clearDefaultReplicationFactor() {
        if (defaultReplicationFactorBuilder_ == null) {
          defaultReplicationFactor_ = null;
          onChanged();
        } else {
          defaultReplicationFactor_ = null;
          defaultReplicationFactorBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public com.google.protobuf.Int64Value.Builder getDefaultReplicationFactorBuilder() {
        
        onChanged();
        return getDefaultReplicationFactorFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getDefaultReplicationFactorOrBuilder() {
        if (defaultReplicationFactorBuilder_ != null) {
          return defaultReplicationFactorBuilder_.getMessageOrBuilder();
        } else {
          return defaultReplicationFactor_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : defaultReplicationFactor_;
        }
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getDefaultReplicationFactorFieldBuilder() {
        if (defaultReplicationFactorBuilder_ == null) {
          defaultReplicationFactorBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getDefaultReplicationFactor(),
                  getParentForChildren(),
                  isClean());
          defaultReplicationFactor_ = null;
        }
        return defaultReplicationFactorBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.KafkaConfig2_6)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.KafkaConfig2_6)
    private static final yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6();
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<KafkaConfig2_6>
        PARSER = new com.google.protobuf.AbstractParser<KafkaConfig2_6>() {
      @java.lang.Override
      public KafkaConfig2_6 parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new KafkaConfig2_6(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<KafkaConfig2_6> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<KafkaConfig2_6> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_6 getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface KafkaConfig2_8OrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.KafkaConfig2_8)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Cluster topics compression type.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
     */
    int getCompressionTypeValue();
    /**
     * <pre>
     * Cluster topics compression type.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.Common.CompressionType getCompressionType();

    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     */
    boolean hasLogFlushIntervalMessages();
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     */
    com.google.protobuf.Int64Value getLogFlushIntervalMessages();
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMessagesOrBuilder();

    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     */
    boolean hasLogFlushIntervalMs();
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     */
    com.google.protobuf.Int64Value getLogFlushIntervalMs();
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMsOrBuilder();

    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     */
    boolean hasLogFlushSchedulerIntervalMs();
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     */
    com.google.protobuf.Int64Value getLogFlushSchedulerIntervalMs();
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogFlushSchedulerIntervalMsOrBuilder();

    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     */
    boolean hasLogRetentionBytes();
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     */
    com.google.protobuf.Int64Value getLogRetentionBytes();
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogRetentionBytesOrBuilder();

    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     */
    boolean hasLogRetentionHours();
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     */
    com.google.protobuf.Int64Value getLogRetentionHours();
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogRetentionHoursOrBuilder();

    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     */
    boolean hasLogRetentionMinutes();
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     */
    com.google.protobuf.Int64Value getLogRetentionMinutes();
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogRetentionMinutesOrBuilder();

    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     */
    boolean hasLogRetentionMs();
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     */
    com.google.protobuf.Int64Value getLogRetentionMs();
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogRetentionMsOrBuilder();

    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     */
    boolean hasLogSegmentBytes();
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     */
    com.google.protobuf.Int64Value getLogSegmentBytes();
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogSegmentBytesOrBuilder();

    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     */
    boolean hasLogPreallocate();
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     */
    com.google.protobuf.BoolValue getLogPreallocate();
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     */
    com.google.protobuf.BoolValueOrBuilder getLogPreallocateOrBuilder();

    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     */
    boolean hasSocketSendBufferBytes();
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     */
    com.google.protobuf.Int64Value getSocketSendBufferBytes();
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getSocketSendBufferBytesOrBuilder();

    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     */
    boolean hasSocketReceiveBufferBytes();
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     */
    com.google.protobuf.Int64Value getSocketReceiveBufferBytes();
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getSocketReceiveBufferBytesOrBuilder();

    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     */
    boolean hasAutoCreateTopicsEnable();
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     */
    com.google.protobuf.BoolValue getAutoCreateTopicsEnable();
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     */
    com.google.protobuf.BoolValueOrBuilder getAutoCreateTopicsEnableOrBuilder();

    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     */
    boolean hasNumPartitions();
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     */
    com.google.protobuf.Int64Value getNumPartitions();
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getNumPartitionsOrBuilder();

    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     */
    boolean hasDefaultReplicationFactor();
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     */
    com.google.protobuf.Int64Value getDefaultReplicationFactor();
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getDefaultReplicationFactorOrBuilder();
  }
  /**
   * <pre>
   * Kafka version 2.8 broker configuration.
   * </pre>
   *
   * Protobuf type {@code yandex.cloud.mdb.kafka.v1.KafkaConfig2_8}
   */
  public  static final class KafkaConfig2_8 extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.KafkaConfig2_8)
      KafkaConfig2_8OrBuilder {
  private static final long serialVersionUID = 0L;
    // Use KafkaConfig2_8.newBuilder() to construct.
    private KafkaConfig2_8(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private KafkaConfig2_8() {
      compressionType_ = 0;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private KafkaConfig2_8(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              int rawValue = input.readEnum();

              compressionType_ = rawValue;
              break;
            }
            case 18: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logFlushIntervalMessages_ != null) {
                subBuilder = logFlushIntervalMessages_.toBuilder();
              }
              logFlushIntervalMessages_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logFlushIntervalMessages_);
                logFlushIntervalMessages_ = subBuilder.buildPartial();
              }

              break;
            }
            case 26: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logFlushIntervalMs_ != null) {
                subBuilder = logFlushIntervalMs_.toBuilder();
              }
              logFlushIntervalMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logFlushIntervalMs_);
                logFlushIntervalMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 34: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logFlushSchedulerIntervalMs_ != null) {
                subBuilder = logFlushSchedulerIntervalMs_.toBuilder();
              }
              logFlushSchedulerIntervalMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logFlushSchedulerIntervalMs_);
                logFlushSchedulerIntervalMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 42: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logRetentionBytes_ != null) {
                subBuilder = logRetentionBytes_.toBuilder();
              }
              logRetentionBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logRetentionBytes_);
                logRetentionBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 50: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logRetentionHours_ != null) {
                subBuilder = logRetentionHours_.toBuilder();
              }
              logRetentionHours_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logRetentionHours_);
                logRetentionHours_ = subBuilder.buildPartial();
              }

              break;
            }
            case 58: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logRetentionMinutes_ != null) {
                subBuilder = logRetentionMinutes_.toBuilder();
              }
              logRetentionMinutes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logRetentionMinutes_);
                logRetentionMinutes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 66: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logRetentionMs_ != null) {
                subBuilder = logRetentionMs_.toBuilder();
              }
              logRetentionMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logRetentionMs_);
                logRetentionMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 74: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logSegmentBytes_ != null) {
                subBuilder = logSegmentBytes_.toBuilder();
              }
              logSegmentBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logSegmentBytes_);
                logSegmentBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 82: {
              com.google.protobuf.BoolValue.Builder subBuilder = null;
              if (logPreallocate_ != null) {
                subBuilder = logPreallocate_.toBuilder();
              }
              logPreallocate_ = input.readMessage(com.google.protobuf.BoolValue.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logPreallocate_);
                logPreallocate_ = subBuilder.buildPartial();
              }

              break;
            }
            case 90: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (socketSendBufferBytes_ != null) {
                subBuilder = socketSendBufferBytes_.toBuilder();
              }
              socketSendBufferBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(socketSendBufferBytes_);
                socketSendBufferBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 98: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (socketReceiveBufferBytes_ != null) {
                subBuilder = socketReceiveBufferBytes_.toBuilder();
              }
              socketReceiveBufferBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(socketReceiveBufferBytes_);
                socketReceiveBufferBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 106: {
              com.google.protobuf.BoolValue.Builder subBuilder = null;
              if (autoCreateTopicsEnable_ != null) {
                subBuilder = autoCreateTopicsEnable_.toBuilder();
              }
              autoCreateTopicsEnable_ = input.readMessage(com.google.protobuf.BoolValue.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(autoCreateTopicsEnable_);
                autoCreateTopicsEnable_ = subBuilder.buildPartial();
              }

              break;
            }
            case 114: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (numPartitions_ != null) {
                subBuilder = numPartitions_.toBuilder();
              }
              numPartitions_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(numPartitions_);
                numPartitions_ = subBuilder.buildPartial();
              }

              break;
            }
            case 122: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (defaultReplicationFactor_ != null) {
                subBuilder = defaultReplicationFactor_.toBuilder();
              }
              defaultReplicationFactor_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(defaultReplicationFactor_);
                defaultReplicationFactor_ = subBuilder.buildPartial();
              }

              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_8_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_8_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.Builder.class);
    }

    public static final int COMPRESSION_TYPE_FIELD_NUMBER = 1;
    private int compressionType_;
    /**
     * <pre>
     * Cluster topics compression type.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
     */
    public int getCompressionTypeValue() {
      return compressionType_;
    }
    /**
     * <pre>
     * Cluster topics compression type.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.Common.CompressionType getCompressionType() {
      @SuppressWarnings("deprecation")
      yandex.cloud.api.mdb.kafka.v1.Common.CompressionType result = yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.valueOf(compressionType_);
      return result == null ? yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.UNRECOGNIZED : result;
    }

    public static final int LOG_FLUSH_INTERVAL_MESSAGES_FIELD_NUMBER = 2;
    private com.google.protobuf.Int64Value logFlushIntervalMessages_;
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     */
    public boolean hasLogFlushIntervalMessages() {
      return logFlushIntervalMessages_ != null;
    }
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     */
    public com.google.protobuf.Int64Value getLogFlushIntervalMessages() {
      return logFlushIntervalMessages_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMessages_;
    }
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMessagesOrBuilder() {
      return getLogFlushIntervalMessages();
    }

    public static final int LOG_FLUSH_INTERVAL_MS_FIELD_NUMBER = 3;
    private com.google.protobuf.Int64Value logFlushIntervalMs_;
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     */
    public boolean hasLogFlushIntervalMs() {
      return logFlushIntervalMs_ != null;
    }
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     */
    public com.google.protobuf.Int64Value getLogFlushIntervalMs() {
      return logFlushIntervalMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMs_;
    }
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMsOrBuilder() {
      return getLogFlushIntervalMs();
    }

    public static final int LOG_FLUSH_SCHEDULER_INTERVAL_MS_FIELD_NUMBER = 4;
    private com.google.protobuf.Int64Value logFlushSchedulerIntervalMs_;
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     */
    public boolean hasLogFlushSchedulerIntervalMs() {
      return logFlushSchedulerIntervalMs_ != null;
    }
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     */
    public com.google.protobuf.Int64Value getLogFlushSchedulerIntervalMs() {
      return logFlushSchedulerIntervalMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushSchedulerIntervalMs_;
    }
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getLogFlushSchedulerIntervalMsOrBuilder() {
      return getLogFlushSchedulerIntervalMs();
    }

    public static final int LOG_RETENTION_BYTES_FIELD_NUMBER = 5;
    private com.google.protobuf.Int64Value logRetentionBytes_;
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     */
    public boolean hasLogRetentionBytes() {
      return logRetentionBytes_ != null;
    }
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     */
    public com.google.protobuf.Int64Value getLogRetentionBytes() {
      return logRetentionBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionBytes_;
    }
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getLogRetentionBytesOrBuilder() {
      return getLogRetentionBytes();
    }

    public static final int LOG_RETENTION_HOURS_FIELD_NUMBER = 6;
    private com.google.protobuf.Int64Value logRetentionHours_;
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     */
    public boolean hasLogRetentionHours() {
      return logRetentionHours_ != null;
    }
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     */
    public com.google.protobuf.Int64Value getLogRetentionHours() {
      return logRetentionHours_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionHours_;
    }
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getLogRetentionHoursOrBuilder() {
      return getLogRetentionHours();
    }

    public static final int LOG_RETENTION_MINUTES_FIELD_NUMBER = 7;
    private com.google.protobuf.Int64Value logRetentionMinutes_;
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     */
    public boolean hasLogRetentionMinutes() {
      return logRetentionMinutes_ != null;
    }
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     */
    public com.google.protobuf.Int64Value getLogRetentionMinutes() {
      return logRetentionMinutes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMinutes_;
    }
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getLogRetentionMinutesOrBuilder() {
      return getLogRetentionMinutes();
    }

    public static final int LOG_RETENTION_MS_FIELD_NUMBER = 8;
    private com.google.protobuf.Int64Value logRetentionMs_;
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     */
    public boolean hasLogRetentionMs() {
      return logRetentionMs_ != null;
    }
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     */
    public com.google.protobuf.Int64Value getLogRetentionMs() {
      return logRetentionMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMs_;
    }
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getLogRetentionMsOrBuilder() {
      return getLogRetentionMs();
    }

    public static final int LOG_SEGMENT_BYTES_FIELD_NUMBER = 9;
    private com.google.protobuf.Int64Value logSegmentBytes_;
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     */
    public boolean hasLogSegmentBytes() {
      return logSegmentBytes_ != null;
    }
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     */
    public com.google.protobuf.Int64Value getLogSegmentBytes() {
      return logSegmentBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logSegmentBytes_;
    }
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getLogSegmentBytesOrBuilder() {
      return getLogSegmentBytes();
    }

    public static final int LOG_PREALLOCATE_FIELD_NUMBER = 10;
    private com.google.protobuf.BoolValue logPreallocate_;
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     */
    public boolean hasLogPreallocate() {
      return logPreallocate_ != null;
    }
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     */
    public com.google.protobuf.BoolValue getLogPreallocate() {
      return logPreallocate_ == null ? com.google.protobuf.BoolValue.getDefaultInstance() : logPreallocate_;
    }
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     */
    public com.google.protobuf.BoolValueOrBuilder getLogPreallocateOrBuilder() {
      return getLogPreallocate();
    }

    public static final int SOCKET_SEND_BUFFER_BYTES_FIELD_NUMBER = 11;
    private com.google.protobuf.Int64Value socketSendBufferBytes_;
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     */
    public boolean hasSocketSendBufferBytes() {
      return socketSendBufferBytes_ != null;
    }
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     */
    public com.google.protobuf.Int64Value getSocketSendBufferBytes() {
      return socketSendBufferBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : socketSendBufferBytes_;
    }
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getSocketSendBufferBytesOrBuilder() {
      return getSocketSendBufferBytes();
    }

    public static final int SOCKET_RECEIVE_BUFFER_BYTES_FIELD_NUMBER = 12;
    private com.google.protobuf.Int64Value socketReceiveBufferBytes_;
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     */
    public boolean hasSocketReceiveBufferBytes() {
      return socketReceiveBufferBytes_ != null;
    }
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     */
    public com.google.protobuf.Int64Value getSocketReceiveBufferBytes() {
      return socketReceiveBufferBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : socketReceiveBufferBytes_;
    }
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getSocketReceiveBufferBytesOrBuilder() {
      return getSocketReceiveBufferBytes();
    }

    public static final int AUTO_CREATE_TOPICS_ENABLE_FIELD_NUMBER = 13;
    private com.google.protobuf.BoolValue autoCreateTopicsEnable_;
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     */
    public boolean hasAutoCreateTopicsEnable() {
      return autoCreateTopicsEnable_ != null;
    }
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     */
    public com.google.protobuf.BoolValue getAutoCreateTopicsEnable() {
      return autoCreateTopicsEnable_ == null ? com.google.protobuf.BoolValue.getDefaultInstance() : autoCreateTopicsEnable_;
    }
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     */
    public com.google.protobuf.BoolValueOrBuilder getAutoCreateTopicsEnableOrBuilder() {
      return getAutoCreateTopicsEnable();
    }

    public static final int NUM_PARTITIONS_FIELD_NUMBER = 14;
    private com.google.protobuf.Int64Value numPartitions_;
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     */
    public boolean hasNumPartitions() {
      return numPartitions_ != null;
    }
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     */
    public com.google.protobuf.Int64Value getNumPartitions() {
      return numPartitions_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : numPartitions_;
    }
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getNumPartitionsOrBuilder() {
      return getNumPartitions();
    }

    public static final int DEFAULT_REPLICATION_FACTOR_FIELD_NUMBER = 15;
    private com.google.protobuf.Int64Value defaultReplicationFactor_;
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     */
    public boolean hasDefaultReplicationFactor() {
      return defaultReplicationFactor_ != null;
    }
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     */
    public com.google.protobuf.Int64Value getDefaultReplicationFactor() {
      return defaultReplicationFactor_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : defaultReplicationFactor_;
    }
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getDefaultReplicationFactorOrBuilder() {
      return getDefaultReplicationFactor();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (compressionType_ != yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.COMPRESSION_TYPE_UNSPECIFIED.getNumber()) {
        output.writeEnum(1, compressionType_);
      }
      if (logFlushIntervalMessages_ != null) {
        output.writeMessage(2, getLogFlushIntervalMessages());
      }
      if (logFlushIntervalMs_ != null) {
        output.writeMessage(3, getLogFlushIntervalMs());
      }
      if (logFlushSchedulerIntervalMs_ != null) {
        output.writeMessage(4, getLogFlushSchedulerIntervalMs());
      }
      if (logRetentionBytes_ != null) {
        output.writeMessage(5, getLogRetentionBytes());
      }
      if (logRetentionHours_ != null) {
        output.writeMessage(6, getLogRetentionHours());
      }
      if (logRetentionMinutes_ != null) {
        output.writeMessage(7, getLogRetentionMinutes());
      }
      if (logRetentionMs_ != null) {
        output.writeMessage(8, getLogRetentionMs());
      }
      if (logSegmentBytes_ != null) {
        output.writeMessage(9, getLogSegmentBytes());
      }
      if (logPreallocate_ != null) {
        output.writeMessage(10, getLogPreallocate());
      }
      if (socketSendBufferBytes_ != null) {
        output.writeMessage(11, getSocketSendBufferBytes());
      }
      if (socketReceiveBufferBytes_ != null) {
        output.writeMessage(12, getSocketReceiveBufferBytes());
      }
      if (autoCreateTopicsEnable_ != null) {
        output.writeMessage(13, getAutoCreateTopicsEnable());
      }
      if (numPartitions_ != null) {
        output.writeMessage(14, getNumPartitions());
      }
      if (defaultReplicationFactor_ != null) {
        output.writeMessage(15, getDefaultReplicationFactor());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (compressionType_ != yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.COMPRESSION_TYPE_UNSPECIFIED.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, compressionType_);
      }
      if (logFlushIntervalMessages_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getLogFlushIntervalMessages());
      }
      if (logFlushIntervalMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getLogFlushIntervalMs());
      }
      if (logFlushSchedulerIntervalMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getLogFlushSchedulerIntervalMs());
      }
      if (logRetentionBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getLogRetentionBytes());
      }
      if (logRetentionHours_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, getLogRetentionHours());
      }
      if (logRetentionMinutes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, getLogRetentionMinutes());
      }
      if (logRetentionMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(8, getLogRetentionMs());
      }
      if (logSegmentBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(9, getLogSegmentBytes());
      }
      if (logPreallocate_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(10, getLogPreallocate());
      }
      if (socketSendBufferBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(11, getSocketSendBufferBytes());
      }
      if (socketReceiveBufferBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(12, getSocketReceiveBufferBytes());
      }
      if (autoCreateTopicsEnable_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(13, getAutoCreateTopicsEnable());
      }
      if (numPartitions_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(14, getNumPartitions());
      }
      if (defaultReplicationFactor_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(15, getDefaultReplicationFactor());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8)) {
        return super.equals(obj);
      }
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 other = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) obj;

      boolean result = true;
      result = result && compressionType_ == other.compressionType_;
      result = result && (hasLogFlushIntervalMessages() == other.hasLogFlushIntervalMessages());
      if (hasLogFlushIntervalMessages()) {
        result = result && getLogFlushIntervalMessages()
            .equals(other.getLogFlushIntervalMessages());
      }
      result = result && (hasLogFlushIntervalMs() == other.hasLogFlushIntervalMs());
      if (hasLogFlushIntervalMs()) {
        result = result && getLogFlushIntervalMs()
            .equals(other.getLogFlushIntervalMs());
      }
      result = result && (hasLogFlushSchedulerIntervalMs() == other.hasLogFlushSchedulerIntervalMs());
      if (hasLogFlushSchedulerIntervalMs()) {
        result = result && getLogFlushSchedulerIntervalMs()
            .equals(other.getLogFlushSchedulerIntervalMs());
      }
      result = result && (hasLogRetentionBytes() == other.hasLogRetentionBytes());
      if (hasLogRetentionBytes()) {
        result = result && getLogRetentionBytes()
            .equals(other.getLogRetentionBytes());
      }
      result = result && (hasLogRetentionHours() == other.hasLogRetentionHours());
      if (hasLogRetentionHours()) {
        result = result && getLogRetentionHours()
            .equals(other.getLogRetentionHours());
      }
      result = result && (hasLogRetentionMinutes() == other.hasLogRetentionMinutes());
      if (hasLogRetentionMinutes()) {
        result = result && getLogRetentionMinutes()
            .equals(other.getLogRetentionMinutes());
      }
      result = result && (hasLogRetentionMs() == other.hasLogRetentionMs());
      if (hasLogRetentionMs()) {
        result = result && getLogRetentionMs()
            .equals(other.getLogRetentionMs());
      }
      result = result && (hasLogSegmentBytes() == other.hasLogSegmentBytes());
      if (hasLogSegmentBytes()) {
        result = result && getLogSegmentBytes()
            .equals(other.getLogSegmentBytes());
      }
      result = result && (hasLogPreallocate() == other.hasLogPreallocate());
      if (hasLogPreallocate()) {
        result = result && getLogPreallocate()
            .equals(other.getLogPreallocate());
      }
      result = result && (hasSocketSendBufferBytes() == other.hasSocketSendBufferBytes());
      if (hasSocketSendBufferBytes()) {
        result = result && getSocketSendBufferBytes()
            .equals(other.getSocketSendBufferBytes());
      }
      result = result && (hasSocketReceiveBufferBytes() == other.hasSocketReceiveBufferBytes());
      if (hasSocketReceiveBufferBytes()) {
        result = result && getSocketReceiveBufferBytes()
            .equals(other.getSocketReceiveBufferBytes());
      }
      result = result && (hasAutoCreateTopicsEnable() == other.hasAutoCreateTopicsEnable());
      if (hasAutoCreateTopicsEnable()) {
        result = result && getAutoCreateTopicsEnable()
            .equals(other.getAutoCreateTopicsEnable());
      }
      result = result && (hasNumPartitions() == other.hasNumPartitions());
      if (hasNumPartitions()) {
        result = result && getNumPartitions()
            .equals(other.getNumPartitions());
      }
      result = result && (hasDefaultReplicationFactor() == other.hasDefaultReplicationFactor());
      if (hasDefaultReplicationFactor()) {
        result = result && getDefaultReplicationFactor()
            .equals(other.getDefaultReplicationFactor());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + COMPRESSION_TYPE_FIELD_NUMBER;
      hash = (53 * hash) + compressionType_;
      if (hasLogFlushIntervalMessages()) {
        hash = (37 * hash) + LOG_FLUSH_INTERVAL_MESSAGES_FIELD_NUMBER;
        hash = (53 * hash) + getLogFlushIntervalMessages().hashCode();
      }
      if (hasLogFlushIntervalMs()) {
        hash = (37 * hash) + LOG_FLUSH_INTERVAL_MS_FIELD_NUMBER;
        hash = (53 * hash) + getLogFlushIntervalMs().hashCode();
      }
      if (hasLogFlushSchedulerIntervalMs()) {
        hash = (37 * hash) + LOG_FLUSH_SCHEDULER_INTERVAL_MS_FIELD_NUMBER;
        hash = (53 * hash) + getLogFlushSchedulerIntervalMs().hashCode();
      }
      if (hasLogRetentionBytes()) {
        hash = (37 * hash) + LOG_RETENTION_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getLogRetentionBytes().hashCode();
      }
      if (hasLogRetentionHours()) {
        hash = (37 * hash) + LOG_RETENTION_HOURS_FIELD_NUMBER;
        hash = (53 * hash) + getLogRetentionHours().hashCode();
      }
      if (hasLogRetentionMinutes()) {
        hash = (37 * hash) + LOG_RETENTION_MINUTES_FIELD_NUMBER;
        hash = (53 * hash) + getLogRetentionMinutes().hashCode();
      }
      if (hasLogRetentionMs()) {
        hash = (37 * hash) + LOG_RETENTION_MS_FIELD_NUMBER;
        hash = (53 * hash) + getLogRetentionMs().hashCode();
      }
      if (hasLogSegmentBytes()) {
        hash = (37 * hash) + LOG_SEGMENT_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getLogSegmentBytes().hashCode();
      }
      if (hasLogPreallocate()) {
        hash = (37 * hash) + LOG_PREALLOCATE_FIELD_NUMBER;
        hash = (53 * hash) + getLogPreallocate().hashCode();
      }
      if (hasSocketSendBufferBytes()) {
        hash = (37 * hash) + SOCKET_SEND_BUFFER_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getSocketSendBufferBytes().hashCode();
      }
      if (hasSocketReceiveBufferBytes()) {
        hash = (37 * hash) + SOCKET_RECEIVE_BUFFER_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getSocketReceiveBufferBytes().hashCode();
      }
      if (hasAutoCreateTopicsEnable()) {
        hash = (37 * hash) + AUTO_CREATE_TOPICS_ENABLE_FIELD_NUMBER;
        hash = (53 * hash) + getAutoCreateTopicsEnable().hashCode();
      }
      if (hasNumPartitions()) {
        hash = (37 * hash) + NUM_PARTITIONS_FIELD_NUMBER;
        hash = (53 * hash) + getNumPartitions().hashCode();
      }
      if (hasDefaultReplicationFactor()) {
        hash = (37 * hash) + DEFAULT_REPLICATION_FACTOR_FIELD_NUMBER;
        hash = (53 * hash) + getDefaultReplicationFactor().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Kafka version 2.8 broker configuration.
     * </pre>
     *
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.KafkaConfig2_8}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.KafkaConfig2_8)
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8OrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_8_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_8_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.Builder.class);
      }

      // Construct using yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        compressionType_ = 0;

        if (logFlushIntervalMessagesBuilder_ == null) {
          logFlushIntervalMessages_ = null;
        } else {
          logFlushIntervalMessages_ = null;
          logFlushIntervalMessagesBuilder_ = null;
        }
        if (logFlushIntervalMsBuilder_ == null) {
          logFlushIntervalMs_ = null;
        } else {
          logFlushIntervalMs_ = null;
          logFlushIntervalMsBuilder_ = null;
        }
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          logFlushSchedulerIntervalMs_ = null;
        } else {
          logFlushSchedulerIntervalMs_ = null;
          logFlushSchedulerIntervalMsBuilder_ = null;
        }
        if (logRetentionBytesBuilder_ == null) {
          logRetentionBytes_ = null;
        } else {
          logRetentionBytes_ = null;
          logRetentionBytesBuilder_ = null;
        }
        if (logRetentionHoursBuilder_ == null) {
          logRetentionHours_ = null;
        } else {
          logRetentionHours_ = null;
          logRetentionHoursBuilder_ = null;
        }
        if (logRetentionMinutesBuilder_ == null) {
          logRetentionMinutes_ = null;
        } else {
          logRetentionMinutes_ = null;
          logRetentionMinutesBuilder_ = null;
        }
        if (logRetentionMsBuilder_ == null) {
          logRetentionMs_ = null;
        } else {
          logRetentionMs_ = null;
          logRetentionMsBuilder_ = null;
        }
        if (logSegmentBytesBuilder_ == null) {
          logSegmentBytes_ = null;
        } else {
          logSegmentBytes_ = null;
          logSegmentBytesBuilder_ = null;
        }
        if (logPreallocateBuilder_ == null) {
          logPreallocate_ = null;
        } else {
          logPreallocate_ = null;
          logPreallocateBuilder_ = null;
        }
        if (socketSendBufferBytesBuilder_ == null) {
          socketSendBufferBytes_ = null;
        } else {
          socketSendBufferBytes_ = null;
          socketSendBufferBytesBuilder_ = null;
        }
        if (socketReceiveBufferBytesBuilder_ == null) {
          socketReceiveBufferBytes_ = null;
        } else {
          socketReceiveBufferBytes_ = null;
          socketReceiveBufferBytesBuilder_ = null;
        }
        if (autoCreateTopicsEnableBuilder_ == null) {
          autoCreateTopicsEnable_ = null;
        } else {
          autoCreateTopicsEnable_ = null;
          autoCreateTopicsEnableBuilder_ = null;
        }
        if (numPartitionsBuilder_ == null) {
          numPartitions_ = null;
        } else {
          numPartitions_ = null;
          numPartitionsBuilder_ = null;
        }
        if (defaultReplicationFactorBuilder_ == null) {
          defaultReplicationFactor_ = null;
        } else {
          defaultReplicationFactor_ = null;
          defaultReplicationFactorBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_8_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 getDefaultInstanceForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 build() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 buildPartial() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 result = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8(this);
        result.compressionType_ = compressionType_;
        if (logFlushIntervalMessagesBuilder_ == null) {
          result.logFlushIntervalMessages_ = logFlushIntervalMessages_;
        } else {
          result.logFlushIntervalMessages_ = logFlushIntervalMessagesBuilder_.build();
        }
        if (logFlushIntervalMsBuilder_ == null) {
          result.logFlushIntervalMs_ = logFlushIntervalMs_;
        } else {
          result.logFlushIntervalMs_ = logFlushIntervalMsBuilder_.build();
        }
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          result.logFlushSchedulerIntervalMs_ = logFlushSchedulerIntervalMs_;
        } else {
          result.logFlushSchedulerIntervalMs_ = logFlushSchedulerIntervalMsBuilder_.build();
        }
        if (logRetentionBytesBuilder_ == null) {
          result.logRetentionBytes_ = logRetentionBytes_;
        } else {
          result.logRetentionBytes_ = logRetentionBytesBuilder_.build();
        }
        if (logRetentionHoursBuilder_ == null) {
          result.logRetentionHours_ = logRetentionHours_;
        } else {
          result.logRetentionHours_ = logRetentionHoursBuilder_.build();
        }
        if (logRetentionMinutesBuilder_ == null) {
          result.logRetentionMinutes_ = logRetentionMinutes_;
        } else {
          result.logRetentionMinutes_ = logRetentionMinutesBuilder_.build();
        }
        if (logRetentionMsBuilder_ == null) {
          result.logRetentionMs_ = logRetentionMs_;
        } else {
          result.logRetentionMs_ = logRetentionMsBuilder_.build();
        }
        if (logSegmentBytesBuilder_ == null) {
          result.logSegmentBytes_ = logSegmentBytes_;
        } else {
          result.logSegmentBytes_ = logSegmentBytesBuilder_.build();
        }
        if (logPreallocateBuilder_ == null) {
          result.logPreallocate_ = logPreallocate_;
        } else {
          result.logPreallocate_ = logPreallocateBuilder_.build();
        }
        if (socketSendBufferBytesBuilder_ == null) {
          result.socketSendBufferBytes_ = socketSendBufferBytes_;
        } else {
          result.socketSendBufferBytes_ = socketSendBufferBytesBuilder_.build();
        }
        if (socketReceiveBufferBytesBuilder_ == null) {
          result.socketReceiveBufferBytes_ = socketReceiveBufferBytes_;
        } else {
          result.socketReceiveBufferBytes_ = socketReceiveBufferBytesBuilder_.build();
        }
        if (autoCreateTopicsEnableBuilder_ == null) {
          result.autoCreateTopicsEnable_ = autoCreateTopicsEnable_;
        } else {
          result.autoCreateTopicsEnable_ = autoCreateTopicsEnableBuilder_.build();
        }
        if (numPartitionsBuilder_ == null) {
          result.numPartitions_ = numPartitions_;
        } else {
          result.numPartitions_ = numPartitionsBuilder_.build();
        }
        if (defaultReplicationFactorBuilder_ == null) {
          result.defaultReplicationFactor_ = defaultReplicationFactor_;
        } else {
          result.defaultReplicationFactor_ = defaultReplicationFactorBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) {
          return mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 other) {
        if (other == yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.getDefaultInstance()) return this;
        if (other.compressionType_ != 0) {
          setCompressionTypeValue(other.getCompressionTypeValue());
        }
        if (other.hasLogFlushIntervalMessages()) {
          mergeLogFlushIntervalMessages(other.getLogFlushIntervalMessages());
        }
        if (other.hasLogFlushIntervalMs()) {
          mergeLogFlushIntervalMs(other.getLogFlushIntervalMs());
        }
        if (other.hasLogFlushSchedulerIntervalMs()) {
          mergeLogFlushSchedulerIntervalMs(other.getLogFlushSchedulerIntervalMs());
        }
        if (other.hasLogRetentionBytes()) {
          mergeLogRetentionBytes(other.getLogRetentionBytes());
        }
        if (other.hasLogRetentionHours()) {
          mergeLogRetentionHours(other.getLogRetentionHours());
        }
        if (other.hasLogRetentionMinutes()) {
          mergeLogRetentionMinutes(other.getLogRetentionMinutes());
        }
        if (other.hasLogRetentionMs()) {
          mergeLogRetentionMs(other.getLogRetentionMs());
        }
        if (other.hasLogSegmentBytes()) {
          mergeLogSegmentBytes(other.getLogSegmentBytes());
        }
        if (other.hasLogPreallocate()) {
          mergeLogPreallocate(other.getLogPreallocate());
        }
        if (other.hasSocketSendBufferBytes()) {
          mergeSocketSendBufferBytes(other.getSocketSendBufferBytes());
        }
        if (other.hasSocketReceiveBufferBytes()) {
          mergeSocketReceiveBufferBytes(other.getSocketReceiveBufferBytes());
        }
        if (other.hasAutoCreateTopicsEnable()) {
          mergeAutoCreateTopicsEnable(other.getAutoCreateTopicsEnable());
        }
        if (other.hasNumPartitions()) {
          mergeNumPartitions(other.getNumPartitions());
        }
        if (other.hasDefaultReplicationFactor()) {
          mergeDefaultReplicationFactor(other.getDefaultReplicationFactor());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private int compressionType_ = 0;
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       */
      public int getCompressionTypeValue() {
        return compressionType_;
      }
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       */
      public Builder setCompressionTypeValue(int value) {
        compressionType_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.Common.CompressionType getCompressionType() {
        @SuppressWarnings("deprecation")
        yandex.cloud.api.mdb.kafka.v1.Common.CompressionType result = yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.valueOf(compressionType_);
        return result == null ? yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       */
      public Builder setCompressionType(yandex.cloud.api.mdb.kafka.v1.Common.CompressionType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        
        compressionType_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       */
      public Builder clearCompressionType() {
        
        compressionType_ = 0;
        onChanged();
        return this;
      }

      private com.google.protobuf.Int64Value logFlushIntervalMessages_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logFlushIntervalMessagesBuilder_;
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public boolean hasLogFlushIntervalMessages() {
        return logFlushIntervalMessagesBuilder_ != null || logFlushIntervalMessages_ != null;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public com.google.protobuf.Int64Value getLogFlushIntervalMessages() {
        if (logFlushIntervalMessagesBuilder_ == null) {
          return logFlushIntervalMessages_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMessages_;
        } else {
          return logFlushIntervalMessagesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public Builder setLogFlushIntervalMessages(com.google.protobuf.Int64Value value) {
        if (logFlushIntervalMessagesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logFlushIntervalMessages_ = value;
          onChanged();
        } else {
          logFlushIntervalMessagesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public Builder setLogFlushIntervalMessages(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logFlushIntervalMessagesBuilder_ == null) {
          logFlushIntervalMessages_ = builderForValue.build();
          onChanged();
        } else {
          logFlushIntervalMessagesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public Builder mergeLogFlushIntervalMessages(com.google.protobuf.Int64Value value) {
        if (logFlushIntervalMessagesBuilder_ == null) {
          if (logFlushIntervalMessages_ != null) {
            logFlushIntervalMessages_ =
              com.google.protobuf.Int64Value.newBuilder(logFlushIntervalMessages_).mergeFrom(value).buildPartial();
          } else {
            logFlushIntervalMessages_ = value;
          }
          onChanged();
        } else {
          logFlushIntervalMessagesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public Builder clearLogFlushIntervalMessages() {
        if (logFlushIntervalMessagesBuilder_ == null) {
          logFlushIntervalMessages_ = null;
          onChanged();
        } else {
          logFlushIntervalMessages_ = null;
          logFlushIntervalMessagesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogFlushIntervalMessagesBuilder() {
        
        onChanged();
        return getLogFlushIntervalMessagesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMessagesOrBuilder() {
        if (logFlushIntervalMessagesBuilder_ != null) {
          return logFlushIntervalMessagesBuilder_.getMessageOrBuilder();
        } else {
          return logFlushIntervalMessages_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMessages_;
        }
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogFlushIntervalMessagesFieldBuilder() {
        if (logFlushIntervalMessagesBuilder_ == null) {
          logFlushIntervalMessagesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogFlushIntervalMessages(),
                  getParentForChildren(),
                  isClean());
          logFlushIntervalMessages_ = null;
        }
        return logFlushIntervalMessagesBuilder_;
      }

      private com.google.protobuf.Int64Value logFlushIntervalMs_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logFlushIntervalMsBuilder_;
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public boolean hasLogFlushIntervalMs() {
        return logFlushIntervalMsBuilder_ != null || logFlushIntervalMs_ != null;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public com.google.protobuf.Int64Value getLogFlushIntervalMs() {
        if (logFlushIntervalMsBuilder_ == null) {
          return logFlushIntervalMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMs_;
        } else {
          return logFlushIntervalMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public Builder setLogFlushIntervalMs(com.google.protobuf.Int64Value value) {
        if (logFlushIntervalMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logFlushIntervalMs_ = value;
          onChanged();
        } else {
          logFlushIntervalMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public Builder setLogFlushIntervalMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logFlushIntervalMsBuilder_ == null) {
          logFlushIntervalMs_ = builderForValue.build();
          onChanged();
        } else {
          logFlushIntervalMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public Builder mergeLogFlushIntervalMs(com.google.protobuf.Int64Value value) {
        if (logFlushIntervalMsBuilder_ == null) {
          if (logFlushIntervalMs_ != null) {
            logFlushIntervalMs_ =
              com.google.protobuf.Int64Value.newBuilder(logFlushIntervalMs_).mergeFrom(value).buildPartial();
          } else {
            logFlushIntervalMs_ = value;
          }
          onChanged();
        } else {
          logFlushIntervalMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public Builder clearLogFlushIntervalMs() {
        if (logFlushIntervalMsBuilder_ == null) {
          logFlushIntervalMs_ = null;
          onChanged();
        } else {
          logFlushIntervalMs_ = null;
          logFlushIntervalMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogFlushIntervalMsBuilder() {
        
        onChanged();
        return getLogFlushIntervalMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMsOrBuilder() {
        if (logFlushIntervalMsBuilder_ != null) {
          return logFlushIntervalMsBuilder_.getMessageOrBuilder();
        } else {
          return logFlushIntervalMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMs_;
        }
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogFlushIntervalMsFieldBuilder() {
        if (logFlushIntervalMsBuilder_ == null) {
          logFlushIntervalMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogFlushIntervalMs(),
                  getParentForChildren(),
                  isClean());
          logFlushIntervalMs_ = null;
        }
        return logFlushIntervalMsBuilder_;
      }

      private com.google.protobuf.Int64Value logFlushSchedulerIntervalMs_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logFlushSchedulerIntervalMsBuilder_;
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public boolean hasLogFlushSchedulerIntervalMs() {
        return logFlushSchedulerIntervalMsBuilder_ != null || logFlushSchedulerIntervalMs_ != null;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public com.google.protobuf.Int64Value getLogFlushSchedulerIntervalMs() {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          return logFlushSchedulerIntervalMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushSchedulerIntervalMs_;
        } else {
          return logFlushSchedulerIntervalMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public Builder setLogFlushSchedulerIntervalMs(com.google.protobuf.Int64Value value) {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logFlushSchedulerIntervalMs_ = value;
          onChanged();
        } else {
          logFlushSchedulerIntervalMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public Builder setLogFlushSchedulerIntervalMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          logFlushSchedulerIntervalMs_ = builderForValue.build();
          onChanged();
        } else {
          logFlushSchedulerIntervalMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public Builder mergeLogFlushSchedulerIntervalMs(com.google.protobuf.Int64Value value) {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          if (logFlushSchedulerIntervalMs_ != null) {
            logFlushSchedulerIntervalMs_ =
              com.google.protobuf.Int64Value.newBuilder(logFlushSchedulerIntervalMs_).mergeFrom(value).buildPartial();
          } else {
            logFlushSchedulerIntervalMs_ = value;
          }
          onChanged();
        } else {
          logFlushSchedulerIntervalMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public Builder clearLogFlushSchedulerIntervalMs() {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          logFlushSchedulerIntervalMs_ = null;
          onChanged();
        } else {
          logFlushSchedulerIntervalMs_ = null;
          logFlushSchedulerIntervalMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogFlushSchedulerIntervalMsBuilder() {
        
        onChanged();
        return getLogFlushSchedulerIntervalMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogFlushSchedulerIntervalMsOrBuilder() {
        if (logFlushSchedulerIntervalMsBuilder_ != null) {
          return logFlushSchedulerIntervalMsBuilder_.getMessageOrBuilder();
        } else {
          return logFlushSchedulerIntervalMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logFlushSchedulerIntervalMs_;
        }
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogFlushSchedulerIntervalMsFieldBuilder() {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          logFlushSchedulerIntervalMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogFlushSchedulerIntervalMs(),
                  getParentForChildren(),
                  isClean());
          logFlushSchedulerIntervalMs_ = null;
        }
        return logFlushSchedulerIntervalMsBuilder_;
      }

      private com.google.protobuf.Int64Value logRetentionBytes_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logRetentionBytesBuilder_;
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public boolean hasLogRetentionBytes() {
        return logRetentionBytesBuilder_ != null || logRetentionBytes_ != null;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public com.google.protobuf.Int64Value getLogRetentionBytes() {
        if (logRetentionBytesBuilder_ == null) {
          return logRetentionBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionBytes_;
        } else {
          return logRetentionBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public Builder setLogRetentionBytes(com.google.protobuf.Int64Value value) {
        if (logRetentionBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logRetentionBytes_ = value;
          onChanged();
        } else {
          logRetentionBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public Builder setLogRetentionBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logRetentionBytesBuilder_ == null) {
          logRetentionBytes_ = builderForValue.build();
          onChanged();
        } else {
          logRetentionBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public Builder mergeLogRetentionBytes(com.google.protobuf.Int64Value value) {
        if (logRetentionBytesBuilder_ == null) {
          if (logRetentionBytes_ != null) {
            logRetentionBytes_ =
              com.google.protobuf.Int64Value.newBuilder(logRetentionBytes_).mergeFrom(value).buildPartial();
          } else {
            logRetentionBytes_ = value;
          }
          onChanged();
        } else {
          logRetentionBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public Builder clearLogRetentionBytes() {
        if (logRetentionBytesBuilder_ == null) {
          logRetentionBytes_ = null;
          onChanged();
        } else {
          logRetentionBytes_ = null;
          logRetentionBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogRetentionBytesBuilder() {
        
        onChanged();
        return getLogRetentionBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogRetentionBytesOrBuilder() {
        if (logRetentionBytesBuilder_ != null) {
          return logRetentionBytesBuilder_.getMessageOrBuilder();
        } else {
          return logRetentionBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionBytes_;
        }
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogRetentionBytesFieldBuilder() {
        if (logRetentionBytesBuilder_ == null) {
          logRetentionBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogRetentionBytes(),
                  getParentForChildren(),
                  isClean());
          logRetentionBytes_ = null;
        }
        return logRetentionBytesBuilder_;
      }

      private com.google.protobuf.Int64Value logRetentionHours_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logRetentionHoursBuilder_;
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public boolean hasLogRetentionHours() {
        return logRetentionHoursBuilder_ != null || logRetentionHours_ != null;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public com.google.protobuf.Int64Value getLogRetentionHours() {
        if (logRetentionHoursBuilder_ == null) {
          return logRetentionHours_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionHours_;
        } else {
          return logRetentionHoursBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public Builder setLogRetentionHours(com.google.protobuf.Int64Value value) {
        if (logRetentionHoursBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logRetentionHours_ = value;
          onChanged();
        } else {
          logRetentionHoursBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public Builder setLogRetentionHours(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logRetentionHoursBuilder_ == null) {
          logRetentionHours_ = builderForValue.build();
          onChanged();
        } else {
          logRetentionHoursBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public Builder mergeLogRetentionHours(com.google.protobuf.Int64Value value) {
        if (logRetentionHoursBuilder_ == null) {
          if (logRetentionHours_ != null) {
            logRetentionHours_ =
              com.google.protobuf.Int64Value.newBuilder(logRetentionHours_).mergeFrom(value).buildPartial();
          } else {
            logRetentionHours_ = value;
          }
          onChanged();
        } else {
          logRetentionHoursBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public Builder clearLogRetentionHours() {
        if (logRetentionHoursBuilder_ == null) {
          logRetentionHours_ = null;
          onChanged();
        } else {
          logRetentionHours_ = null;
          logRetentionHoursBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogRetentionHoursBuilder() {
        
        onChanged();
        return getLogRetentionHoursFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogRetentionHoursOrBuilder() {
        if (logRetentionHoursBuilder_ != null) {
          return logRetentionHoursBuilder_.getMessageOrBuilder();
        } else {
          return logRetentionHours_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionHours_;
        }
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogRetentionHoursFieldBuilder() {
        if (logRetentionHoursBuilder_ == null) {
          logRetentionHoursBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogRetentionHours(),
                  getParentForChildren(),
                  isClean());
          logRetentionHours_ = null;
        }
        return logRetentionHoursBuilder_;
      }

      private com.google.protobuf.Int64Value logRetentionMinutes_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logRetentionMinutesBuilder_;
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public boolean hasLogRetentionMinutes() {
        return logRetentionMinutesBuilder_ != null || logRetentionMinutes_ != null;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public com.google.protobuf.Int64Value getLogRetentionMinutes() {
        if (logRetentionMinutesBuilder_ == null) {
          return logRetentionMinutes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMinutes_;
        } else {
          return logRetentionMinutesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public Builder setLogRetentionMinutes(com.google.protobuf.Int64Value value) {
        if (logRetentionMinutesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logRetentionMinutes_ = value;
          onChanged();
        } else {
          logRetentionMinutesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public Builder setLogRetentionMinutes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logRetentionMinutesBuilder_ == null) {
          logRetentionMinutes_ = builderForValue.build();
          onChanged();
        } else {
          logRetentionMinutesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public Builder mergeLogRetentionMinutes(com.google.protobuf.Int64Value value) {
        if (logRetentionMinutesBuilder_ == null) {
          if (logRetentionMinutes_ != null) {
            logRetentionMinutes_ =
              com.google.protobuf.Int64Value.newBuilder(logRetentionMinutes_).mergeFrom(value).buildPartial();
          } else {
            logRetentionMinutes_ = value;
          }
          onChanged();
        } else {
          logRetentionMinutesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public Builder clearLogRetentionMinutes() {
        if (logRetentionMinutesBuilder_ == null) {
          logRetentionMinutes_ = null;
          onChanged();
        } else {
          logRetentionMinutes_ = null;
          logRetentionMinutesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogRetentionMinutesBuilder() {
        
        onChanged();
        return getLogRetentionMinutesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogRetentionMinutesOrBuilder() {
        if (logRetentionMinutesBuilder_ != null) {
          return logRetentionMinutesBuilder_.getMessageOrBuilder();
        } else {
          return logRetentionMinutes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMinutes_;
        }
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogRetentionMinutesFieldBuilder() {
        if (logRetentionMinutesBuilder_ == null) {
          logRetentionMinutesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogRetentionMinutes(),
                  getParentForChildren(),
                  isClean());
          logRetentionMinutes_ = null;
        }
        return logRetentionMinutesBuilder_;
      }

      private com.google.protobuf.Int64Value logRetentionMs_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logRetentionMsBuilder_;
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public boolean hasLogRetentionMs() {
        return logRetentionMsBuilder_ != null || logRetentionMs_ != null;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public com.google.protobuf.Int64Value getLogRetentionMs() {
        if (logRetentionMsBuilder_ == null) {
          return logRetentionMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMs_;
        } else {
          return logRetentionMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public Builder setLogRetentionMs(com.google.protobuf.Int64Value value) {
        if (logRetentionMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logRetentionMs_ = value;
          onChanged();
        } else {
          logRetentionMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public Builder setLogRetentionMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logRetentionMsBuilder_ == null) {
          logRetentionMs_ = builderForValue.build();
          onChanged();
        } else {
          logRetentionMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public Builder mergeLogRetentionMs(com.google.protobuf.Int64Value value) {
        if (logRetentionMsBuilder_ == null) {
          if (logRetentionMs_ != null) {
            logRetentionMs_ =
              com.google.protobuf.Int64Value.newBuilder(logRetentionMs_).mergeFrom(value).buildPartial();
          } else {
            logRetentionMs_ = value;
          }
          onChanged();
        } else {
          logRetentionMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public Builder clearLogRetentionMs() {
        if (logRetentionMsBuilder_ == null) {
          logRetentionMs_ = null;
          onChanged();
        } else {
          logRetentionMs_ = null;
          logRetentionMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogRetentionMsBuilder() {
        
        onChanged();
        return getLogRetentionMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogRetentionMsOrBuilder() {
        if (logRetentionMsBuilder_ != null) {
          return logRetentionMsBuilder_.getMessageOrBuilder();
        } else {
          return logRetentionMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMs_;
        }
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogRetentionMsFieldBuilder() {
        if (logRetentionMsBuilder_ == null) {
          logRetentionMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogRetentionMs(),
                  getParentForChildren(),
                  isClean());
          logRetentionMs_ = null;
        }
        return logRetentionMsBuilder_;
      }

      private com.google.protobuf.Int64Value logSegmentBytes_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logSegmentBytesBuilder_;
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public boolean hasLogSegmentBytes() {
        return logSegmentBytesBuilder_ != null || logSegmentBytes_ != null;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public com.google.protobuf.Int64Value getLogSegmentBytes() {
        if (logSegmentBytesBuilder_ == null) {
          return logSegmentBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logSegmentBytes_;
        } else {
          return logSegmentBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public Builder setLogSegmentBytes(com.google.protobuf.Int64Value value) {
        if (logSegmentBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logSegmentBytes_ = value;
          onChanged();
        } else {
          logSegmentBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public Builder setLogSegmentBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logSegmentBytesBuilder_ == null) {
          logSegmentBytes_ = builderForValue.build();
          onChanged();
        } else {
          logSegmentBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public Builder mergeLogSegmentBytes(com.google.protobuf.Int64Value value) {
        if (logSegmentBytesBuilder_ == null) {
          if (logSegmentBytes_ != null) {
            logSegmentBytes_ =
              com.google.protobuf.Int64Value.newBuilder(logSegmentBytes_).mergeFrom(value).buildPartial();
          } else {
            logSegmentBytes_ = value;
          }
          onChanged();
        } else {
          logSegmentBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public Builder clearLogSegmentBytes() {
        if (logSegmentBytesBuilder_ == null) {
          logSegmentBytes_ = null;
          onChanged();
        } else {
          logSegmentBytes_ = null;
          logSegmentBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogSegmentBytesBuilder() {
        
        onChanged();
        return getLogSegmentBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogSegmentBytesOrBuilder() {
        if (logSegmentBytesBuilder_ != null) {
          return logSegmentBytesBuilder_.getMessageOrBuilder();
        } else {
          return logSegmentBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logSegmentBytes_;
        }
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogSegmentBytesFieldBuilder() {
        if (logSegmentBytesBuilder_ == null) {
          logSegmentBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogSegmentBytes(),
                  getParentForChildren(),
                  isClean());
          logSegmentBytes_ = null;
        }
        return logSegmentBytesBuilder_;
      }

      private com.google.protobuf.BoolValue logPreallocate_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder> logPreallocateBuilder_;
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public boolean hasLogPreallocate() {
        return logPreallocateBuilder_ != null || logPreallocate_ != null;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public com.google.protobuf.BoolValue getLogPreallocate() {
        if (logPreallocateBuilder_ == null) {
          return logPreallocate_ == null ? com.google.protobuf.BoolValue.getDefaultInstance() : logPreallocate_;
        } else {
          return logPreallocateBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public Builder setLogPreallocate(com.google.protobuf.BoolValue value) {
        if (logPreallocateBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logPreallocate_ = value;
          onChanged();
        } else {
          logPreallocateBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public Builder setLogPreallocate(
          com.google.protobuf.BoolValue.Builder builderForValue) {
        if (logPreallocateBuilder_ == null) {
          logPreallocate_ = builderForValue.build();
          onChanged();
        } else {
          logPreallocateBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public Builder mergeLogPreallocate(com.google.protobuf.BoolValue value) {
        if (logPreallocateBuilder_ == null) {
          if (logPreallocate_ != null) {
            logPreallocate_ =
              com.google.protobuf.BoolValue.newBuilder(logPreallocate_).mergeFrom(value).buildPartial();
          } else {
            logPreallocate_ = value;
          }
          onChanged();
        } else {
          logPreallocateBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public Builder clearLogPreallocate() {
        if (logPreallocateBuilder_ == null) {
          logPreallocate_ = null;
          onChanged();
        } else {
          logPreallocate_ = null;
          logPreallocateBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public com.google.protobuf.BoolValue.Builder getLogPreallocateBuilder() {
        
        onChanged();
        return getLogPreallocateFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public com.google.protobuf.BoolValueOrBuilder getLogPreallocateOrBuilder() {
        if (logPreallocateBuilder_ != null) {
          return logPreallocateBuilder_.getMessageOrBuilder();
        } else {
          return logPreallocate_ == null ?
              com.google.protobuf.BoolValue.getDefaultInstance() : logPreallocate_;
        }
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder> 
          getLogPreallocateFieldBuilder() {
        if (logPreallocateBuilder_ == null) {
          logPreallocateBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder>(
                  getLogPreallocate(),
                  getParentForChildren(),
                  isClean());
          logPreallocate_ = null;
        }
        return logPreallocateBuilder_;
      }

      private com.google.protobuf.Int64Value socketSendBufferBytes_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> socketSendBufferBytesBuilder_;
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public boolean hasSocketSendBufferBytes() {
        return socketSendBufferBytesBuilder_ != null || socketSendBufferBytes_ != null;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public com.google.protobuf.Int64Value getSocketSendBufferBytes() {
        if (socketSendBufferBytesBuilder_ == null) {
          return socketSendBufferBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : socketSendBufferBytes_;
        } else {
          return socketSendBufferBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public Builder setSocketSendBufferBytes(com.google.protobuf.Int64Value value) {
        if (socketSendBufferBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          socketSendBufferBytes_ = value;
          onChanged();
        } else {
          socketSendBufferBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public Builder setSocketSendBufferBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (socketSendBufferBytesBuilder_ == null) {
          socketSendBufferBytes_ = builderForValue.build();
          onChanged();
        } else {
          socketSendBufferBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public Builder mergeSocketSendBufferBytes(com.google.protobuf.Int64Value value) {
        if (socketSendBufferBytesBuilder_ == null) {
          if (socketSendBufferBytes_ != null) {
            socketSendBufferBytes_ =
              com.google.protobuf.Int64Value.newBuilder(socketSendBufferBytes_).mergeFrom(value).buildPartial();
          } else {
            socketSendBufferBytes_ = value;
          }
          onChanged();
        } else {
          socketSendBufferBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public Builder clearSocketSendBufferBytes() {
        if (socketSendBufferBytesBuilder_ == null) {
          socketSendBufferBytes_ = null;
          onChanged();
        } else {
          socketSendBufferBytes_ = null;
          socketSendBufferBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public com.google.protobuf.Int64Value.Builder getSocketSendBufferBytesBuilder() {
        
        onChanged();
        return getSocketSendBufferBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getSocketSendBufferBytesOrBuilder() {
        if (socketSendBufferBytesBuilder_ != null) {
          return socketSendBufferBytesBuilder_.getMessageOrBuilder();
        } else {
          return socketSendBufferBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : socketSendBufferBytes_;
        }
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getSocketSendBufferBytesFieldBuilder() {
        if (socketSendBufferBytesBuilder_ == null) {
          socketSendBufferBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getSocketSendBufferBytes(),
                  getParentForChildren(),
                  isClean());
          socketSendBufferBytes_ = null;
        }
        return socketSendBufferBytesBuilder_;
      }

      private com.google.protobuf.Int64Value socketReceiveBufferBytes_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> socketReceiveBufferBytesBuilder_;
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public boolean hasSocketReceiveBufferBytes() {
        return socketReceiveBufferBytesBuilder_ != null || socketReceiveBufferBytes_ != null;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public com.google.protobuf.Int64Value getSocketReceiveBufferBytes() {
        if (socketReceiveBufferBytesBuilder_ == null) {
          return socketReceiveBufferBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : socketReceiveBufferBytes_;
        } else {
          return socketReceiveBufferBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public Builder setSocketReceiveBufferBytes(com.google.protobuf.Int64Value value) {
        if (socketReceiveBufferBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          socketReceiveBufferBytes_ = value;
          onChanged();
        } else {
          socketReceiveBufferBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public Builder setSocketReceiveBufferBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (socketReceiveBufferBytesBuilder_ == null) {
          socketReceiveBufferBytes_ = builderForValue.build();
          onChanged();
        } else {
          socketReceiveBufferBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public Builder mergeSocketReceiveBufferBytes(com.google.protobuf.Int64Value value) {
        if (socketReceiveBufferBytesBuilder_ == null) {
          if (socketReceiveBufferBytes_ != null) {
            socketReceiveBufferBytes_ =
              com.google.protobuf.Int64Value.newBuilder(socketReceiveBufferBytes_).mergeFrom(value).buildPartial();
          } else {
            socketReceiveBufferBytes_ = value;
          }
          onChanged();
        } else {
          socketReceiveBufferBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public Builder clearSocketReceiveBufferBytes() {
        if (socketReceiveBufferBytesBuilder_ == null) {
          socketReceiveBufferBytes_ = null;
          onChanged();
        } else {
          socketReceiveBufferBytes_ = null;
          socketReceiveBufferBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public com.google.protobuf.Int64Value.Builder getSocketReceiveBufferBytesBuilder() {
        
        onChanged();
        return getSocketReceiveBufferBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getSocketReceiveBufferBytesOrBuilder() {
        if (socketReceiveBufferBytesBuilder_ != null) {
          return socketReceiveBufferBytesBuilder_.getMessageOrBuilder();
        } else {
          return socketReceiveBufferBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : socketReceiveBufferBytes_;
        }
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getSocketReceiveBufferBytesFieldBuilder() {
        if (socketReceiveBufferBytesBuilder_ == null) {
          socketReceiveBufferBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getSocketReceiveBufferBytes(),
                  getParentForChildren(),
                  isClean());
          socketReceiveBufferBytes_ = null;
        }
        return socketReceiveBufferBytesBuilder_;
      }

      private com.google.protobuf.BoolValue autoCreateTopicsEnable_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder> autoCreateTopicsEnableBuilder_;
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public boolean hasAutoCreateTopicsEnable() {
        return autoCreateTopicsEnableBuilder_ != null || autoCreateTopicsEnable_ != null;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public com.google.protobuf.BoolValue getAutoCreateTopicsEnable() {
        if (autoCreateTopicsEnableBuilder_ == null) {
          return autoCreateTopicsEnable_ == null ? com.google.protobuf.BoolValue.getDefaultInstance() : autoCreateTopicsEnable_;
        } else {
          return autoCreateTopicsEnableBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public Builder setAutoCreateTopicsEnable(com.google.protobuf.BoolValue value) {
        if (autoCreateTopicsEnableBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          autoCreateTopicsEnable_ = value;
          onChanged();
        } else {
          autoCreateTopicsEnableBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public Builder setAutoCreateTopicsEnable(
          com.google.protobuf.BoolValue.Builder builderForValue) {
        if (autoCreateTopicsEnableBuilder_ == null) {
          autoCreateTopicsEnable_ = builderForValue.build();
          onChanged();
        } else {
          autoCreateTopicsEnableBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public Builder mergeAutoCreateTopicsEnable(com.google.protobuf.BoolValue value) {
        if (autoCreateTopicsEnableBuilder_ == null) {
          if (autoCreateTopicsEnable_ != null) {
            autoCreateTopicsEnable_ =
              com.google.protobuf.BoolValue.newBuilder(autoCreateTopicsEnable_).mergeFrom(value).buildPartial();
          } else {
            autoCreateTopicsEnable_ = value;
          }
          onChanged();
        } else {
          autoCreateTopicsEnableBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public Builder clearAutoCreateTopicsEnable() {
        if (autoCreateTopicsEnableBuilder_ == null) {
          autoCreateTopicsEnable_ = null;
          onChanged();
        } else {
          autoCreateTopicsEnable_ = null;
          autoCreateTopicsEnableBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public com.google.protobuf.BoolValue.Builder getAutoCreateTopicsEnableBuilder() {
        
        onChanged();
        return getAutoCreateTopicsEnableFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public com.google.protobuf.BoolValueOrBuilder getAutoCreateTopicsEnableOrBuilder() {
        if (autoCreateTopicsEnableBuilder_ != null) {
          return autoCreateTopicsEnableBuilder_.getMessageOrBuilder();
        } else {
          return autoCreateTopicsEnable_ == null ?
              com.google.protobuf.BoolValue.getDefaultInstance() : autoCreateTopicsEnable_;
        }
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder> 
          getAutoCreateTopicsEnableFieldBuilder() {
        if (autoCreateTopicsEnableBuilder_ == null) {
          autoCreateTopicsEnableBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder>(
                  getAutoCreateTopicsEnable(),
                  getParentForChildren(),
                  isClean());
          autoCreateTopicsEnable_ = null;
        }
        return autoCreateTopicsEnableBuilder_;
      }

      private com.google.protobuf.Int64Value numPartitions_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> numPartitionsBuilder_;
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public boolean hasNumPartitions() {
        return numPartitionsBuilder_ != null || numPartitions_ != null;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public com.google.protobuf.Int64Value getNumPartitions() {
        if (numPartitionsBuilder_ == null) {
          return numPartitions_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : numPartitions_;
        } else {
          return numPartitionsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public Builder setNumPartitions(com.google.protobuf.Int64Value value) {
        if (numPartitionsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          numPartitions_ = value;
          onChanged();
        } else {
          numPartitionsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public Builder setNumPartitions(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (numPartitionsBuilder_ == null) {
          numPartitions_ = builderForValue.build();
          onChanged();
        } else {
          numPartitionsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public Builder mergeNumPartitions(com.google.protobuf.Int64Value value) {
        if (numPartitionsBuilder_ == null) {
          if (numPartitions_ != null) {
            numPartitions_ =
              com.google.protobuf.Int64Value.newBuilder(numPartitions_).mergeFrom(value).buildPartial();
          } else {
            numPartitions_ = value;
          }
          onChanged();
        } else {
          numPartitionsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public Builder clearNumPartitions() {
        if (numPartitionsBuilder_ == null) {
          numPartitions_ = null;
          onChanged();
        } else {
          numPartitions_ = null;
          numPartitionsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public com.google.protobuf.Int64Value.Builder getNumPartitionsBuilder() {
        
        onChanged();
        return getNumPartitionsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getNumPartitionsOrBuilder() {
        if (numPartitionsBuilder_ != null) {
          return numPartitionsBuilder_.getMessageOrBuilder();
        } else {
          return numPartitions_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : numPartitions_;
        }
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getNumPartitionsFieldBuilder() {
        if (numPartitionsBuilder_ == null) {
          numPartitionsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getNumPartitions(),
                  getParentForChildren(),
                  isClean());
          numPartitions_ = null;
        }
        return numPartitionsBuilder_;
      }

      private com.google.protobuf.Int64Value defaultReplicationFactor_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> defaultReplicationFactorBuilder_;
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public boolean hasDefaultReplicationFactor() {
        return defaultReplicationFactorBuilder_ != null || defaultReplicationFactor_ != null;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public com.google.protobuf.Int64Value getDefaultReplicationFactor() {
        if (defaultReplicationFactorBuilder_ == null) {
          return defaultReplicationFactor_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : defaultReplicationFactor_;
        } else {
          return defaultReplicationFactorBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public Builder setDefaultReplicationFactor(com.google.protobuf.Int64Value value) {
        if (defaultReplicationFactorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          defaultReplicationFactor_ = value;
          onChanged();
        } else {
          defaultReplicationFactorBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public Builder setDefaultReplicationFactor(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (defaultReplicationFactorBuilder_ == null) {
          defaultReplicationFactor_ = builderForValue.build();
          onChanged();
        } else {
          defaultReplicationFactorBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public Builder mergeDefaultReplicationFactor(com.google.protobuf.Int64Value value) {
        if (defaultReplicationFactorBuilder_ == null) {
          if (defaultReplicationFactor_ != null) {
            defaultReplicationFactor_ =
              com.google.protobuf.Int64Value.newBuilder(defaultReplicationFactor_).mergeFrom(value).buildPartial();
          } else {
            defaultReplicationFactor_ = value;
          }
          onChanged();
        } else {
          defaultReplicationFactorBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public Builder clearDefaultReplicationFactor() {
        if (defaultReplicationFactorBuilder_ == null) {
          defaultReplicationFactor_ = null;
          onChanged();
        } else {
          defaultReplicationFactor_ = null;
          defaultReplicationFactorBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public com.google.protobuf.Int64Value.Builder getDefaultReplicationFactorBuilder() {
        
        onChanged();
        return getDefaultReplicationFactorFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getDefaultReplicationFactorOrBuilder() {
        if (defaultReplicationFactorBuilder_ != null) {
          return defaultReplicationFactorBuilder_.getMessageOrBuilder();
        } else {
          return defaultReplicationFactor_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : defaultReplicationFactor_;
        }
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getDefaultReplicationFactorFieldBuilder() {
        if (defaultReplicationFactorBuilder_ == null) {
          defaultReplicationFactorBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getDefaultReplicationFactor(),
                  getParentForChildren(),
                  isClean());
          defaultReplicationFactor_ = null;
        }
        return defaultReplicationFactorBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.KafkaConfig2_8)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.KafkaConfig2_8)
    private static final yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8();
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<KafkaConfig2_8>
        PARSER = new com.google.protobuf.AbstractParser<KafkaConfig2_8>() {
      @java.lang.Override
      public KafkaConfig2_8 parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new KafkaConfig2_8(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<KafkaConfig2_8> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<KafkaConfig2_8> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface HostOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.Host)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Name of the host.
     * </pre>
     *
     * <code>string name = 1;</code>
     */
    java.lang.String getName();
    /**
     * <pre>
     * Name of the host.
     * </pre>
     *
     * <code>string name = 1;</code>
     */
    com.google.protobuf.ByteString
        getNameBytes();

    /**
     * <pre>
     * ID of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>string cluster_id = 2;</code>
     */
    java.lang.String getClusterId();
    /**
     * <pre>
     * ID of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>string cluster_id = 2;</code>
     */
    com.google.protobuf.ByteString
        getClusterIdBytes();

    /**
     * <pre>
     * ID of the availability zone where the host resides.
     * </pre>
     *
     * <code>string zone_id = 3;</code>
     */
    java.lang.String getZoneId();
    /**
     * <pre>
     * ID of the availability zone where the host resides.
     * </pre>
     *
     * <code>string zone_id = 3;</code>
     */
    com.google.protobuf.ByteString
        getZoneIdBytes();

    /**
     * <pre>
     * Host role.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Host.Role role = 4;</code>
     */
    int getRoleValue();
    /**
     * <pre>
     * Host role.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Host.Role role = 4;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Role getRole();

    /**
     * <pre>
     * Computational resources allocated to the host.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
     */
    boolean hasResources();
    /**
     * <pre>
     * Computational resources allocated to the host.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources getResources();
    /**
     * <pre>
     * Computational resources allocated to the host.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder getResourcesOrBuilder();

    /**
     * <pre>
     * Aggregated host health data.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Host.Health health = 6;</code>
     */
    int getHealthValue();
    /**
     * <pre>
     * Aggregated host health data.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Host.Health health = 6;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Health getHealth();

    /**
     * <pre>
     * ID of the subnet the host resides in.
     * </pre>
     *
     * <code>string subnet_id = 8;</code>
     */
    java.lang.String getSubnetId();
    /**
     * <pre>
     * ID of the subnet the host resides in.
     * </pre>
     *
     * <code>string subnet_id = 8;</code>
     */
    com.google.protobuf.ByteString
        getSubnetIdBytes();

    /**
     * <pre>
     * The flag that defines whether a public IP address is assigned to the node.
     * If the value is `true`, then this node is available on the Internet via it's public IP address.
     * </pre>
     *
     * <code>bool assign_public_ip = 9;</code>
     */
    boolean getAssignPublicIp();
  }
  /**
   * <pre>
   * Cluster host metadata.
   * </pre>
   *
   * Protobuf type {@code yandex.cloud.mdb.kafka.v1.Host}
   */
  public  static final class Host extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.Host)
      HostOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Host.newBuilder() to construct.
    private Host(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Host() {
      name_ = "";
      clusterId_ = "";
      zoneId_ = "";
      role_ = 0;
      health_ = 0;
      subnetId_ = "";
      assignPublicIp_ = false;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private Host(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              name_ = s;
              break;
            }
            case 18: {
              java.lang.String s = input.readStringRequireUtf8();

              clusterId_ = s;
              break;
            }
            case 26: {
              java.lang.String s = input.readStringRequireUtf8();

              zoneId_ = s;
              break;
            }
            case 32: {
              int rawValue = input.readEnum();

              role_ = rawValue;
              break;
            }
            case 42: {
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder subBuilder = null;
              if (resources_ != null) {
                subBuilder = resources_.toBuilder();
              }
              resources_ = input.readMessage(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resources_);
                resources_ = subBuilder.buildPartial();
              }

              break;
            }
            case 48: {
              int rawValue = input.readEnum();

              health_ = rawValue;
              break;
            }
            case 66: {
              java.lang.String s = input.readStringRequireUtf8();

              subnetId_ = s;
              break;
            }
            case 72: {

              assignPublicIp_ = input.readBool();
              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Host_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Host_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Builder.class);
    }

    /**
     * Protobuf enum {@code yandex.cloud.mdb.kafka.v1.Host.Role}
     */
    public enum Role
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>ROLE_UNSPECIFIED = 0;</code>
       */
      ROLE_UNSPECIFIED(0),
      /**
       * <pre>
       * the host is a Kafka broker.
       * </pre>
       *
       * <code>KAFKA = 1;</code>
       */
      KAFKA(1),
      /**
       * <pre>
       * the host is a ZooKeeper server.
       * </pre>
       *
       * <code>ZOOKEEPER = 2;</code>
       */
      ZOOKEEPER(2),
      UNRECOGNIZED(-1),
      ;

      /**
       * <code>ROLE_UNSPECIFIED = 0;</code>
       */
      public static final int ROLE_UNSPECIFIED_VALUE = 0;
      /**
       * <pre>
       * the host is a Kafka broker.
       * </pre>
       *
       * <code>KAFKA = 1;</code>
       */
      public static final int KAFKA_VALUE = 1;
      /**
       * <pre>
       * the host is a ZooKeeper server.
       * </pre>
       *
       * <code>ZOOKEEPER = 2;</code>
       */
      public static final int ZOOKEEPER_VALUE = 2;


      public final int getNumber() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalArgumentException(
              "Can't get the number of an unknown enum value.");
        }
        return value;
      }

      /**
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static Role valueOf(int value) {
        return forNumber(value);
      }

      public static Role forNumber(int value) {
        switch (value) {
          case 0: return ROLE_UNSPECIFIED;
          case 1: return KAFKA;
          case 2: return ZOOKEEPER;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<Role>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final com.google.protobuf.Internal.EnumLiteMap<
          Role> internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<Role>() {
              public Role findValueByNumber(int number) {
                return Role.forNumber(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(ordinal());
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.getDescriptor().getEnumTypes().get(0);
      }

      private static final Role[] VALUES = values();

      public static Role valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        if (desc.getIndex() == -1) {
          return UNRECOGNIZED;
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private Role(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:yandex.cloud.mdb.kafka.v1.Host.Role)
    }

    /**
     * Protobuf enum {@code yandex.cloud.mdb.kafka.v1.Host.Health}
     */
    public enum Health
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <pre>
       * health of the host is unknown.
       * </pre>
       *
       * <code>UNKNOWN = 0;</code>
       */
      UNKNOWN(0),
      /**
       * <pre>
       * the host is performing all its functions normally.
       * </pre>
       *
       * <code>ALIVE = 1;</code>
       */
      ALIVE(1),
      /**
       * <pre>
       * the host is inoperable and cannot perform any of its essential functions.
       * </pre>
       *
       * <code>DEAD = 2;</code>
       */
      DEAD(2),
      /**
       * <pre>
       * the host is degraded and can perform only some of its essential functions.
       * </pre>
       *
       * <code>DEGRADED = 3;</code>
       */
      DEGRADED(3),
      UNRECOGNIZED(-1),
      ;

      /**
       * <pre>
       * health of the host is unknown.
       * </pre>
       *
       * <code>UNKNOWN = 0;</code>
       */
      public static final int UNKNOWN_VALUE = 0;
      /**
       * <pre>
       * the host is performing all its functions normally.
       * </pre>
       *
       * <code>ALIVE = 1;</code>
       */
      public static final int ALIVE_VALUE = 1;
      /**
       * <pre>
       * the host is inoperable and cannot perform any of its essential functions.
       * </pre>
       *
       * <code>DEAD = 2;</code>
       */
      public static final int DEAD_VALUE = 2;
      /**
       * <pre>
       * the host is degraded and can perform only some of its essential functions.
       * </pre>
       *
       * <code>DEGRADED = 3;</code>
       */
      public static final int DEGRADED_VALUE = 3;


      public final int getNumber() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalArgumentException(
              "Can't get the number of an unknown enum value.");
        }
        return value;
      }

      /**
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static Health valueOf(int value) {
        return forNumber(value);
      }

      public static Health forNumber(int value) {
        switch (value) {
          case 0: return UNKNOWN;
          case 1: return ALIVE;
          case 2: return DEAD;
          case 3: return DEGRADED;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<Health>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final com.google.protobuf.Internal.EnumLiteMap<
          Health> internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<Health>() {
              public Health findValueByNumber(int number) {
                return Health.forNumber(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(ordinal());
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.getDescriptor().getEnumTypes().get(1);
      }

      private static final Health[] VALUES = values();

      public static Health valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        if (desc.getIndex() == -1) {
          return UNRECOGNIZED;
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private Health(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:yandex.cloud.mdb.kafka.v1.Host.Health)
    }

    public static final int NAME_FIELD_NUMBER = 1;
    private volatile java.lang.Object name_;
    /**
     * <pre>
     * Name of the host.
     * </pre>
     *
     * <code>string name = 1;</code>
     */
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        name_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Name of the host.
     * </pre>
     *
     * <code>string name = 1;</code>
     */
    public com.google.protobuf.ByteString
        getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CLUSTER_ID_FIELD_NUMBER = 2;
    private volatile java.lang.Object clusterId_;
    /**
     * <pre>
     * ID of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>string cluster_id = 2;</code>
     */
    public java.lang.String getClusterId() {
      java.lang.Object ref = clusterId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        clusterId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>string cluster_id = 2;</code>
     */
    public com.google.protobuf.ByteString
        getClusterIdBytes() {
      java.lang.Object ref = clusterId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        clusterId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int ZONE_ID_FIELD_NUMBER = 3;
    private volatile java.lang.Object zoneId_;
    /**
     * <pre>
     * ID of the availability zone where the host resides.
     * </pre>
     *
     * <code>string zone_id = 3;</code>
     */
    public java.lang.String getZoneId() {
      java.lang.Object ref = zoneId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        zoneId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of the availability zone where the host resides.
     * </pre>
     *
     * <code>string zone_id = 3;</code>
     */
    public com.google.protobuf.ByteString
        getZoneIdBytes() {
      java.lang.Object ref = zoneId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        zoneId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int ROLE_FIELD_NUMBER = 4;
    private int role_;
    /**
     * <pre>
     * Host role.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Host.Role role = 4;</code>
     */
    public int getRoleValue() {
      return role_;
    }
    /**
     * <pre>
     * Host role.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Host.Role role = 4;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Role getRole() {
      @SuppressWarnings("deprecation")
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Role result = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Role.valueOf(role_);
      return result == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Role.UNRECOGNIZED : result;
    }

    public static final int RESOURCES_FIELD_NUMBER = 5;
    private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources resources_;
    /**
     * <pre>
     * Computational resources allocated to the host.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
     */
    public boolean hasResources() {
      return resources_ != null;
    }
    /**
     * <pre>
     * Computational resources allocated to the host.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources getResources() {
      return resources_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.getDefaultInstance() : resources_;
    }
    /**
     * <pre>
     * Computational resources allocated to the host.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder getResourcesOrBuilder() {
      return getResources();
    }

    public static final int HEALTH_FIELD_NUMBER = 6;
    private int health_;
    /**
     * <pre>
     * Aggregated host health data.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Host.Health health = 6;</code>
     */
    public int getHealthValue() {
      return health_;
    }
    /**
     * <pre>
     * Aggregated host health data.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Host.Health health = 6;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Health getHealth() {
      @SuppressWarnings("deprecation")
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Health result = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Health.valueOf(health_);
      return result == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Health.UNRECOGNIZED : result;
    }

    public static final int SUBNET_ID_FIELD_NUMBER = 8;
    private volatile java.lang.Object subnetId_;
    /**
     * <pre>
     * ID of the subnet the host resides in.
     * </pre>
     *
     * <code>string subnet_id = 8;</code>
     */
    public java.lang.String getSubnetId() {
      java.lang.Object ref = subnetId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        subnetId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of the subnet the host resides in.
     * </pre>
     *
     * <code>string subnet_id = 8;</code>
     */
    public com.google.protobuf.ByteString
        getSubnetIdBytes() {
      java.lang.Object ref = subnetId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        subnetId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int ASSIGN_PUBLIC_IP_FIELD_NUMBER = 9;
    private boolean assignPublicIp_;
    /**
     * <pre>
     * The flag that defines whether a public IP address is assigned to the node.
     * If the value is `true`, then this node is available on the Internet via it's public IP address.
     * </pre>
     *
     * <code>bool assign_public_ip = 9;</code>
     */
    public boolean getAssignPublicIp() {
      return assignPublicIp_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!getNameBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, name_);
      }
      if (!getClusterIdBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, clusterId_);
      }
      if (!getZoneIdBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, zoneId_);
      }
      if (role_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Role.ROLE_UNSPECIFIED.getNumber()) {
        output.writeEnum(4, role_);
      }
      if (resources_ != null) {
        output.writeMessage(5, getResources());
      }
      if (health_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Health.UNKNOWN.getNumber()) {
        output.writeEnum(6, health_);
      }
      if (!getSubnetIdBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 8, subnetId_);
      }
      if (assignPublicIp_ != false) {
        output.writeBool(9, assignPublicIp_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!getNameBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, name_);
      }
      if (!getClusterIdBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, clusterId_);
      }
      if (!getZoneIdBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, zoneId_);
      }
      if (role_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Role.ROLE_UNSPECIFIED.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(4, role_);
      }
      if (resources_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getResources());
      }
      if (health_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Health.UNKNOWN.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(6, health_);
      }
      if (!getSubnetIdBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(8, subnetId_);
      }
      if (assignPublicIp_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(9, assignPublicIp_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host)) {
        return super.equals(obj);
      }
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host other = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host) obj;

      boolean result = true;
      result = result && getName()
          .equals(other.getName());
      result = result && getClusterId()
          .equals(other.getClusterId());
      result = result && getZoneId()
          .equals(other.getZoneId());
      result = result && role_ == other.role_;
      result = result && (hasResources() == other.hasResources());
      if (hasResources()) {
        result = result && getResources()
            .equals(other.getResources());
      }
      result = result && health_ == other.health_;
      result = result && getSubnetId()
          .equals(other.getSubnetId());
      result = result && (getAssignPublicIp()
          == other.getAssignPublicIp());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + NAME_FIELD_NUMBER;
      hash = (53 * hash) + getName().hashCode();
      hash = (37 * hash) + CLUSTER_ID_FIELD_NUMBER;
      hash = (53 * hash) + getClusterId().hashCode();
      hash = (37 * hash) + ZONE_ID_FIELD_NUMBER;
      hash = (53 * hash) + getZoneId().hashCode();
      hash = (37 * hash) + ROLE_FIELD_NUMBER;
      hash = (53 * hash) + role_;
      if (hasResources()) {
        hash = (37 * hash) + RESOURCES_FIELD_NUMBER;
        hash = (53 * hash) + getResources().hashCode();
      }
      hash = (37 * hash) + HEALTH_FIELD_NUMBER;
      hash = (53 * hash) + health_;
      hash = (37 * hash) + SUBNET_ID_FIELD_NUMBER;
      hash = (53 * hash) + getSubnetId().hashCode();
      hash = (37 * hash) + ASSIGN_PUBLIC_IP_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getAssignPublicIp());
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Cluster host metadata.
     * </pre>
     *
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.Host}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.Host)
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.HostOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Host_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Host_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Builder.class);
      }

      // Construct using yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        name_ = "";

        clusterId_ = "";

        zoneId_ = "";

        role_ = 0;

        if (resourcesBuilder_ == null) {
          resources_ = null;
        } else {
          resources_ = null;
          resourcesBuilder_ = null;
        }
        health_ = 0;

        subnetId_ = "";

        assignPublicIp_ = false;

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Host_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host getDefaultInstanceForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host build() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host buildPartial() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host result = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host(this);
        result.name_ = name_;
        result.clusterId_ = clusterId_;
        result.zoneId_ = zoneId_;
        result.role_ = role_;
        if (resourcesBuilder_ == null) {
          result.resources_ = resources_;
        } else {
          result.resources_ = resourcesBuilder_.build();
        }
        result.health_ = health_;
        result.subnetId_ = subnetId_;
        result.assignPublicIp_ = assignPublicIp_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host) {
          return mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host other) {
        if (other == yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.getDefaultInstance()) return this;
        if (!other.getName().isEmpty()) {
          name_ = other.name_;
          onChanged();
        }
        if (!other.getClusterId().isEmpty()) {
          clusterId_ = other.clusterId_;
          onChanged();
        }
        if (!other.getZoneId().isEmpty()) {
          zoneId_ = other.zoneId_;
          onChanged();
        }
        if (other.role_ != 0) {
          setRoleValue(other.getRoleValue());
        }
        if (other.hasResources()) {
          mergeResources(other.getResources());
        }
        if (other.health_ != 0) {
          setHealthValue(other.getHealthValue());
        }
        if (!other.getSubnetId().isEmpty()) {
          subnetId_ = other.subnetId_;
          onChanged();
        }
        if (other.getAssignPublicIp() != false) {
          setAssignPublicIp(other.getAssignPublicIp());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private java.lang.Object name_ = "";
      /**
       * <pre>
       * Name of the host.
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Name of the host.
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Name of the host.
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public Builder setName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Name of the host.
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public Builder clearName() {
        
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Name of the host.
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        name_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object clusterId_ = "";
      /**
       * <pre>
       * ID of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>string cluster_id = 2;</code>
       */
      public java.lang.String getClusterId() {
        java.lang.Object ref = clusterId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          clusterId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>string cluster_id = 2;</code>
       */
      public com.google.protobuf.ByteString
          getClusterIdBytes() {
        java.lang.Object ref = clusterId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          clusterId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>string cluster_id = 2;</code>
       */
      public Builder setClusterId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        clusterId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>string cluster_id = 2;</code>
       */
      public Builder clearClusterId() {
        
        clusterId_ = getDefaultInstance().getClusterId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>string cluster_id = 2;</code>
       */
      public Builder setClusterIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        clusterId_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object zoneId_ = "";
      /**
       * <pre>
       * ID of the availability zone where the host resides.
       * </pre>
       *
       * <code>string zone_id = 3;</code>
       */
      public java.lang.String getZoneId() {
        java.lang.Object ref = zoneId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          zoneId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of the availability zone where the host resides.
       * </pre>
       *
       * <code>string zone_id = 3;</code>
       */
      public com.google.protobuf.ByteString
          getZoneIdBytes() {
        java.lang.Object ref = zoneId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          zoneId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of the availability zone where the host resides.
       * </pre>
       *
       * <code>string zone_id = 3;</code>
       */
      public Builder setZoneId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        zoneId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the availability zone where the host resides.
       * </pre>
       *
       * <code>string zone_id = 3;</code>
       */
      public Builder clearZoneId() {
        
        zoneId_ = getDefaultInstance().getZoneId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the availability zone where the host resides.
       * </pre>
       *
       * <code>string zone_id = 3;</code>
       */
      public Builder setZoneIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        zoneId_ = value;
        onChanged();
        return this;
      }

      private int role_ = 0;
      /**
       * <pre>
       * Host role.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Host.Role role = 4;</code>
       */
      public int getRoleValue() {
        return role_;
      }
      /**
       * <pre>
       * Host role.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Host.Role role = 4;</code>
       */
      public Builder setRoleValue(int value) {
        role_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Host role.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Host.Role role = 4;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Role getRole() {
        @SuppressWarnings("deprecation")
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Role result = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Role.valueOf(role_);
        return result == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Role.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       * Host role.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Host.Role role = 4;</code>
       */
      public Builder setRole(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Role value) {
        if (value == null) {
          throw new NullPointerException();
        }
        
        role_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Host role.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Host.Role role = 4;</code>
       */
      public Builder clearRole() {
        
        role_ = 0;
        onChanged();
        return this;
      }

      private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources resources_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder> resourcesBuilder_;
      /**
       * <pre>
       * Computational resources allocated to the host.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
       */
      public boolean hasResources() {
        return resourcesBuilder_ != null || resources_ != null;
      }
      /**
       * <pre>
       * Computational resources allocated to the host.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources getResources() {
        if (resourcesBuilder_ == null) {
          return resources_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.getDefaultInstance() : resources_;
        } else {
          return resourcesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Computational resources allocated to the host.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
       */
      public Builder setResources(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources value) {
        if (resourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resources_ = value;
          onChanged();
        } else {
          resourcesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Computational resources allocated to the host.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
       */
      public Builder setResources(
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder builderForValue) {
        if (resourcesBuilder_ == null) {
          resources_ = builderForValue.build();
          onChanged();
        } else {
          resourcesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Computational resources allocated to the host.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
       */
      public Builder mergeResources(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources value) {
        if (resourcesBuilder_ == null) {
          if (resources_ != null) {
            resources_ =
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.newBuilder(resources_).mergeFrom(value).buildPartial();
          } else {
            resources_ = value;
          }
          onChanged();
        } else {
          resourcesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Computational resources allocated to the host.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
       */
      public Builder clearResources() {
        if (resourcesBuilder_ == null) {
          resources_ = null;
          onChanged();
        } else {
          resources_ = null;
          resourcesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Computational resources allocated to the host.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder getResourcesBuilder() {
        
        onChanged();
        return getResourcesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Computational resources allocated to the host.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder getResourcesOrBuilder() {
        if (resourcesBuilder_ != null) {
          return resourcesBuilder_.getMessageOrBuilder();
        } else {
          return resources_ == null ?
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.getDefaultInstance() : resources_;
        }
      }
      /**
       * <pre>
       * Computational resources allocated to the host.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder> 
          getResourcesFieldBuilder() {
        if (resourcesBuilder_ == null) {
          resourcesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder>(
                  getResources(),
                  getParentForChildren(),
                  isClean());
          resources_ = null;
        }
        return resourcesBuilder_;
      }

      private int health_ = 0;
      /**
       * <pre>
       * Aggregated host health data.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Host.Health health = 6;</code>
       */
      public int getHealthValue() {
        return health_;
      }
      /**
       * <pre>
       * Aggregated host health data.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Host.Health health = 6;</code>
       */
      public Builder setHealthValue(int value) {
        health_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Aggregated host health data.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Host.Health health = 6;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Health getHealth() {
        @SuppressWarnings("deprecation")
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Health result = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Health.valueOf(health_);
        return result == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Health.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       * Aggregated host health data.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Host.Health health = 6;</code>
       */
      public Builder setHealth(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Health value) {
        if (value == null) {
          throw new NullPointerException();
        }
        
        health_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Aggregated host health data.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Host.Health health = 6;</code>
       */
      public Builder clearHealth() {
        
        health_ = 0;
        onChanged();
        return this;
      }

      private java.lang.Object subnetId_ = "";
      /**
       * <pre>
       * ID of the subnet the host resides in.
       * </pre>
       *
       * <code>string subnet_id = 8;</code>
       */
      public java.lang.String getSubnetId() {
        java.lang.Object ref = subnetId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          subnetId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of the subnet the host resides in.
       * </pre>
       *
       * <code>string subnet_id = 8;</code>
       */
      public com.google.protobuf.ByteString
          getSubnetIdBytes() {
        java.lang.Object ref = subnetId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          subnetId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of the subnet the host resides in.
       * </pre>
       *
       * <code>string subnet_id = 8;</code>
       */
      public Builder setSubnetId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        subnetId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the subnet the host resides in.
       * </pre>
       *
       * <code>string subnet_id = 8;</code>
       */
      public Builder clearSubnetId() {
        
        subnetId_ = getDefaultInstance().getSubnetId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the subnet the host resides in.
       * </pre>
       *
       * <code>string subnet_id = 8;</code>
       */
      public Builder setSubnetIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        subnetId_ = value;
        onChanged();
        return this;
      }

      private boolean assignPublicIp_ ;
      /**
       * <pre>
       * The flag that defines whether a public IP address is assigned to the node.
       * If the value is `true`, then this node is available on the Internet via it's public IP address.
       * </pre>
       *
       * <code>bool assign_public_ip = 9;</code>
       */
      public boolean getAssignPublicIp() {
        return assignPublicIp_;
      }
      /**
       * <pre>
       * The flag that defines whether a public IP address is assigned to the node.
       * If the value is `true`, then this node is available on the Internet via it's public IP address.
       * </pre>
       *
       * <code>bool assign_public_ip = 9;</code>
       */
      public Builder setAssignPublicIp(boolean value) {
        
        assignPublicIp_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The flag that defines whether a public IP address is assigned to the node.
       * If the value is `true`, then this node is available on the Internet via it's public IP address.
       * </pre>
       *
       * <code>bool assign_public_ip = 9;</code>
       */
      public Builder clearAssignPublicIp() {
        
        assignPublicIp_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.Host)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.Host)
    private static final yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host();
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<Host>
        PARSER = new com.google.protobuf.AbstractParser<Host>() {
      @java.lang.Override
      public Host parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Host(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<Host> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Host> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_Cluster_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_Cluster_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_Cluster_LabelsEntry_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_Cluster_LabelsEntry_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_Monitoring_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_Monitoring_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Kafka_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Kafka_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Zookeeper_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Zookeeper_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_Resources_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_Resources_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_1_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_1_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_6_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_6_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_8_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_8_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_Host_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_Host_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\'yandex/cloud/mdb/kafka/v1/cluster.prot" +
      "o\022\031yandex.cloud.mdb.kafka.v1\032\036google/pro" +
      "tobuf/wrappers.proto\032\037google/protobuf/ti" +
      "mestamp.proto\032&yandex/cloud/mdb/kafka/v1" +
      "/common.proto\032+yandex/cloud/mdb/kafka/v1" +
      "/maintenance.proto\"\231\010\n\007Cluster\022\n\n\002id\030\001 \001" +
      "(\t\022\021\n\tfolder_id\030\002 \001(\t\022.\n\ncreated_at\030\003 \001(" +
      "\0132\032.google.protobuf.Timestamp\022\014\n\004name\030\004 " +
      "\001(\t\022\023\n\013description\030\005 \001(\t\022>\n\006labels\030\006 \003(\013" +
      "2..yandex.cloud.mdb.kafka.v1.Cluster.Lab" +
      "elsEntry\022C\n\013environment\030\007 \001(\0162..yandex.c" +
      "loud.mdb.kafka.v1.Cluster.Environment\0229\n" +
      "\nmonitoring\030\010 \003(\0132%.yandex.cloud.mdb.kaf" +
      "ka.v1.Monitoring\0225\n\006config\030\t \001(\0132%.yande" +
      "x.cloud.mdb.kafka.v1.ConfigSpec\022\022\n\nnetwo" +
      "rk_id\030\n \001(\t\0229\n\006health\030\013 \001(\0162).yandex.clo" +
      "ud.mdb.kafka.v1.Cluster.Health\0229\n\006status" +
      "\030\014 \001(\0162).yandex.cloud.mdb.kafka.v1.Clust" +
      "er.Status\022\032\n\022security_group_ids\030\r \003(\t\022\026\n" +
      "\016host_group_ids\030\016 \003(\t\022\033\n\023deletion_protec" +
      "tion\030\017 \001(\010\022H\n\022maintenance_window\030\020 \001(\0132," +
      ".yandex.cloud.mdb.kafka.v1.MaintenanceWi" +
      "ndow\022J\n\021planned_operation\030\021 \001(\0132/.yandex" +
      ".cloud.mdb.kafka.v1.MaintenanceOperation" +
      "\032-\n\013LabelsEntry\022\013\n\003key\030\001 \001(\t\022\r\n\005value\030\002 " +
      "\001(\t:\0028\001\"I\n\013Environment\022\033\n\027ENVIRONMENT_UN" +
      "SPECIFIED\020\000\022\016\n\nPRODUCTION\020\001\022\r\n\tPRESTABLE" +
      "\020\002\"?\n\006Health\022\022\n\016HEALTH_UNKNOWN\020\000\022\t\n\005ALIV" +
      "E\020\001\022\010\n\004DEAD\020\002\022\014\n\010DEGRADED\020\003\"y\n\006Status\022\022\n" +
      "\016STATUS_UNKNOWN\020\000\022\014\n\010CREATING\020\001\022\013\n\007RUNNI" +
      "NG\020\002\022\t\n\005ERROR\020\003\022\014\n\010UPDATING\020\004\022\014\n\010STOPPIN" +
      "G\020\005\022\013\n\007STOPPED\020\006\022\014\n\010STARTING\020\007\"=\n\nMonito" +
      "ring\022\014\n\004name\030\001 \001(\t\022\023\n\013description\030\002 \001(\t\022" +
      "\014\n\004link\030\003 \001(\t\"\320\005\n\nConfigSpec\022\017\n\007version\030" +
      "\001 \001(\t\022:\n\005kafka\030\002 \001(\0132+.yandex.cloud.mdb." +
      "kafka.v1.ConfigSpec.Kafka\022B\n\tzookeeper\030\003" +
      " \001(\0132/.yandex.cloud.mdb.kafka.v1.ConfigS" +
      "pec.Zookeeper\022\017\n\007zone_id\030\004 \003(\t\0222\n\rbroker" +
      "s_count\030\005 \001(\0132\033.google.protobuf.Int64Val" +
      "ue\022\030\n\020assign_public_ip\030\006 \001(\010\022\030\n\020unmanage" +
      "d_topics\030\007 \001(\010\022\027\n\017schema_registry\030\010 \001(\010\032" +
      "\330\002\n\005Kafka\0227\n\tresources\030\001 \001(\0132$.yandex.cl" +
      "oud.mdb.kafka.v1.Resources\022V\n\020kafka_conf" +
      "ig_2_1\030\002 \001(\0132).yandex.cloud.mdb.kafka.v1" +
      ".KafkaConfig2_1H\000R\017kafkaConfig_2_1\022V\n\020ka" +
      "fka_config_2_6\030\003 \001(\0132).yandex.cloud.mdb." +
      "kafka.v1.KafkaConfig2_6H\000R\017kafkaConfig_2" +
      "_6\022V\n\020kafka_config_2_8\030\004 \001(\0132).yandex.cl" +
      "oud.mdb.kafka.v1.KafkaConfig2_8H\000R\017kafka" +
      "Config_2_8B\016\n\014kafka_config\032D\n\tZookeeper\022" +
      "7\n\tresources\030\001 \001(\0132$.yandex.cloud.mdb.ka" +
      "fka.v1.Resources\"P\n\tResources\022\032\n\022resourc" +
      "e_preset_id\030\001 \001(\t\022\021\n\tdisk_size\030\002 \001(\003\022\024\n\014" +
      "disk_type_id\030\003 \001(\t\"\244\007\n\016KafkaConfig2_1\022D\n" +
      "\020compression_type\030\001 \001(\0162*.yandex.cloud.m" +
      "db.kafka.v1.CompressionType\022@\n\033log_flush" +
      "_interval_messages\030\002 \001(\0132\033.google.protob" +
      "uf.Int64Value\022:\n\025log_flush_interval_ms\030\003" +
      " \001(\0132\033.google.protobuf.Int64Value\022D\n\037log" +
      "_flush_scheduler_interval_ms\030\004 \001(\0132\033.goo" +
      "gle.protobuf.Int64Value\0228\n\023log_retention" +
      "_bytes\030\005 \001(\0132\033.google.protobuf.Int64Valu" +
      "e\0228\n\023log_retention_hours\030\006 \001(\0132\033.google." +
      "protobuf.Int64Value\022:\n\025log_retention_min" +
      "utes\030\007 \001(\0132\033.google.protobuf.Int64Value\022" +
      "5\n\020log_retention_ms\030\010 \001(\0132\033.google.proto" +
      "buf.Int64Value\0226\n\021log_segment_bytes\030\t \001(" +
      "\0132\033.google.protobuf.Int64Value\0223\n\017log_pr" +
      "eallocate\030\n \001(\0132\032.google.protobuf.BoolVa" +
      "lue\022=\n\030socket_send_buffer_bytes\030\013 \001(\0132\033." +
      "google.protobuf.Int64Value\022@\n\033socket_rec" +
      "eive_buffer_bytes\030\014 \001(\0132\033.google.protobu" +
      "f.Int64Value\022=\n\031auto_create_topics_enabl" +
      "e\030\r \001(\0132\032.google.protobuf.BoolValue\0223\n\016n" +
      "um_partitions\030\016 \001(\0132\033.google.protobuf.In" +
      "t64Value\022?\n\032default_replication_factor\030\017" +
      " \001(\0132\033.google.protobuf.Int64Value\"\244\007\n\016Ka" +
      "fkaConfig2_6\022D\n\020compression_type\030\001 \001(\0162*" +
      ".yandex.cloud.mdb.kafka.v1.CompressionTy" +
      "pe\022@\n\033log_flush_interval_messages\030\002 \001(\0132" +
      "\033.google.protobuf.Int64Value\022:\n\025log_flus" +
      "h_interval_ms\030\003 \001(\0132\033.google.protobuf.In" +
      "t64Value\022D\n\037log_flush_scheduler_interval" +
      "_ms\030\004 \001(\0132\033.google.protobuf.Int64Value\0228" +
      "\n\023log_retention_bytes\030\005 \001(\0132\033.google.pro" +
      "tobuf.Int64Value\0228\n\023log_retention_hours\030" +
      "\006 \001(\0132\033.google.protobuf.Int64Value\022:\n\025lo" +
      "g_retention_minutes\030\007 \001(\0132\033.google.proto" +
      "buf.Int64Value\0225\n\020log_retention_ms\030\010 \001(\013" +
      "2\033.google.protobuf.Int64Value\0226\n\021log_seg" +
      "ment_bytes\030\t \001(\0132\033.google.protobuf.Int64" +
      "Value\0223\n\017log_preallocate\030\n \001(\0132\032.google." +
      "protobuf.BoolValue\022=\n\030socket_send_buffer" +
      "_bytes\030\013 \001(\0132\033.google.protobuf.Int64Valu" +
      "e\022@\n\033socket_receive_buffer_bytes\030\014 \001(\0132\033" +
      ".google.protobuf.Int64Value\022=\n\031auto_crea" +
      "te_topics_enable\030\r \001(\0132\032.google.protobuf" +
      ".BoolValue\0223\n\016num_partitions\030\016 \001(\0132\033.goo" +
      "gle.protobuf.Int64Value\022?\n\032default_repli" +
      "cation_factor\030\017 \001(\0132\033.google.protobuf.In" +
      "t64Value\"\244\007\n\016KafkaConfig2_8\022D\n\020compressi" +
      "on_type\030\001 \001(\0162*.yandex.cloud.mdb.kafka.v" +
      "1.CompressionType\022@\n\033log_flush_interval_" +
      "messages\030\002 \001(\0132\033.google.protobuf.Int64Va" +
      "lue\022:\n\025log_flush_interval_ms\030\003 \001(\0132\033.goo" +
      "gle.protobuf.Int64Value\022D\n\037log_flush_sch" +
      "eduler_interval_ms\030\004 \001(\0132\033.google.protob" +
      "uf.Int64Value\0228\n\023log_retention_bytes\030\005 \001" +
      "(\0132\033.google.protobuf.Int64Value\0228\n\023log_r" +
      "etention_hours\030\006 \001(\0132\033.google.protobuf.I" +
      "nt64Value\022:\n\025log_retention_minutes\030\007 \001(\013" +
      "2\033.google.protobuf.Int64Value\0225\n\020log_ret" +
      "ention_ms\030\010 \001(\0132\033.google.protobuf.Int64V" +
      "alue\0226\n\021log_segment_bytes\030\t \001(\0132\033.google" +
      ".protobuf.Int64Value\0223\n\017log_preallocate\030" +
      "\n \001(\0132\032.google.protobuf.BoolValue\022=\n\030soc" +
      "ket_send_buffer_bytes\030\013 \001(\0132\033.google.pro" +
      "tobuf.Int64Value\022@\n\033socket_receive_buffe" +
      "r_bytes\030\014 \001(\0132\033.google.protobuf.Int64Val" +
      "ue\022=\n\031auto_create_topics_enable\030\r \001(\0132\032." +
      "google.protobuf.BoolValue\0223\n\016num_partiti" +
      "ons\030\016 \001(\0132\033.google.protobuf.Int64Value\022?" +
      "\n\032default_replication_factor\030\017 \001(\0132\033.goo" +
      "gle.protobuf.Int64Value\"\375\002\n\004Host\022\014\n\004name" +
      "\030\001 \001(\t\022\022\n\ncluster_id\030\002 \001(\t\022\017\n\007zone_id\030\003 " +
      "\001(\t\0222\n\004role\030\004 \001(\0162$.yandex.cloud.mdb.kaf" +
      "ka.v1.Host.Role\0227\n\tresources\030\005 \001(\0132$.yan" +
      "dex.cloud.mdb.kafka.v1.Resources\0226\n\006heal" +
      "th\030\006 \001(\0162&.yandex.cloud.mdb.kafka.v1.Hos" +
      "t.Health\022\021\n\tsubnet_id\030\010 \001(\t\022\030\n\020assign_pu" +
      "blic_ip\030\t \001(\010\"6\n\004Role\022\024\n\020ROLE_UNSPECIFIE" +
      "D\020\000\022\t\n\005KAFKA\020\001\022\r\n\tZOOKEEPER\020\002\"8\n\006Health\022" +
      "\013\n\007UNKNOWN\020\000\022\t\n\005ALIVE\020\001\022\010\n\004DEAD\020\002\022\014\n\010DEG" +
      "RADED\020\003Bd\n\035yandex.cloud.api.mdb.kafka.v1" +
      "ZCgithub.com/yandex-cloud/go-genproto/ya" +
      "ndex/cloud/mdb/kafka/v1;kafkab\006proto3"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
        new com.google.protobuf.Descriptors.FileDescriptor.    InternalDescriptorAssigner() {
          public com.google.protobuf.ExtensionRegistry assignDescriptors(
              com.google.protobuf.Descriptors.FileDescriptor root) {
            descriptor = root;
            return null;
          }
        };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          com.google.protobuf.WrappersProto.getDescriptor(),
          com.google.protobuf.TimestampProto.getDescriptor(),
          yandex.cloud.api.mdb.kafka.v1.Common.getDescriptor(),
          yandex.cloud.api.mdb.kafka.v1.Maintenance.getDescriptor(),
        }, assigner);
    internal_static_yandex_cloud_mdb_kafka_v1_Cluster_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_yandex_cloud_mdb_kafka_v1_Cluster_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_Cluster_descriptor,
        new java.lang.String[] { "Id", "FolderId", "CreatedAt", "Name", "Description", "Labels", "Environment", "Monitoring", "Config", "NetworkId", "Health", "Status", "SecurityGroupIds", "HostGroupIds", "DeletionProtection", "MaintenanceWindow", "PlannedOperation", });
    internal_static_yandex_cloud_mdb_kafka_v1_Cluster_LabelsEntry_descriptor =
      internal_static_yandex_cloud_mdb_kafka_v1_Cluster_descriptor.getNestedTypes().get(0);
    internal_static_yandex_cloud_mdb_kafka_v1_Cluster_LabelsEntry_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_Cluster_LabelsEntry_descriptor,
        new java.lang.String[] { "Key", "Value", });
    internal_static_yandex_cloud_mdb_kafka_v1_Monitoring_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_yandex_cloud_mdb_kafka_v1_Monitoring_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_Monitoring_descriptor,
        new java.lang.String[] { "Name", "Description", "Link", });
    internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_descriptor,
        new java.lang.String[] { "Version", "Kafka", "Zookeeper", "ZoneId", "BrokersCount", "AssignPublicIp", "UnmanagedTopics", "SchemaRegistry", });
    internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Kafka_descriptor =
      internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_descriptor.getNestedTypes().get(0);
    internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Kafka_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Kafka_descriptor,
        new java.lang.String[] { "Resources", "KafkaConfig21", "KafkaConfig26", "KafkaConfig28", "KafkaConfig", });
    internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Zookeeper_descriptor =
      internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_descriptor.getNestedTypes().get(1);
    internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Zookeeper_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Zookeeper_descriptor,
        new java.lang.String[] { "Resources", });
    internal_static_yandex_cloud_mdb_kafka_v1_Resources_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_yandex_cloud_mdb_kafka_v1_Resources_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_Resources_descriptor,
        new java.lang.String[] { "ResourcePresetId", "DiskSize", "DiskTypeId", });
    internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_1_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_1_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_1_descriptor,
        new java.lang.String[] { "CompressionType", "LogFlushIntervalMessages", "LogFlushIntervalMs", "LogFlushSchedulerIntervalMs", "LogRetentionBytes", "LogRetentionHours", "LogRetentionMinutes", "LogRetentionMs", "LogSegmentBytes", "LogPreallocate", "SocketSendBufferBytes", "SocketReceiveBufferBytes", "AutoCreateTopicsEnable", "NumPartitions", "DefaultReplicationFactor", });
    internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_6_descriptor =
      getDescriptor().getMessageTypes().get(5);
    internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_6_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_6_descriptor,
        new java.lang.String[] { "CompressionType", "LogFlushIntervalMessages", "LogFlushIntervalMs", "LogFlushSchedulerIntervalMs", "LogRetentionBytes", "LogRetentionHours", "LogRetentionMinutes", "LogRetentionMs", "LogSegmentBytes", "LogPreallocate", "SocketSendBufferBytes", "SocketReceiveBufferBytes", "AutoCreateTopicsEnable", "NumPartitions", "DefaultReplicationFactor", });
    internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_8_descriptor =
      getDescriptor().getMessageTypes().get(6);
    internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_8_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_8_descriptor,
        new java.lang.String[] { "CompressionType", "LogFlushIntervalMessages", "LogFlushIntervalMs", "LogFlushSchedulerIntervalMs", "LogRetentionBytes", "LogRetentionHours", "LogRetentionMinutes", "LogRetentionMs", "LogSegmentBytes", "LogPreallocate", "SocketSendBufferBytes", "SocketReceiveBufferBytes", "AutoCreateTopicsEnable", "NumPartitions", "DefaultReplicationFactor", });
    internal_static_yandex_cloud_mdb_kafka_v1_Host_descriptor =
      getDescriptor().getMessageTypes().get(7);
    internal_static_yandex_cloud_mdb_kafka_v1_Host_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_Host_descriptor,
        new java.lang.String[] { "Name", "ClusterId", "ZoneId", "Role", "Resources", "Health", "SubnetId", "AssignPublicIp", });
    com.google.protobuf.WrappersProto.getDescriptor();
    com.google.protobuf.TimestampProto.getDescriptor();
    yandex.cloud.api.mdb.kafka.v1.Common.getDescriptor();
    yandex.cloud.api.mdb.kafka.v1.Maintenance.getDescriptor();
  }

  // @@protoc_insertion_point(outer_class_scope)
}
