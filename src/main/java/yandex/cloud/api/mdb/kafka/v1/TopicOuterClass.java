// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: yandex/cloud/mdb/kafka/v1/topic.proto

package yandex.cloud.api.mdb.kafka.v1;

public final class TopicOuterClass {
  private TopicOuterClass() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (com.google.protobuf.ExtensionRegistryLite) registry);
  }
  public interface TopicOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.Topic)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Name of the topic.
     * </pre>
     *
     * <code>string name = 1;</code>
     */
    java.lang.String getName();
    /**
     * <pre>
     * Name of the topic.
     * </pre>
     *
     * <code>string name = 1;</code>
     */
    com.google.protobuf.ByteString
        getNameBytes();

    /**
     * <pre>
     * ID of an Apache Kafka® cluster that the topic belongs to.
     * To get the Apache Kafka® cluster ID, make a [ClusterService.List] request.
     * </pre>
     *
     * <code>string cluster_id = 2;</code>
     */
    java.lang.String getClusterId();
    /**
     * <pre>
     * ID of an Apache Kafka® cluster that the topic belongs to.
     * To get the Apache Kafka® cluster ID, make a [ClusterService.List] request.
     * </pre>
     *
     * <code>string cluster_id = 2;</code>
     */
    com.google.protobuf.ByteString
        getClusterIdBytes();

    /**
     * <pre>
     * The number of the topic's partitions.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value partitions = 3;</code>
     */
    boolean hasPartitions();
    /**
     * <pre>
     * The number of the topic's partitions.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value partitions = 3;</code>
     */
    com.google.protobuf.Int64Value getPartitions();
    /**
     * <pre>
     * The number of the topic's partitions.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value partitions = 3;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getPartitionsOrBuilder();

    /**
     * <pre>
     * Amount of data copies (replicas) for the topic in the cluster.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value replication_factor = 4;</code>
     */
    boolean hasReplicationFactor();
    /**
     * <pre>
     * Amount of data copies (replicas) for the topic in the cluster.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value replication_factor = 4;</code>
     */
    com.google.protobuf.Int64Value getReplicationFactor();
    /**
     * <pre>
     * Amount of data copies (replicas) for the topic in the cluster.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value replication_factor = 4;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getReplicationFactorOrBuilder();

    /**
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 5[json_name = "topicConfig_2_1"];</code>
     */
    boolean hasTopicConfig21();
    /**
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 5[json_name = "topicConfig_2_1"];</code>
     */
    yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 getTopicConfig21();
    /**
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 5[json_name = "topicConfig_2_1"];</code>
     */
    yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1OrBuilder getTopicConfig21OrBuilder();

    /**
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 6[json_name = "topicConfig_2_6"];</code>
     */
    boolean hasTopicConfig26();
    /**
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 6[json_name = "topicConfig_2_6"];</code>
     */
    yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 getTopicConfig26();
    /**
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 6[json_name = "topicConfig_2_6"];</code>
     */
    yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6OrBuilder getTopicConfig26OrBuilder();

    public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic.TopicConfigCase getTopicConfigCase();
  }
  /**
   * <pre>
   * An Kafka topic.
   * For more information, see the [Concepts → Topics and partitions](/docs/managed-kafka/concepts/topics) section of the documentation.
   * </pre>
   *
   * Protobuf type {@code yandex.cloud.mdb.kafka.v1.Topic}
   */
  public  static final class Topic extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.Topic)
      TopicOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Topic.newBuilder() to construct.
    private Topic(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Topic() {
      name_ = "";
      clusterId_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private Topic(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              name_ = s;
              break;
            }
            case 18: {
              java.lang.String s = input.readStringRequireUtf8();

              clusterId_ = s;
              break;
            }
            case 26: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (partitions_ != null) {
                subBuilder = partitions_.toBuilder();
              }
              partitions_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(partitions_);
                partitions_ = subBuilder.buildPartial();
              }

              break;
            }
            case 34: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (replicationFactor_ != null) {
                subBuilder = replicationFactor_.toBuilder();
              }
              replicationFactor_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(replicationFactor_);
                replicationFactor_ = subBuilder.buildPartial();
              }

              break;
            }
            case 42: {
              yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.Builder subBuilder = null;
              if (topicConfigCase_ == 5) {
                subBuilder = ((yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1) topicConfig_).toBuilder();
              }
              topicConfig_ =
                  input.readMessage(yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom((yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1) topicConfig_);
                topicConfig_ = subBuilder.buildPartial();
              }
              topicConfigCase_ = 5;
              break;
            }
            case 50: {
              yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.Builder subBuilder = null;
              if (topicConfigCase_ == 6) {
                subBuilder = ((yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6) topicConfig_).toBuilder();
              }
              topicConfig_ =
                  input.readMessage(yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom((yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6) topicConfig_);
                topicConfig_ = subBuilder.buildPartial();
              }
              topicConfigCase_ = 6;
              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Topic_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Topic_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic.class, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic.Builder.class);
    }

    private int topicConfigCase_ = 0;
    private java.lang.Object topicConfig_;
    public enum TopicConfigCase
        implements com.google.protobuf.Internal.EnumLite {
      TOPIC_CONFIG_2_1(5),
      TOPIC_CONFIG_2_6(6),
      TOPICCONFIG_NOT_SET(0);
      private final int value;
      private TopicConfigCase(int value) {
        this.value = value;
      }
      /**
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static TopicConfigCase valueOf(int value) {
        return forNumber(value);
      }

      public static TopicConfigCase forNumber(int value) {
        switch (value) {
          case 5: return TOPIC_CONFIG_2_1;
          case 6: return TOPIC_CONFIG_2_6;
          case 0: return TOPICCONFIG_NOT_SET;
          default: return null;
        }
      }
      public int getNumber() {
        return this.value;
      }
    };

    public TopicConfigCase
    getTopicConfigCase() {
      return TopicConfigCase.forNumber(
          topicConfigCase_);
    }

    public static final int NAME_FIELD_NUMBER = 1;
    private volatile java.lang.Object name_;
    /**
     * <pre>
     * Name of the topic.
     * </pre>
     *
     * <code>string name = 1;</code>
     */
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        name_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Name of the topic.
     * </pre>
     *
     * <code>string name = 1;</code>
     */
    public com.google.protobuf.ByteString
        getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CLUSTER_ID_FIELD_NUMBER = 2;
    private volatile java.lang.Object clusterId_;
    /**
     * <pre>
     * ID of an Apache Kafka® cluster that the topic belongs to.
     * To get the Apache Kafka® cluster ID, make a [ClusterService.List] request.
     * </pre>
     *
     * <code>string cluster_id = 2;</code>
     */
    public java.lang.String getClusterId() {
      java.lang.Object ref = clusterId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        clusterId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of an Apache Kafka® cluster that the topic belongs to.
     * To get the Apache Kafka® cluster ID, make a [ClusterService.List] request.
     * </pre>
     *
     * <code>string cluster_id = 2;</code>
     */
    public com.google.protobuf.ByteString
        getClusterIdBytes() {
      java.lang.Object ref = clusterId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        clusterId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int PARTITIONS_FIELD_NUMBER = 3;
    private com.google.protobuf.Int64Value partitions_;
    /**
     * <pre>
     * The number of the topic's partitions.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value partitions = 3;</code>
     */
    public boolean hasPartitions() {
      return partitions_ != null;
    }
    /**
     * <pre>
     * The number of the topic's partitions.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value partitions = 3;</code>
     */
    public com.google.protobuf.Int64Value getPartitions() {
      return partitions_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : partitions_;
    }
    /**
     * <pre>
     * The number of the topic's partitions.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value partitions = 3;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getPartitionsOrBuilder() {
      return getPartitions();
    }

    public static final int REPLICATION_FACTOR_FIELD_NUMBER = 4;
    private com.google.protobuf.Int64Value replicationFactor_;
    /**
     * <pre>
     * Amount of data copies (replicas) for the topic in the cluster.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value replication_factor = 4;</code>
     */
    public boolean hasReplicationFactor() {
      return replicationFactor_ != null;
    }
    /**
     * <pre>
     * Amount of data copies (replicas) for the topic in the cluster.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value replication_factor = 4;</code>
     */
    public com.google.protobuf.Int64Value getReplicationFactor() {
      return replicationFactor_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : replicationFactor_;
    }
    /**
     * <pre>
     * Amount of data copies (replicas) for the topic in the cluster.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value replication_factor = 4;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getReplicationFactorOrBuilder() {
      return getReplicationFactor();
    }

    public static final int TOPIC_CONFIG_2_1_FIELD_NUMBER = 5;
    /**
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 5[json_name = "topicConfig_2_1"];</code>
     */
    public boolean hasTopicConfig21() {
      return topicConfigCase_ == 5;
    }
    /**
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 5[json_name = "topicConfig_2_1"];</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 getTopicConfig21() {
      if (topicConfigCase_ == 5) {
         return (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1) topicConfig_;
      }
      return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.getDefaultInstance();
    }
    /**
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 5[json_name = "topicConfig_2_1"];</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1OrBuilder getTopicConfig21OrBuilder() {
      if (topicConfigCase_ == 5) {
         return (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1) topicConfig_;
      }
      return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.getDefaultInstance();
    }

    public static final int TOPIC_CONFIG_2_6_FIELD_NUMBER = 6;
    /**
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 6[json_name = "topicConfig_2_6"];</code>
     */
    public boolean hasTopicConfig26() {
      return topicConfigCase_ == 6;
    }
    /**
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 6[json_name = "topicConfig_2_6"];</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 getTopicConfig26() {
      if (topicConfigCase_ == 6) {
         return (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6) topicConfig_;
      }
      return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.getDefaultInstance();
    }
    /**
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 6[json_name = "topicConfig_2_6"];</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6OrBuilder getTopicConfig26OrBuilder() {
      if (topicConfigCase_ == 6) {
         return (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6) topicConfig_;
      }
      return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.getDefaultInstance();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!getNameBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, name_);
      }
      if (!getClusterIdBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, clusterId_);
      }
      if (partitions_ != null) {
        output.writeMessage(3, getPartitions());
      }
      if (replicationFactor_ != null) {
        output.writeMessage(4, getReplicationFactor());
      }
      if (topicConfigCase_ == 5) {
        output.writeMessage(5, (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1) topicConfig_);
      }
      if (topicConfigCase_ == 6) {
        output.writeMessage(6, (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6) topicConfig_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!getNameBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, name_);
      }
      if (!getClusterIdBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, clusterId_);
      }
      if (partitions_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getPartitions());
      }
      if (replicationFactor_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getReplicationFactor());
      }
      if (topicConfigCase_ == 5) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1) topicConfig_);
      }
      if (topicConfigCase_ == 6) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6) topicConfig_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic)) {
        return super.equals(obj);
      }
      yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic other = (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic) obj;

      boolean result = true;
      result = result && getName()
          .equals(other.getName());
      result = result && getClusterId()
          .equals(other.getClusterId());
      result = result && (hasPartitions() == other.hasPartitions());
      if (hasPartitions()) {
        result = result && getPartitions()
            .equals(other.getPartitions());
      }
      result = result && (hasReplicationFactor() == other.hasReplicationFactor());
      if (hasReplicationFactor()) {
        result = result && getReplicationFactor()
            .equals(other.getReplicationFactor());
      }
      result = result && getTopicConfigCase().equals(
          other.getTopicConfigCase());
      if (!result) return false;
      switch (topicConfigCase_) {
        case 5:
          result = result && getTopicConfig21()
              .equals(other.getTopicConfig21());
          break;
        case 6:
          result = result && getTopicConfig26()
              .equals(other.getTopicConfig26());
          break;
        case 0:
        default:
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + NAME_FIELD_NUMBER;
      hash = (53 * hash) + getName().hashCode();
      hash = (37 * hash) + CLUSTER_ID_FIELD_NUMBER;
      hash = (53 * hash) + getClusterId().hashCode();
      if (hasPartitions()) {
        hash = (37 * hash) + PARTITIONS_FIELD_NUMBER;
        hash = (53 * hash) + getPartitions().hashCode();
      }
      if (hasReplicationFactor()) {
        hash = (37 * hash) + REPLICATION_FACTOR_FIELD_NUMBER;
        hash = (53 * hash) + getReplicationFactor().hashCode();
      }
      switch (topicConfigCase_) {
        case 5:
          hash = (37 * hash) + TOPIC_CONFIG_2_1_FIELD_NUMBER;
          hash = (53 * hash) + getTopicConfig21().hashCode();
          break;
        case 6:
          hash = (37 * hash) + TOPIC_CONFIG_2_6_FIELD_NUMBER;
          hash = (53 * hash) + getTopicConfig26().hashCode();
          break;
        case 0:
        default:
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * An Kafka topic.
     * For more information, see the [Concepts → Topics and partitions](/docs/managed-kafka/concepts/topics) section of the documentation.
     * </pre>
     *
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.Topic}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.Topic)
        yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Topic_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Topic_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic.class, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic.Builder.class);
      }

      // Construct using yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        name_ = "";

        clusterId_ = "";

        if (partitionsBuilder_ == null) {
          partitions_ = null;
        } else {
          partitions_ = null;
          partitionsBuilder_ = null;
        }
        if (replicationFactorBuilder_ == null) {
          replicationFactor_ = null;
        } else {
          replicationFactor_ = null;
          replicationFactorBuilder_ = null;
        }
        topicConfigCase_ = 0;
        topicConfig_ = null;
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Topic_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic getDefaultInstanceForType() {
        return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic build() {
        yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic buildPartial() {
        yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic result = new yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic(this);
        result.name_ = name_;
        result.clusterId_ = clusterId_;
        if (partitionsBuilder_ == null) {
          result.partitions_ = partitions_;
        } else {
          result.partitions_ = partitionsBuilder_.build();
        }
        if (replicationFactorBuilder_ == null) {
          result.replicationFactor_ = replicationFactor_;
        } else {
          result.replicationFactor_ = replicationFactorBuilder_.build();
        }
        if (topicConfigCase_ == 5) {
          if (topicConfig21Builder_ == null) {
            result.topicConfig_ = topicConfig_;
          } else {
            result.topicConfig_ = topicConfig21Builder_.build();
          }
        }
        if (topicConfigCase_ == 6) {
          if (topicConfig26Builder_ == null) {
            result.topicConfig_ = topicConfig_;
          } else {
            result.topicConfig_ = topicConfig26Builder_.build();
          }
        }
        result.topicConfigCase_ = topicConfigCase_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic) {
          return mergeFrom((yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic other) {
        if (other == yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic.getDefaultInstance()) return this;
        if (!other.getName().isEmpty()) {
          name_ = other.name_;
          onChanged();
        }
        if (!other.getClusterId().isEmpty()) {
          clusterId_ = other.clusterId_;
          onChanged();
        }
        if (other.hasPartitions()) {
          mergePartitions(other.getPartitions());
        }
        if (other.hasReplicationFactor()) {
          mergeReplicationFactor(other.getReplicationFactor());
        }
        switch (other.getTopicConfigCase()) {
          case TOPIC_CONFIG_2_1: {
            mergeTopicConfig21(other.getTopicConfig21());
            break;
          }
          case TOPIC_CONFIG_2_6: {
            mergeTopicConfig26(other.getTopicConfig26());
            break;
          }
          case TOPICCONFIG_NOT_SET: {
            break;
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int topicConfigCase_ = 0;
      private java.lang.Object topicConfig_;
      public TopicConfigCase
          getTopicConfigCase() {
        return TopicConfigCase.forNumber(
            topicConfigCase_);
      }

      public Builder clearTopicConfig() {
        topicConfigCase_ = 0;
        topicConfig_ = null;
        onChanged();
        return this;
      }


      private java.lang.Object name_ = "";
      /**
       * <pre>
       * Name of the topic.
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Name of the topic.
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Name of the topic.
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public Builder setName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Name of the topic.
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public Builder clearName() {
        
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Name of the topic.
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        name_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object clusterId_ = "";
      /**
       * <pre>
       * ID of an Apache Kafka® cluster that the topic belongs to.
       * To get the Apache Kafka® cluster ID, make a [ClusterService.List] request.
       * </pre>
       *
       * <code>string cluster_id = 2;</code>
       */
      public java.lang.String getClusterId() {
        java.lang.Object ref = clusterId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          clusterId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of an Apache Kafka® cluster that the topic belongs to.
       * To get the Apache Kafka® cluster ID, make a [ClusterService.List] request.
       * </pre>
       *
       * <code>string cluster_id = 2;</code>
       */
      public com.google.protobuf.ByteString
          getClusterIdBytes() {
        java.lang.Object ref = clusterId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          clusterId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of an Apache Kafka® cluster that the topic belongs to.
       * To get the Apache Kafka® cluster ID, make a [ClusterService.List] request.
       * </pre>
       *
       * <code>string cluster_id = 2;</code>
       */
      public Builder setClusterId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        clusterId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of an Apache Kafka® cluster that the topic belongs to.
       * To get the Apache Kafka® cluster ID, make a [ClusterService.List] request.
       * </pre>
       *
       * <code>string cluster_id = 2;</code>
       */
      public Builder clearClusterId() {
        
        clusterId_ = getDefaultInstance().getClusterId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of an Apache Kafka® cluster that the topic belongs to.
       * To get the Apache Kafka® cluster ID, make a [ClusterService.List] request.
       * </pre>
       *
       * <code>string cluster_id = 2;</code>
       */
      public Builder setClusterIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        clusterId_ = value;
        onChanged();
        return this;
      }

      private com.google.protobuf.Int64Value partitions_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> partitionsBuilder_;
      /**
       * <pre>
       * The number of the topic's partitions.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value partitions = 3;</code>
       */
      public boolean hasPartitions() {
        return partitionsBuilder_ != null || partitions_ != null;
      }
      /**
       * <pre>
       * The number of the topic's partitions.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value partitions = 3;</code>
       */
      public com.google.protobuf.Int64Value getPartitions() {
        if (partitionsBuilder_ == null) {
          return partitions_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : partitions_;
        } else {
          return partitionsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of the topic's partitions.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value partitions = 3;</code>
       */
      public Builder setPartitions(com.google.protobuf.Int64Value value) {
        if (partitionsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          partitions_ = value;
          onChanged();
        } else {
          partitionsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of the topic's partitions.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value partitions = 3;</code>
       */
      public Builder setPartitions(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (partitionsBuilder_ == null) {
          partitions_ = builderForValue.build();
          onChanged();
        } else {
          partitionsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of the topic's partitions.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value partitions = 3;</code>
       */
      public Builder mergePartitions(com.google.protobuf.Int64Value value) {
        if (partitionsBuilder_ == null) {
          if (partitions_ != null) {
            partitions_ =
              com.google.protobuf.Int64Value.newBuilder(partitions_).mergeFrom(value).buildPartial();
          } else {
            partitions_ = value;
          }
          onChanged();
        } else {
          partitionsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of the topic's partitions.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value partitions = 3;</code>
       */
      public Builder clearPartitions() {
        if (partitionsBuilder_ == null) {
          partitions_ = null;
          onChanged();
        } else {
          partitions_ = null;
          partitionsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of the topic's partitions.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value partitions = 3;</code>
       */
      public com.google.protobuf.Int64Value.Builder getPartitionsBuilder() {
        
        onChanged();
        return getPartitionsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of the topic's partitions.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value partitions = 3;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getPartitionsOrBuilder() {
        if (partitionsBuilder_ != null) {
          return partitionsBuilder_.getMessageOrBuilder();
        } else {
          return partitions_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : partitions_;
        }
      }
      /**
       * <pre>
       * The number of the topic's partitions.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value partitions = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getPartitionsFieldBuilder() {
        if (partitionsBuilder_ == null) {
          partitionsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getPartitions(),
                  getParentForChildren(),
                  isClean());
          partitions_ = null;
        }
        return partitionsBuilder_;
      }

      private com.google.protobuf.Int64Value replicationFactor_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> replicationFactorBuilder_;
      /**
       * <pre>
       * Amount of data copies (replicas) for the topic in the cluster.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replication_factor = 4;</code>
       */
      public boolean hasReplicationFactor() {
        return replicationFactorBuilder_ != null || replicationFactor_ != null;
      }
      /**
       * <pre>
       * Amount of data copies (replicas) for the topic in the cluster.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replication_factor = 4;</code>
       */
      public com.google.protobuf.Int64Value getReplicationFactor() {
        if (replicationFactorBuilder_ == null) {
          return replicationFactor_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : replicationFactor_;
        } else {
          return replicationFactorBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Amount of data copies (replicas) for the topic in the cluster.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replication_factor = 4;</code>
       */
      public Builder setReplicationFactor(com.google.protobuf.Int64Value value) {
        if (replicationFactorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          replicationFactor_ = value;
          onChanged();
        } else {
          replicationFactorBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Amount of data copies (replicas) for the topic in the cluster.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replication_factor = 4;</code>
       */
      public Builder setReplicationFactor(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (replicationFactorBuilder_ == null) {
          replicationFactor_ = builderForValue.build();
          onChanged();
        } else {
          replicationFactorBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Amount of data copies (replicas) for the topic in the cluster.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replication_factor = 4;</code>
       */
      public Builder mergeReplicationFactor(com.google.protobuf.Int64Value value) {
        if (replicationFactorBuilder_ == null) {
          if (replicationFactor_ != null) {
            replicationFactor_ =
              com.google.protobuf.Int64Value.newBuilder(replicationFactor_).mergeFrom(value).buildPartial();
          } else {
            replicationFactor_ = value;
          }
          onChanged();
        } else {
          replicationFactorBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Amount of data copies (replicas) for the topic in the cluster.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replication_factor = 4;</code>
       */
      public Builder clearReplicationFactor() {
        if (replicationFactorBuilder_ == null) {
          replicationFactor_ = null;
          onChanged();
        } else {
          replicationFactor_ = null;
          replicationFactorBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Amount of data copies (replicas) for the topic in the cluster.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replication_factor = 4;</code>
       */
      public com.google.protobuf.Int64Value.Builder getReplicationFactorBuilder() {
        
        onChanged();
        return getReplicationFactorFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Amount of data copies (replicas) for the topic in the cluster.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replication_factor = 4;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getReplicationFactorOrBuilder() {
        if (replicationFactorBuilder_ != null) {
          return replicationFactorBuilder_.getMessageOrBuilder();
        } else {
          return replicationFactor_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : replicationFactor_;
        }
      }
      /**
       * <pre>
       * Amount of data copies (replicas) for the topic in the cluster.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replication_factor = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getReplicationFactorFieldBuilder() {
        if (replicationFactorBuilder_ == null) {
          replicationFactorBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getReplicationFactor(),
                  getParentForChildren(),
                  isClean());
          replicationFactor_ = null;
        }
        return replicationFactorBuilder_;
      }

      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.Builder, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1OrBuilder> topicConfig21Builder_;
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 5[json_name = "topicConfig_2_1"];</code>
       */
      public boolean hasTopicConfig21() {
        return topicConfigCase_ == 5;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 5[json_name = "topicConfig_2_1"];</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 getTopicConfig21() {
        if (topicConfig21Builder_ == null) {
          if (topicConfigCase_ == 5) {
            return (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1) topicConfig_;
          }
          return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.getDefaultInstance();
        } else {
          if (topicConfigCase_ == 5) {
            return topicConfig21Builder_.getMessage();
          }
          return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.getDefaultInstance();
        }
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 5[json_name = "topicConfig_2_1"];</code>
       */
      public Builder setTopicConfig21(yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 value) {
        if (topicConfig21Builder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          topicConfig_ = value;
          onChanged();
        } else {
          topicConfig21Builder_.setMessage(value);
        }
        topicConfigCase_ = 5;
        return this;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 5[json_name = "topicConfig_2_1"];</code>
       */
      public Builder setTopicConfig21(
          yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.Builder builderForValue) {
        if (topicConfig21Builder_ == null) {
          topicConfig_ = builderForValue.build();
          onChanged();
        } else {
          topicConfig21Builder_.setMessage(builderForValue.build());
        }
        topicConfigCase_ = 5;
        return this;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 5[json_name = "topicConfig_2_1"];</code>
       */
      public Builder mergeTopicConfig21(yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 value) {
        if (topicConfig21Builder_ == null) {
          if (topicConfigCase_ == 5 &&
              topicConfig_ != yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.getDefaultInstance()) {
            topicConfig_ = yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.newBuilder((yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1) topicConfig_)
                .mergeFrom(value).buildPartial();
          } else {
            topicConfig_ = value;
          }
          onChanged();
        } else {
          if (topicConfigCase_ == 5) {
            topicConfig21Builder_.mergeFrom(value);
          }
          topicConfig21Builder_.setMessage(value);
        }
        topicConfigCase_ = 5;
        return this;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 5[json_name = "topicConfig_2_1"];</code>
       */
      public Builder clearTopicConfig21() {
        if (topicConfig21Builder_ == null) {
          if (topicConfigCase_ == 5) {
            topicConfigCase_ = 0;
            topicConfig_ = null;
            onChanged();
          }
        } else {
          if (topicConfigCase_ == 5) {
            topicConfigCase_ = 0;
            topicConfig_ = null;
          }
          topicConfig21Builder_.clear();
        }
        return this;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 5[json_name = "topicConfig_2_1"];</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.Builder getTopicConfig21Builder() {
        return getTopicConfig21FieldBuilder().getBuilder();
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 5[json_name = "topicConfig_2_1"];</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1OrBuilder getTopicConfig21OrBuilder() {
        if ((topicConfigCase_ == 5) && (topicConfig21Builder_ != null)) {
          return topicConfig21Builder_.getMessageOrBuilder();
        } else {
          if (topicConfigCase_ == 5) {
            return (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1) topicConfig_;
          }
          return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.getDefaultInstance();
        }
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 5[json_name = "topicConfig_2_1"];</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.Builder, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1OrBuilder> 
          getTopicConfig21FieldBuilder() {
        if (topicConfig21Builder_ == null) {
          if (!(topicConfigCase_ == 5)) {
            topicConfig_ = yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.getDefaultInstance();
          }
          topicConfig21Builder_ = new com.google.protobuf.SingleFieldBuilderV3<
              yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.Builder, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1OrBuilder>(
                  (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1) topicConfig_,
                  getParentForChildren(),
                  isClean());
          topicConfig_ = null;
        }
        topicConfigCase_ = 5;
        onChanged();;
        return topicConfig21Builder_;
      }

      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.Builder, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6OrBuilder> topicConfig26Builder_;
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 6[json_name = "topicConfig_2_6"];</code>
       */
      public boolean hasTopicConfig26() {
        return topicConfigCase_ == 6;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 6[json_name = "topicConfig_2_6"];</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 getTopicConfig26() {
        if (topicConfig26Builder_ == null) {
          if (topicConfigCase_ == 6) {
            return (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6) topicConfig_;
          }
          return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.getDefaultInstance();
        } else {
          if (topicConfigCase_ == 6) {
            return topicConfig26Builder_.getMessage();
          }
          return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.getDefaultInstance();
        }
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 6[json_name = "topicConfig_2_6"];</code>
       */
      public Builder setTopicConfig26(yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 value) {
        if (topicConfig26Builder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          topicConfig_ = value;
          onChanged();
        } else {
          topicConfig26Builder_.setMessage(value);
        }
        topicConfigCase_ = 6;
        return this;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 6[json_name = "topicConfig_2_6"];</code>
       */
      public Builder setTopicConfig26(
          yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.Builder builderForValue) {
        if (topicConfig26Builder_ == null) {
          topicConfig_ = builderForValue.build();
          onChanged();
        } else {
          topicConfig26Builder_.setMessage(builderForValue.build());
        }
        topicConfigCase_ = 6;
        return this;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 6[json_name = "topicConfig_2_6"];</code>
       */
      public Builder mergeTopicConfig26(yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 value) {
        if (topicConfig26Builder_ == null) {
          if (topicConfigCase_ == 6 &&
              topicConfig_ != yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.getDefaultInstance()) {
            topicConfig_ = yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.newBuilder((yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6) topicConfig_)
                .mergeFrom(value).buildPartial();
          } else {
            topicConfig_ = value;
          }
          onChanged();
        } else {
          if (topicConfigCase_ == 6) {
            topicConfig26Builder_.mergeFrom(value);
          }
          topicConfig26Builder_.setMessage(value);
        }
        topicConfigCase_ = 6;
        return this;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 6[json_name = "topicConfig_2_6"];</code>
       */
      public Builder clearTopicConfig26() {
        if (topicConfig26Builder_ == null) {
          if (topicConfigCase_ == 6) {
            topicConfigCase_ = 0;
            topicConfig_ = null;
            onChanged();
          }
        } else {
          if (topicConfigCase_ == 6) {
            topicConfigCase_ = 0;
            topicConfig_ = null;
          }
          topicConfig26Builder_.clear();
        }
        return this;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 6[json_name = "topicConfig_2_6"];</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.Builder getTopicConfig26Builder() {
        return getTopicConfig26FieldBuilder().getBuilder();
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 6[json_name = "topicConfig_2_6"];</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6OrBuilder getTopicConfig26OrBuilder() {
        if ((topicConfigCase_ == 6) && (topicConfig26Builder_ != null)) {
          return topicConfig26Builder_.getMessageOrBuilder();
        } else {
          if (topicConfigCase_ == 6) {
            return (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6) topicConfig_;
          }
          return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.getDefaultInstance();
        }
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 6[json_name = "topicConfig_2_6"];</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.Builder, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6OrBuilder> 
          getTopicConfig26FieldBuilder() {
        if (topicConfig26Builder_ == null) {
          if (!(topicConfigCase_ == 6)) {
            topicConfig_ = yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.getDefaultInstance();
          }
          topicConfig26Builder_ = new com.google.protobuf.SingleFieldBuilderV3<
              yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.Builder, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6OrBuilder>(
                  (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6) topicConfig_,
                  getParentForChildren(),
                  isClean());
          topicConfig_ = null;
        }
        topicConfigCase_ = 6;
        onChanged();;
        return topicConfig26Builder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.Topic)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.Topic)
    private static final yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic();
    }

    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<Topic>
        PARSER = new com.google.protobuf.AbstractParser<Topic>() {
      @java.lang.Override
      public Topic parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Topic(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<Topic> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Topic> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.Topic getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface TopicSpecOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.TopicSpec)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Name of the topic.
     * </pre>
     *
     * <code>string name = 1;</code>
     */
    java.lang.String getName();
    /**
     * <pre>
     * Name of the topic.
     * </pre>
     *
     * <code>string name = 1;</code>
     */
    com.google.protobuf.ByteString
        getNameBytes();

    /**
     * <pre>
     * The number of the topic's partitions.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value partitions = 2;</code>
     */
    boolean hasPartitions();
    /**
     * <pre>
     * The number of the topic's partitions.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value partitions = 2;</code>
     */
    com.google.protobuf.Int64Value getPartitions();
    /**
     * <pre>
     * The number of the topic's partitions.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value partitions = 2;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getPartitionsOrBuilder();

    /**
     * <pre>
     * Amount of copies of a topic data kept in the cluster.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value replication_factor = 3;</code>
     */
    boolean hasReplicationFactor();
    /**
     * <pre>
     * Amount of copies of a topic data kept in the cluster.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value replication_factor = 3;</code>
     */
    com.google.protobuf.Int64Value getReplicationFactor();
    /**
     * <pre>
     * Amount of copies of a topic data kept in the cluster.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value replication_factor = 3;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getReplicationFactorOrBuilder();

    /**
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 4;</code>
     */
    boolean hasTopicConfig21();
    /**
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 4;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 getTopicConfig21();
    /**
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 4;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1OrBuilder getTopicConfig21OrBuilder();

    /**
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 5;</code>
     */
    boolean hasTopicConfig26();
    /**
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 5;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 getTopicConfig26();
    /**
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 5;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6OrBuilder getTopicConfig26OrBuilder();

    public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec.TopicConfigCase getTopicConfigCase();
  }
  /**
   * Protobuf type {@code yandex.cloud.mdb.kafka.v1.TopicSpec}
   */
  public  static final class TopicSpec extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.TopicSpec)
      TopicSpecOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use TopicSpec.newBuilder() to construct.
    private TopicSpec(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private TopicSpec() {
      name_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private TopicSpec(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              name_ = s;
              break;
            }
            case 18: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (partitions_ != null) {
                subBuilder = partitions_.toBuilder();
              }
              partitions_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(partitions_);
                partitions_ = subBuilder.buildPartial();
              }

              break;
            }
            case 26: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (replicationFactor_ != null) {
                subBuilder = replicationFactor_.toBuilder();
              }
              replicationFactor_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(replicationFactor_);
                replicationFactor_ = subBuilder.buildPartial();
              }

              break;
            }
            case 34: {
              yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.Builder subBuilder = null;
              if (topicConfigCase_ == 4) {
                subBuilder = ((yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1) topicConfig_).toBuilder();
              }
              topicConfig_ =
                  input.readMessage(yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom((yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1) topicConfig_);
                topicConfig_ = subBuilder.buildPartial();
              }
              topicConfigCase_ = 4;
              break;
            }
            case 42: {
              yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.Builder subBuilder = null;
              if (topicConfigCase_ == 5) {
                subBuilder = ((yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6) topicConfig_).toBuilder();
              }
              topicConfig_ =
                  input.readMessage(yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom((yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6) topicConfig_);
                topicConfig_ = subBuilder.buildPartial();
              }
              topicConfigCase_ = 5;
              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_TopicSpec_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_TopicSpec_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec.class, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec.Builder.class);
    }

    private int topicConfigCase_ = 0;
    private java.lang.Object topicConfig_;
    public enum TopicConfigCase
        implements com.google.protobuf.Internal.EnumLite {
      TOPIC_CONFIG_2_1(4),
      TOPIC_CONFIG_2_6(5),
      TOPICCONFIG_NOT_SET(0);
      private final int value;
      private TopicConfigCase(int value) {
        this.value = value;
      }
      /**
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static TopicConfigCase valueOf(int value) {
        return forNumber(value);
      }

      public static TopicConfigCase forNumber(int value) {
        switch (value) {
          case 4: return TOPIC_CONFIG_2_1;
          case 5: return TOPIC_CONFIG_2_6;
          case 0: return TOPICCONFIG_NOT_SET;
          default: return null;
        }
      }
      public int getNumber() {
        return this.value;
      }
    };

    public TopicConfigCase
    getTopicConfigCase() {
      return TopicConfigCase.forNumber(
          topicConfigCase_);
    }

    public static final int NAME_FIELD_NUMBER = 1;
    private volatile java.lang.Object name_;
    /**
     * <pre>
     * Name of the topic.
     * </pre>
     *
     * <code>string name = 1;</code>
     */
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        name_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Name of the topic.
     * </pre>
     *
     * <code>string name = 1;</code>
     */
    public com.google.protobuf.ByteString
        getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int PARTITIONS_FIELD_NUMBER = 2;
    private com.google.protobuf.Int64Value partitions_;
    /**
     * <pre>
     * The number of the topic's partitions.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value partitions = 2;</code>
     */
    public boolean hasPartitions() {
      return partitions_ != null;
    }
    /**
     * <pre>
     * The number of the topic's partitions.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value partitions = 2;</code>
     */
    public com.google.protobuf.Int64Value getPartitions() {
      return partitions_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : partitions_;
    }
    /**
     * <pre>
     * The number of the topic's partitions.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value partitions = 2;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getPartitionsOrBuilder() {
      return getPartitions();
    }

    public static final int REPLICATION_FACTOR_FIELD_NUMBER = 3;
    private com.google.protobuf.Int64Value replicationFactor_;
    /**
     * <pre>
     * Amount of copies of a topic data kept in the cluster.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value replication_factor = 3;</code>
     */
    public boolean hasReplicationFactor() {
      return replicationFactor_ != null;
    }
    /**
     * <pre>
     * Amount of copies of a topic data kept in the cluster.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value replication_factor = 3;</code>
     */
    public com.google.protobuf.Int64Value getReplicationFactor() {
      return replicationFactor_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : replicationFactor_;
    }
    /**
     * <pre>
     * Amount of copies of a topic data kept in the cluster.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value replication_factor = 3;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getReplicationFactorOrBuilder() {
      return getReplicationFactor();
    }

    public static final int TOPIC_CONFIG_2_1_FIELD_NUMBER = 4;
    /**
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 4;</code>
     */
    public boolean hasTopicConfig21() {
      return topicConfigCase_ == 4;
    }
    /**
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 4;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 getTopicConfig21() {
      if (topicConfigCase_ == 4) {
         return (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1) topicConfig_;
      }
      return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.getDefaultInstance();
    }
    /**
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 4;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1OrBuilder getTopicConfig21OrBuilder() {
      if (topicConfigCase_ == 4) {
         return (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1) topicConfig_;
      }
      return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.getDefaultInstance();
    }

    public static final int TOPIC_CONFIG_2_6_FIELD_NUMBER = 5;
    /**
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 5;</code>
     */
    public boolean hasTopicConfig26() {
      return topicConfigCase_ == 5;
    }
    /**
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 5;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 getTopicConfig26() {
      if (topicConfigCase_ == 5) {
         return (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6) topicConfig_;
      }
      return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.getDefaultInstance();
    }
    /**
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 5;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6OrBuilder getTopicConfig26OrBuilder() {
      if (topicConfigCase_ == 5) {
         return (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6) topicConfig_;
      }
      return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.getDefaultInstance();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!getNameBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, name_);
      }
      if (partitions_ != null) {
        output.writeMessage(2, getPartitions());
      }
      if (replicationFactor_ != null) {
        output.writeMessage(3, getReplicationFactor());
      }
      if (topicConfigCase_ == 4) {
        output.writeMessage(4, (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1) topicConfig_);
      }
      if (topicConfigCase_ == 5) {
        output.writeMessage(5, (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6) topicConfig_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!getNameBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, name_);
      }
      if (partitions_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getPartitions());
      }
      if (replicationFactor_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getReplicationFactor());
      }
      if (topicConfigCase_ == 4) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1) topicConfig_);
      }
      if (topicConfigCase_ == 5) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6) topicConfig_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec)) {
        return super.equals(obj);
      }
      yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec other = (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec) obj;

      boolean result = true;
      result = result && getName()
          .equals(other.getName());
      result = result && (hasPartitions() == other.hasPartitions());
      if (hasPartitions()) {
        result = result && getPartitions()
            .equals(other.getPartitions());
      }
      result = result && (hasReplicationFactor() == other.hasReplicationFactor());
      if (hasReplicationFactor()) {
        result = result && getReplicationFactor()
            .equals(other.getReplicationFactor());
      }
      result = result && getTopicConfigCase().equals(
          other.getTopicConfigCase());
      if (!result) return false;
      switch (topicConfigCase_) {
        case 4:
          result = result && getTopicConfig21()
              .equals(other.getTopicConfig21());
          break;
        case 5:
          result = result && getTopicConfig26()
              .equals(other.getTopicConfig26());
          break;
        case 0:
        default:
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + NAME_FIELD_NUMBER;
      hash = (53 * hash) + getName().hashCode();
      if (hasPartitions()) {
        hash = (37 * hash) + PARTITIONS_FIELD_NUMBER;
        hash = (53 * hash) + getPartitions().hashCode();
      }
      if (hasReplicationFactor()) {
        hash = (37 * hash) + REPLICATION_FACTOR_FIELD_NUMBER;
        hash = (53 * hash) + getReplicationFactor().hashCode();
      }
      switch (topicConfigCase_) {
        case 4:
          hash = (37 * hash) + TOPIC_CONFIG_2_1_FIELD_NUMBER;
          hash = (53 * hash) + getTopicConfig21().hashCode();
          break;
        case 5:
          hash = (37 * hash) + TOPIC_CONFIG_2_6_FIELD_NUMBER;
          hash = (53 * hash) + getTopicConfig26().hashCode();
          break;
        case 0:
        default:
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.TopicSpec}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.TopicSpec)
        yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpecOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_TopicSpec_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_TopicSpec_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec.class, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec.Builder.class);
      }

      // Construct using yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        name_ = "";

        if (partitionsBuilder_ == null) {
          partitions_ = null;
        } else {
          partitions_ = null;
          partitionsBuilder_ = null;
        }
        if (replicationFactorBuilder_ == null) {
          replicationFactor_ = null;
        } else {
          replicationFactor_ = null;
          replicationFactorBuilder_ = null;
        }
        topicConfigCase_ = 0;
        topicConfig_ = null;
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_TopicSpec_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec getDefaultInstanceForType() {
        return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec build() {
        yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec buildPartial() {
        yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec result = new yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec(this);
        result.name_ = name_;
        if (partitionsBuilder_ == null) {
          result.partitions_ = partitions_;
        } else {
          result.partitions_ = partitionsBuilder_.build();
        }
        if (replicationFactorBuilder_ == null) {
          result.replicationFactor_ = replicationFactor_;
        } else {
          result.replicationFactor_ = replicationFactorBuilder_.build();
        }
        if (topicConfigCase_ == 4) {
          if (topicConfig21Builder_ == null) {
            result.topicConfig_ = topicConfig_;
          } else {
            result.topicConfig_ = topicConfig21Builder_.build();
          }
        }
        if (topicConfigCase_ == 5) {
          if (topicConfig26Builder_ == null) {
            result.topicConfig_ = topicConfig_;
          } else {
            result.topicConfig_ = topicConfig26Builder_.build();
          }
        }
        result.topicConfigCase_ = topicConfigCase_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec) {
          return mergeFrom((yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec other) {
        if (other == yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec.getDefaultInstance()) return this;
        if (!other.getName().isEmpty()) {
          name_ = other.name_;
          onChanged();
        }
        if (other.hasPartitions()) {
          mergePartitions(other.getPartitions());
        }
        if (other.hasReplicationFactor()) {
          mergeReplicationFactor(other.getReplicationFactor());
        }
        switch (other.getTopicConfigCase()) {
          case TOPIC_CONFIG_2_1: {
            mergeTopicConfig21(other.getTopicConfig21());
            break;
          }
          case TOPIC_CONFIG_2_6: {
            mergeTopicConfig26(other.getTopicConfig26());
            break;
          }
          case TOPICCONFIG_NOT_SET: {
            break;
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int topicConfigCase_ = 0;
      private java.lang.Object topicConfig_;
      public TopicConfigCase
          getTopicConfigCase() {
        return TopicConfigCase.forNumber(
            topicConfigCase_);
      }

      public Builder clearTopicConfig() {
        topicConfigCase_ = 0;
        topicConfig_ = null;
        onChanged();
        return this;
      }


      private java.lang.Object name_ = "";
      /**
       * <pre>
       * Name of the topic.
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Name of the topic.
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Name of the topic.
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public Builder setName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Name of the topic.
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public Builder clearName() {
        
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Name of the topic.
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        name_ = value;
        onChanged();
        return this;
      }

      private com.google.protobuf.Int64Value partitions_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> partitionsBuilder_;
      /**
       * <pre>
       * The number of the topic's partitions.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value partitions = 2;</code>
       */
      public boolean hasPartitions() {
        return partitionsBuilder_ != null || partitions_ != null;
      }
      /**
       * <pre>
       * The number of the topic's partitions.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value partitions = 2;</code>
       */
      public com.google.protobuf.Int64Value getPartitions() {
        if (partitionsBuilder_ == null) {
          return partitions_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : partitions_;
        } else {
          return partitionsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of the topic's partitions.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value partitions = 2;</code>
       */
      public Builder setPartitions(com.google.protobuf.Int64Value value) {
        if (partitionsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          partitions_ = value;
          onChanged();
        } else {
          partitionsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of the topic's partitions.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value partitions = 2;</code>
       */
      public Builder setPartitions(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (partitionsBuilder_ == null) {
          partitions_ = builderForValue.build();
          onChanged();
        } else {
          partitionsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of the topic's partitions.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value partitions = 2;</code>
       */
      public Builder mergePartitions(com.google.protobuf.Int64Value value) {
        if (partitionsBuilder_ == null) {
          if (partitions_ != null) {
            partitions_ =
              com.google.protobuf.Int64Value.newBuilder(partitions_).mergeFrom(value).buildPartial();
          } else {
            partitions_ = value;
          }
          onChanged();
        } else {
          partitionsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of the topic's partitions.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value partitions = 2;</code>
       */
      public Builder clearPartitions() {
        if (partitionsBuilder_ == null) {
          partitions_ = null;
          onChanged();
        } else {
          partitions_ = null;
          partitionsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of the topic's partitions.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value partitions = 2;</code>
       */
      public com.google.protobuf.Int64Value.Builder getPartitionsBuilder() {
        
        onChanged();
        return getPartitionsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of the topic's partitions.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value partitions = 2;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getPartitionsOrBuilder() {
        if (partitionsBuilder_ != null) {
          return partitionsBuilder_.getMessageOrBuilder();
        } else {
          return partitions_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : partitions_;
        }
      }
      /**
       * <pre>
       * The number of the topic's partitions.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value partitions = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getPartitionsFieldBuilder() {
        if (partitionsBuilder_ == null) {
          partitionsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getPartitions(),
                  getParentForChildren(),
                  isClean());
          partitions_ = null;
        }
        return partitionsBuilder_;
      }

      private com.google.protobuf.Int64Value replicationFactor_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> replicationFactorBuilder_;
      /**
       * <pre>
       * Amount of copies of a topic data kept in the cluster.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replication_factor = 3;</code>
       */
      public boolean hasReplicationFactor() {
        return replicationFactorBuilder_ != null || replicationFactor_ != null;
      }
      /**
       * <pre>
       * Amount of copies of a topic data kept in the cluster.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replication_factor = 3;</code>
       */
      public com.google.protobuf.Int64Value getReplicationFactor() {
        if (replicationFactorBuilder_ == null) {
          return replicationFactor_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : replicationFactor_;
        } else {
          return replicationFactorBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Amount of copies of a topic data kept in the cluster.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replication_factor = 3;</code>
       */
      public Builder setReplicationFactor(com.google.protobuf.Int64Value value) {
        if (replicationFactorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          replicationFactor_ = value;
          onChanged();
        } else {
          replicationFactorBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Amount of copies of a topic data kept in the cluster.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replication_factor = 3;</code>
       */
      public Builder setReplicationFactor(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (replicationFactorBuilder_ == null) {
          replicationFactor_ = builderForValue.build();
          onChanged();
        } else {
          replicationFactorBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Amount of copies of a topic data kept in the cluster.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replication_factor = 3;</code>
       */
      public Builder mergeReplicationFactor(com.google.protobuf.Int64Value value) {
        if (replicationFactorBuilder_ == null) {
          if (replicationFactor_ != null) {
            replicationFactor_ =
              com.google.protobuf.Int64Value.newBuilder(replicationFactor_).mergeFrom(value).buildPartial();
          } else {
            replicationFactor_ = value;
          }
          onChanged();
        } else {
          replicationFactorBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Amount of copies of a topic data kept in the cluster.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replication_factor = 3;</code>
       */
      public Builder clearReplicationFactor() {
        if (replicationFactorBuilder_ == null) {
          replicationFactor_ = null;
          onChanged();
        } else {
          replicationFactor_ = null;
          replicationFactorBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Amount of copies of a topic data kept in the cluster.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replication_factor = 3;</code>
       */
      public com.google.protobuf.Int64Value.Builder getReplicationFactorBuilder() {
        
        onChanged();
        return getReplicationFactorFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Amount of copies of a topic data kept in the cluster.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replication_factor = 3;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getReplicationFactorOrBuilder() {
        if (replicationFactorBuilder_ != null) {
          return replicationFactorBuilder_.getMessageOrBuilder();
        } else {
          return replicationFactor_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : replicationFactor_;
        }
      }
      /**
       * <pre>
       * Amount of copies of a topic data kept in the cluster.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replication_factor = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getReplicationFactorFieldBuilder() {
        if (replicationFactorBuilder_ == null) {
          replicationFactorBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getReplicationFactor(),
                  getParentForChildren(),
                  isClean());
          replicationFactor_ = null;
        }
        return replicationFactorBuilder_;
      }

      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.Builder, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1OrBuilder> topicConfig21Builder_;
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 4;</code>
       */
      public boolean hasTopicConfig21() {
        return topicConfigCase_ == 4;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 4;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 getTopicConfig21() {
        if (topicConfig21Builder_ == null) {
          if (topicConfigCase_ == 4) {
            return (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1) topicConfig_;
          }
          return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.getDefaultInstance();
        } else {
          if (topicConfigCase_ == 4) {
            return topicConfig21Builder_.getMessage();
          }
          return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.getDefaultInstance();
        }
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 4;</code>
       */
      public Builder setTopicConfig21(yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 value) {
        if (topicConfig21Builder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          topicConfig_ = value;
          onChanged();
        } else {
          topicConfig21Builder_.setMessage(value);
        }
        topicConfigCase_ = 4;
        return this;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 4;</code>
       */
      public Builder setTopicConfig21(
          yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.Builder builderForValue) {
        if (topicConfig21Builder_ == null) {
          topicConfig_ = builderForValue.build();
          onChanged();
        } else {
          topicConfig21Builder_.setMessage(builderForValue.build());
        }
        topicConfigCase_ = 4;
        return this;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 4;</code>
       */
      public Builder mergeTopicConfig21(yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 value) {
        if (topicConfig21Builder_ == null) {
          if (topicConfigCase_ == 4 &&
              topicConfig_ != yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.getDefaultInstance()) {
            topicConfig_ = yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.newBuilder((yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1) topicConfig_)
                .mergeFrom(value).buildPartial();
          } else {
            topicConfig_ = value;
          }
          onChanged();
        } else {
          if (topicConfigCase_ == 4) {
            topicConfig21Builder_.mergeFrom(value);
          }
          topicConfig21Builder_.setMessage(value);
        }
        topicConfigCase_ = 4;
        return this;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 4;</code>
       */
      public Builder clearTopicConfig21() {
        if (topicConfig21Builder_ == null) {
          if (topicConfigCase_ == 4) {
            topicConfigCase_ = 0;
            topicConfig_ = null;
            onChanged();
          }
        } else {
          if (topicConfigCase_ == 4) {
            topicConfigCase_ = 0;
            topicConfig_ = null;
          }
          topicConfig21Builder_.clear();
        }
        return this;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 4;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.Builder getTopicConfig21Builder() {
        return getTopicConfig21FieldBuilder().getBuilder();
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 4;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1OrBuilder getTopicConfig21OrBuilder() {
        if ((topicConfigCase_ == 4) && (topicConfig21Builder_ != null)) {
          return topicConfig21Builder_.getMessageOrBuilder();
        } else {
          if (topicConfigCase_ == 4) {
            return (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1) topicConfig_;
          }
          return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.getDefaultInstance();
        }
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1 topic_config_2_1 = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.Builder, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1OrBuilder> 
          getTopicConfig21FieldBuilder() {
        if (topicConfig21Builder_ == null) {
          if (!(topicConfigCase_ == 4)) {
            topicConfig_ = yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.getDefaultInstance();
          }
          topicConfig21Builder_ = new com.google.protobuf.SingleFieldBuilderV3<
              yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.Builder, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1OrBuilder>(
                  (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1) topicConfig_,
                  getParentForChildren(),
                  isClean());
          topicConfig_ = null;
        }
        topicConfigCase_ = 4;
        onChanged();;
        return topicConfig21Builder_;
      }

      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.Builder, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6OrBuilder> topicConfig26Builder_;
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 5;</code>
       */
      public boolean hasTopicConfig26() {
        return topicConfigCase_ == 5;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 5;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 getTopicConfig26() {
        if (topicConfig26Builder_ == null) {
          if (topicConfigCase_ == 5) {
            return (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6) topicConfig_;
          }
          return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.getDefaultInstance();
        } else {
          if (topicConfigCase_ == 5) {
            return topicConfig26Builder_.getMessage();
          }
          return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.getDefaultInstance();
        }
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 5;</code>
       */
      public Builder setTopicConfig26(yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 value) {
        if (topicConfig26Builder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          topicConfig_ = value;
          onChanged();
        } else {
          topicConfig26Builder_.setMessage(value);
        }
        topicConfigCase_ = 5;
        return this;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 5;</code>
       */
      public Builder setTopicConfig26(
          yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.Builder builderForValue) {
        if (topicConfig26Builder_ == null) {
          topicConfig_ = builderForValue.build();
          onChanged();
        } else {
          topicConfig26Builder_.setMessage(builderForValue.build());
        }
        topicConfigCase_ = 5;
        return this;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 5;</code>
       */
      public Builder mergeTopicConfig26(yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 value) {
        if (topicConfig26Builder_ == null) {
          if (topicConfigCase_ == 5 &&
              topicConfig_ != yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.getDefaultInstance()) {
            topicConfig_ = yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.newBuilder((yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6) topicConfig_)
                .mergeFrom(value).buildPartial();
          } else {
            topicConfig_ = value;
          }
          onChanged();
        } else {
          if (topicConfigCase_ == 5) {
            topicConfig26Builder_.mergeFrom(value);
          }
          topicConfig26Builder_.setMessage(value);
        }
        topicConfigCase_ = 5;
        return this;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 5;</code>
       */
      public Builder clearTopicConfig26() {
        if (topicConfig26Builder_ == null) {
          if (topicConfigCase_ == 5) {
            topicConfigCase_ = 0;
            topicConfig_ = null;
            onChanged();
          }
        } else {
          if (topicConfigCase_ == 5) {
            topicConfigCase_ = 0;
            topicConfig_ = null;
          }
          topicConfig26Builder_.clear();
        }
        return this;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 5;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.Builder getTopicConfig26Builder() {
        return getTopicConfig26FieldBuilder().getBuilder();
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 5;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6OrBuilder getTopicConfig26OrBuilder() {
        if ((topicConfigCase_ == 5) && (topicConfig26Builder_ != null)) {
          return topicConfig26Builder_.getMessageOrBuilder();
        } else {
          if (topicConfigCase_ == 5) {
            return (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6) topicConfig_;
          }
          return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.getDefaultInstance();
        }
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6 topic_config_2_6 = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.Builder, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6OrBuilder> 
          getTopicConfig26FieldBuilder() {
        if (topicConfig26Builder_ == null) {
          if (!(topicConfigCase_ == 5)) {
            topicConfig_ = yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.getDefaultInstance();
          }
          topicConfig26Builder_ = new com.google.protobuf.SingleFieldBuilderV3<
              yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.Builder, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6OrBuilder>(
                  (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6) topicConfig_,
                  getParentForChildren(),
                  isClean());
          topicConfig_ = null;
        }
        topicConfigCase_ = 5;
        onChanged();;
        return topicConfig26Builder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.TopicSpec)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.TopicSpec)
    private static final yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec();
    }

    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<TopicSpec>
        PARSER = new com.google.protobuf.AbstractParser<TopicSpec>() {
      @java.lang.Override
      public TopicSpec parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new TopicSpec(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<TopicSpec> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<TopicSpec> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicSpec getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface TopicConfig2_1OrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.TopicConfig2_1)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Retention policy to use on old log messages.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1.CleanupPolicy cleanup_policy = 1;</code>
     */
    int getCleanupPolicyValue();
    /**
     * <pre>
     * Retention policy to use on old log messages.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1.CleanupPolicy cleanup_policy = 1;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.CleanupPolicy getCleanupPolicy();

    /**
     * <pre>
     * The compression type for a given topic.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 2;</code>
     */
    int getCompressionTypeValue();
    /**
     * <pre>
     * The compression type for a given topic.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 2;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.Common.CompressionType getCompressionType();

    /**
     * <pre>
     * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
     */
    boolean hasDeleteRetentionMs();
    /**
     * <pre>
     * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
     */
    com.google.protobuf.Int64Value getDeleteRetentionMs();
    /**
     * <pre>
     * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getDeleteRetentionMsOrBuilder();

    /**
     * <pre>
     * The time to wait before deleting a file from the filesystem.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
     */
    boolean hasFileDeleteDelayMs();
    /**
     * <pre>
     * The time to wait before deleting a file from the filesystem.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
     */
    com.google.protobuf.Int64Value getFileDeleteDelayMs();
    /**
     * <pre>
     * The time to wait before deleting a file from the filesystem.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getFileDeleteDelayMsOrBuilder();

    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_messages] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
     */
    boolean hasFlushMessages();
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_messages] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
     */
    com.google.protobuf.Int64Value getFlushMessages();
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_messages] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getFlushMessagesOrBuilder();

    /**
     * <pre>
     * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_ms] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
     */
    boolean hasFlushMs();
    /**
     * <pre>
     * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_ms] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
     */
    com.google.protobuf.Int64Value getFlushMs();
    /**
     * <pre>
     * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_ms] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getFlushMsOrBuilder();

    /**
     * <pre>
     * The minimum time in milliseconds a message will remain uncompacted in the log.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
     */
    boolean hasMinCompactionLagMs();
    /**
     * <pre>
     * The minimum time in milliseconds a message will remain uncompacted in the log.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
     */
    com.google.protobuf.Int64Value getMinCompactionLagMs();
    /**
     * <pre>
     * The minimum time in milliseconds a message will remain uncompacted in the log.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getMinCompactionLagMsOrBuilder();

    /**
     * <pre>
     * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
     * It is helpful if you need to control the size of log due to limited disk space.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_bytes] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
     */
    boolean hasRetentionBytes();
    /**
     * <pre>
     * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
     * It is helpful if you need to control the size of log due to limited disk space.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_bytes] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
     */
    com.google.protobuf.Int64Value getRetentionBytes();
    /**
     * <pre>
     * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
     * It is helpful if you need to control the size of log due to limited disk space.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_bytes] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getRetentionBytesOrBuilder();

    /**
     * <pre>
     * The number of milliseconds to keep a log segment's file before deleting it.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_ms] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
     */
    boolean hasRetentionMs();
    /**
     * <pre>
     * The number of milliseconds to keep a log segment's file before deleting it.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_ms] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
     */
    com.google.protobuf.Int64Value getRetentionMs();
    /**
     * <pre>
     * The number of milliseconds to keep a log segment's file before deleting it.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_ms] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getRetentionMsOrBuilder();

    /**
     * <pre>
     * The largest record batch size allowed in topic.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
     */
    boolean hasMaxMessageBytes();
    /**
     * <pre>
     * The largest record batch size allowed in topic.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
     */
    com.google.protobuf.Int64Value getMaxMessageBytes();
    /**
     * <pre>
     * The largest record batch size allowed in topic.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getMaxMessageBytesOrBuilder();

    /**
     * <pre>
     * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
     * to be considered successful (when a producer sets acks to "all").
     * </pre>
     *
     * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
     */
    boolean hasMinInsyncReplicas();
    /**
     * <pre>
     * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
     * to be considered successful (when a producer sets acks to "all").
     * </pre>
     *
     * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
     */
    com.google.protobuf.Int64Value getMinInsyncReplicas();
    /**
     * <pre>
     * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
     * to be considered successful (when a producer sets acks to "all").
     * </pre>
     *
     * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getMinInsyncReplicasOrBuilder();

    /**
     * <pre>
     * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
     * at a time so a larger segment size means fewer files but less granular control over retention.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_segment_bytes] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
     */
    boolean hasSegmentBytes();
    /**
     * <pre>
     * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
     * at a time so a larger segment size means fewer files but less granular control over retention.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_segment_bytes] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
     */
    com.google.protobuf.Int64Value getSegmentBytes();
    /**
     * <pre>
     * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
     * at a time so a larger segment size means fewer files but less granular control over retention.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_segment_bytes] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getSegmentBytesOrBuilder();

    /**
     * <pre>
     * True if we should preallocate the file on disk when creating a new log segment.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_preallocate] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue preallocate = 13;</code>
     */
    boolean hasPreallocate();
    /**
     * <pre>
     * True if we should preallocate the file on disk when creating a new log segment.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_preallocate] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue preallocate = 13;</code>
     */
    com.google.protobuf.BoolValue getPreallocate();
    /**
     * <pre>
     * True if we should preallocate the file on disk when creating a new log segment.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_preallocate] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue preallocate = 13;</code>
     */
    com.google.protobuf.BoolValueOrBuilder getPreallocateOrBuilder();
  }
  /**
   * <pre>
   * A topic settings for 2.1.
   * </pre>
   *
   * Protobuf type {@code yandex.cloud.mdb.kafka.v1.TopicConfig2_1}
   */
  public  static final class TopicConfig2_1 extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.TopicConfig2_1)
      TopicConfig2_1OrBuilder {
  private static final long serialVersionUID = 0L;
    // Use TopicConfig2_1.newBuilder() to construct.
    private TopicConfig2_1(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private TopicConfig2_1() {
      cleanupPolicy_ = 0;
      compressionType_ = 0;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private TopicConfig2_1(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              int rawValue = input.readEnum();

              cleanupPolicy_ = rawValue;
              break;
            }
            case 16: {
              int rawValue = input.readEnum();

              compressionType_ = rawValue;
              break;
            }
            case 26: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (deleteRetentionMs_ != null) {
                subBuilder = deleteRetentionMs_.toBuilder();
              }
              deleteRetentionMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(deleteRetentionMs_);
                deleteRetentionMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 34: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (fileDeleteDelayMs_ != null) {
                subBuilder = fileDeleteDelayMs_.toBuilder();
              }
              fileDeleteDelayMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(fileDeleteDelayMs_);
                fileDeleteDelayMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 42: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (flushMessages_ != null) {
                subBuilder = flushMessages_.toBuilder();
              }
              flushMessages_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(flushMessages_);
                flushMessages_ = subBuilder.buildPartial();
              }

              break;
            }
            case 50: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (flushMs_ != null) {
                subBuilder = flushMs_.toBuilder();
              }
              flushMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(flushMs_);
                flushMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 58: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (minCompactionLagMs_ != null) {
                subBuilder = minCompactionLagMs_.toBuilder();
              }
              minCompactionLagMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(minCompactionLagMs_);
                minCompactionLagMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 66: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (retentionBytes_ != null) {
                subBuilder = retentionBytes_.toBuilder();
              }
              retentionBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(retentionBytes_);
                retentionBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 74: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (retentionMs_ != null) {
                subBuilder = retentionMs_.toBuilder();
              }
              retentionMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(retentionMs_);
                retentionMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 82: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (maxMessageBytes_ != null) {
                subBuilder = maxMessageBytes_.toBuilder();
              }
              maxMessageBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(maxMessageBytes_);
                maxMessageBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 90: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (minInsyncReplicas_ != null) {
                subBuilder = minInsyncReplicas_.toBuilder();
              }
              minInsyncReplicas_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(minInsyncReplicas_);
                minInsyncReplicas_ = subBuilder.buildPartial();
              }

              break;
            }
            case 98: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (segmentBytes_ != null) {
                subBuilder = segmentBytes_.toBuilder();
              }
              segmentBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(segmentBytes_);
                segmentBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 106: {
              com.google.protobuf.BoolValue.Builder subBuilder = null;
              if (preallocate_ != null) {
                subBuilder = preallocate_.toBuilder();
              }
              preallocate_ = input.readMessage(com.google.protobuf.BoolValue.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(preallocate_);
                preallocate_ = subBuilder.buildPartial();
              }

              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_TopicConfig2_1_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_TopicConfig2_1_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.class, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.Builder.class);
    }

    /**
     * Protobuf enum {@code yandex.cloud.mdb.kafka.v1.TopicConfig2_1.CleanupPolicy}
     */
    public enum CleanupPolicy
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>CLEANUP_POLICY_UNSPECIFIED = 0;</code>
       */
      CLEANUP_POLICY_UNSPECIFIED(0),
      /**
       * <pre>
       * this policy discards log segments when either their retention time or log size limit is reached. See also: [KafkaConfig2_1.log_retention_ms] and other similar parameters.
       * </pre>
       *
       * <code>CLEANUP_POLICY_DELETE = 1;</code>
       */
      CLEANUP_POLICY_DELETE(1),
      /**
       * <pre>
       * this policy compacts messages in log.
       * </pre>
       *
       * <code>CLEANUP_POLICY_COMPACT = 2;</code>
       */
      CLEANUP_POLICY_COMPACT(2),
      /**
       * <pre>
       * this policy use both compaction and deletion for messages and log segments.
       * </pre>
       *
       * <code>CLEANUP_POLICY_COMPACT_AND_DELETE = 3;</code>
       */
      CLEANUP_POLICY_COMPACT_AND_DELETE(3),
      UNRECOGNIZED(-1),
      ;

      /**
       * <code>CLEANUP_POLICY_UNSPECIFIED = 0;</code>
       */
      public static final int CLEANUP_POLICY_UNSPECIFIED_VALUE = 0;
      /**
       * <pre>
       * this policy discards log segments when either their retention time or log size limit is reached. See also: [KafkaConfig2_1.log_retention_ms] and other similar parameters.
       * </pre>
       *
       * <code>CLEANUP_POLICY_DELETE = 1;</code>
       */
      public static final int CLEANUP_POLICY_DELETE_VALUE = 1;
      /**
       * <pre>
       * this policy compacts messages in log.
       * </pre>
       *
       * <code>CLEANUP_POLICY_COMPACT = 2;</code>
       */
      public static final int CLEANUP_POLICY_COMPACT_VALUE = 2;
      /**
       * <pre>
       * this policy use both compaction and deletion for messages and log segments.
       * </pre>
       *
       * <code>CLEANUP_POLICY_COMPACT_AND_DELETE = 3;</code>
       */
      public static final int CLEANUP_POLICY_COMPACT_AND_DELETE_VALUE = 3;


      public final int getNumber() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalArgumentException(
              "Can't get the number of an unknown enum value.");
        }
        return value;
      }

      /**
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static CleanupPolicy valueOf(int value) {
        return forNumber(value);
      }

      public static CleanupPolicy forNumber(int value) {
        switch (value) {
          case 0: return CLEANUP_POLICY_UNSPECIFIED;
          case 1: return CLEANUP_POLICY_DELETE;
          case 2: return CLEANUP_POLICY_COMPACT;
          case 3: return CLEANUP_POLICY_COMPACT_AND_DELETE;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<CleanupPolicy>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final com.google.protobuf.Internal.EnumLiteMap<
          CleanupPolicy> internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<CleanupPolicy>() {
              public CleanupPolicy findValueByNumber(int number) {
                return CleanupPolicy.forNumber(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(ordinal());
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.getDescriptor().getEnumTypes().get(0);
      }

      private static final CleanupPolicy[] VALUES = values();

      public static CleanupPolicy valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        if (desc.getIndex() == -1) {
          return UNRECOGNIZED;
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private CleanupPolicy(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:yandex.cloud.mdb.kafka.v1.TopicConfig2_1.CleanupPolicy)
    }

    public static final int CLEANUP_POLICY_FIELD_NUMBER = 1;
    private int cleanupPolicy_;
    /**
     * <pre>
     * Retention policy to use on old log messages.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1.CleanupPolicy cleanup_policy = 1;</code>
     */
    public int getCleanupPolicyValue() {
      return cleanupPolicy_;
    }
    /**
     * <pre>
     * Retention policy to use on old log messages.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1.CleanupPolicy cleanup_policy = 1;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.CleanupPolicy getCleanupPolicy() {
      @SuppressWarnings("deprecation")
      yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.CleanupPolicy result = yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.CleanupPolicy.valueOf(cleanupPolicy_);
      return result == null ? yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.CleanupPolicy.UNRECOGNIZED : result;
    }

    public static final int COMPRESSION_TYPE_FIELD_NUMBER = 2;
    private int compressionType_;
    /**
     * <pre>
     * The compression type for a given topic.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 2;</code>
     */
    public int getCompressionTypeValue() {
      return compressionType_;
    }
    /**
     * <pre>
     * The compression type for a given topic.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 2;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.Common.CompressionType getCompressionType() {
      @SuppressWarnings("deprecation")
      yandex.cloud.api.mdb.kafka.v1.Common.CompressionType result = yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.valueOf(compressionType_);
      return result == null ? yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.UNRECOGNIZED : result;
    }

    public static final int DELETE_RETENTION_MS_FIELD_NUMBER = 3;
    private com.google.protobuf.Int64Value deleteRetentionMs_;
    /**
     * <pre>
     * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
     */
    public boolean hasDeleteRetentionMs() {
      return deleteRetentionMs_ != null;
    }
    /**
     * <pre>
     * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
     */
    public com.google.protobuf.Int64Value getDeleteRetentionMs() {
      return deleteRetentionMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : deleteRetentionMs_;
    }
    /**
     * <pre>
     * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getDeleteRetentionMsOrBuilder() {
      return getDeleteRetentionMs();
    }

    public static final int FILE_DELETE_DELAY_MS_FIELD_NUMBER = 4;
    private com.google.protobuf.Int64Value fileDeleteDelayMs_;
    /**
     * <pre>
     * The time to wait before deleting a file from the filesystem.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
     */
    public boolean hasFileDeleteDelayMs() {
      return fileDeleteDelayMs_ != null;
    }
    /**
     * <pre>
     * The time to wait before deleting a file from the filesystem.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
     */
    public com.google.protobuf.Int64Value getFileDeleteDelayMs() {
      return fileDeleteDelayMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : fileDeleteDelayMs_;
    }
    /**
     * <pre>
     * The time to wait before deleting a file from the filesystem.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getFileDeleteDelayMsOrBuilder() {
      return getFileDeleteDelayMs();
    }

    public static final int FLUSH_MESSAGES_FIELD_NUMBER = 5;
    private com.google.protobuf.Int64Value flushMessages_;
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_messages] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
     */
    public boolean hasFlushMessages() {
      return flushMessages_ != null;
    }
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_messages] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
     */
    public com.google.protobuf.Int64Value getFlushMessages() {
      return flushMessages_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : flushMessages_;
    }
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_messages] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getFlushMessagesOrBuilder() {
      return getFlushMessages();
    }

    public static final int FLUSH_MS_FIELD_NUMBER = 6;
    private com.google.protobuf.Int64Value flushMs_;
    /**
     * <pre>
     * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_ms] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
     */
    public boolean hasFlushMs() {
      return flushMs_ != null;
    }
    /**
     * <pre>
     * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_ms] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
     */
    public com.google.protobuf.Int64Value getFlushMs() {
      return flushMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : flushMs_;
    }
    /**
     * <pre>
     * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_ms] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getFlushMsOrBuilder() {
      return getFlushMs();
    }

    public static final int MIN_COMPACTION_LAG_MS_FIELD_NUMBER = 7;
    private com.google.protobuf.Int64Value minCompactionLagMs_;
    /**
     * <pre>
     * The minimum time in milliseconds a message will remain uncompacted in the log.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
     */
    public boolean hasMinCompactionLagMs() {
      return minCompactionLagMs_ != null;
    }
    /**
     * <pre>
     * The minimum time in milliseconds a message will remain uncompacted in the log.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
     */
    public com.google.protobuf.Int64Value getMinCompactionLagMs() {
      return minCompactionLagMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : minCompactionLagMs_;
    }
    /**
     * <pre>
     * The minimum time in milliseconds a message will remain uncompacted in the log.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getMinCompactionLagMsOrBuilder() {
      return getMinCompactionLagMs();
    }

    public static final int RETENTION_BYTES_FIELD_NUMBER = 8;
    private com.google.protobuf.Int64Value retentionBytes_;
    /**
     * <pre>
     * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
     * It is helpful if you need to control the size of log due to limited disk space.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_bytes] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
     */
    public boolean hasRetentionBytes() {
      return retentionBytes_ != null;
    }
    /**
     * <pre>
     * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
     * It is helpful if you need to control the size of log due to limited disk space.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_bytes] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
     */
    public com.google.protobuf.Int64Value getRetentionBytes() {
      return retentionBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : retentionBytes_;
    }
    /**
     * <pre>
     * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
     * It is helpful if you need to control the size of log due to limited disk space.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_bytes] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getRetentionBytesOrBuilder() {
      return getRetentionBytes();
    }

    public static final int RETENTION_MS_FIELD_NUMBER = 9;
    private com.google.protobuf.Int64Value retentionMs_;
    /**
     * <pre>
     * The number of milliseconds to keep a log segment's file before deleting it.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_ms] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
     */
    public boolean hasRetentionMs() {
      return retentionMs_ != null;
    }
    /**
     * <pre>
     * The number of milliseconds to keep a log segment's file before deleting it.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_ms] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
     */
    public com.google.protobuf.Int64Value getRetentionMs() {
      return retentionMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : retentionMs_;
    }
    /**
     * <pre>
     * The number of milliseconds to keep a log segment's file before deleting it.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_ms] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getRetentionMsOrBuilder() {
      return getRetentionMs();
    }

    public static final int MAX_MESSAGE_BYTES_FIELD_NUMBER = 10;
    private com.google.protobuf.Int64Value maxMessageBytes_;
    /**
     * <pre>
     * The largest record batch size allowed in topic.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
     */
    public boolean hasMaxMessageBytes() {
      return maxMessageBytes_ != null;
    }
    /**
     * <pre>
     * The largest record batch size allowed in topic.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
     */
    public com.google.protobuf.Int64Value getMaxMessageBytes() {
      return maxMessageBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : maxMessageBytes_;
    }
    /**
     * <pre>
     * The largest record batch size allowed in topic.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getMaxMessageBytesOrBuilder() {
      return getMaxMessageBytes();
    }

    public static final int MIN_INSYNC_REPLICAS_FIELD_NUMBER = 11;
    private com.google.protobuf.Int64Value minInsyncReplicas_;
    /**
     * <pre>
     * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
     * to be considered successful (when a producer sets acks to "all").
     * </pre>
     *
     * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
     */
    public boolean hasMinInsyncReplicas() {
      return minInsyncReplicas_ != null;
    }
    /**
     * <pre>
     * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
     * to be considered successful (when a producer sets acks to "all").
     * </pre>
     *
     * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
     */
    public com.google.protobuf.Int64Value getMinInsyncReplicas() {
      return minInsyncReplicas_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : minInsyncReplicas_;
    }
    /**
     * <pre>
     * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
     * to be considered successful (when a producer sets acks to "all").
     * </pre>
     *
     * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getMinInsyncReplicasOrBuilder() {
      return getMinInsyncReplicas();
    }

    public static final int SEGMENT_BYTES_FIELD_NUMBER = 12;
    private com.google.protobuf.Int64Value segmentBytes_;
    /**
     * <pre>
     * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
     * at a time so a larger segment size means fewer files but less granular control over retention.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_segment_bytes] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
     */
    public boolean hasSegmentBytes() {
      return segmentBytes_ != null;
    }
    /**
     * <pre>
     * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
     * at a time so a larger segment size means fewer files but less granular control over retention.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_segment_bytes] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
     */
    public com.google.protobuf.Int64Value getSegmentBytes() {
      return segmentBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : segmentBytes_;
    }
    /**
     * <pre>
     * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
     * at a time so a larger segment size means fewer files but less granular control over retention.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_segment_bytes] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getSegmentBytesOrBuilder() {
      return getSegmentBytes();
    }

    public static final int PREALLOCATE_FIELD_NUMBER = 13;
    private com.google.protobuf.BoolValue preallocate_;
    /**
     * <pre>
     * True if we should preallocate the file on disk when creating a new log segment.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_preallocate] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue preallocate = 13;</code>
     */
    public boolean hasPreallocate() {
      return preallocate_ != null;
    }
    /**
     * <pre>
     * True if we should preallocate the file on disk when creating a new log segment.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_preallocate] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue preallocate = 13;</code>
     */
    public com.google.protobuf.BoolValue getPreallocate() {
      return preallocate_ == null ? com.google.protobuf.BoolValue.getDefaultInstance() : preallocate_;
    }
    /**
     * <pre>
     * True if we should preallocate the file on disk when creating a new log segment.
     * This setting overrides the cluster-level [KafkaConfig2_1.log_preallocate] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue preallocate = 13;</code>
     */
    public com.google.protobuf.BoolValueOrBuilder getPreallocateOrBuilder() {
      return getPreallocate();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (cleanupPolicy_ != yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.CleanupPolicy.CLEANUP_POLICY_UNSPECIFIED.getNumber()) {
        output.writeEnum(1, cleanupPolicy_);
      }
      if (compressionType_ != yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.COMPRESSION_TYPE_UNSPECIFIED.getNumber()) {
        output.writeEnum(2, compressionType_);
      }
      if (deleteRetentionMs_ != null) {
        output.writeMessage(3, getDeleteRetentionMs());
      }
      if (fileDeleteDelayMs_ != null) {
        output.writeMessage(4, getFileDeleteDelayMs());
      }
      if (flushMessages_ != null) {
        output.writeMessage(5, getFlushMessages());
      }
      if (flushMs_ != null) {
        output.writeMessage(6, getFlushMs());
      }
      if (minCompactionLagMs_ != null) {
        output.writeMessage(7, getMinCompactionLagMs());
      }
      if (retentionBytes_ != null) {
        output.writeMessage(8, getRetentionBytes());
      }
      if (retentionMs_ != null) {
        output.writeMessage(9, getRetentionMs());
      }
      if (maxMessageBytes_ != null) {
        output.writeMessage(10, getMaxMessageBytes());
      }
      if (minInsyncReplicas_ != null) {
        output.writeMessage(11, getMinInsyncReplicas());
      }
      if (segmentBytes_ != null) {
        output.writeMessage(12, getSegmentBytes());
      }
      if (preallocate_ != null) {
        output.writeMessage(13, getPreallocate());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (cleanupPolicy_ != yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.CleanupPolicy.CLEANUP_POLICY_UNSPECIFIED.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, cleanupPolicy_);
      }
      if (compressionType_ != yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.COMPRESSION_TYPE_UNSPECIFIED.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, compressionType_);
      }
      if (deleteRetentionMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getDeleteRetentionMs());
      }
      if (fileDeleteDelayMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getFileDeleteDelayMs());
      }
      if (flushMessages_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getFlushMessages());
      }
      if (flushMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, getFlushMs());
      }
      if (minCompactionLagMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, getMinCompactionLagMs());
      }
      if (retentionBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(8, getRetentionBytes());
      }
      if (retentionMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(9, getRetentionMs());
      }
      if (maxMessageBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(10, getMaxMessageBytes());
      }
      if (minInsyncReplicas_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(11, getMinInsyncReplicas());
      }
      if (segmentBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(12, getSegmentBytes());
      }
      if (preallocate_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(13, getPreallocate());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1)) {
        return super.equals(obj);
      }
      yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 other = (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1) obj;

      boolean result = true;
      result = result && cleanupPolicy_ == other.cleanupPolicy_;
      result = result && compressionType_ == other.compressionType_;
      result = result && (hasDeleteRetentionMs() == other.hasDeleteRetentionMs());
      if (hasDeleteRetentionMs()) {
        result = result && getDeleteRetentionMs()
            .equals(other.getDeleteRetentionMs());
      }
      result = result && (hasFileDeleteDelayMs() == other.hasFileDeleteDelayMs());
      if (hasFileDeleteDelayMs()) {
        result = result && getFileDeleteDelayMs()
            .equals(other.getFileDeleteDelayMs());
      }
      result = result && (hasFlushMessages() == other.hasFlushMessages());
      if (hasFlushMessages()) {
        result = result && getFlushMessages()
            .equals(other.getFlushMessages());
      }
      result = result && (hasFlushMs() == other.hasFlushMs());
      if (hasFlushMs()) {
        result = result && getFlushMs()
            .equals(other.getFlushMs());
      }
      result = result && (hasMinCompactionLagMs() == other.hasMinCompactionLagMs());
      if (hasMinCompactionLagMs()) {
        result = result && getMinCompactionLagMs()
            .equals(other.getMinCompactionLagMs());
      }
      result = result && (hasRetentionBytes() == other.hasRetentionBytes());
      if (hasRetentionBytes()) {
        result = result && getRetentionBytes()
            .equals(other.getRetentionBytes());
      }
      result = result && (hasRetentionMs() == other.hasRetentionMs());
      if (hasRetentionMs()) {
        result = result && getRetentionMs()
            .equals(other.getRetentionMs());
      }
      result = result && (hasMaxMessageBytes() == other.hasMaxMessageBytes());
      if (hasMaxMessageBytes()) {
        result = result && getMaxMessageBytes()
            .equals(other.getMaxMessageBytes());
      }
      result = result && (hasMinInsyncReplicas() == other.hasMinInsyncReplicas());
      if (hasMinInsyncReplicas()) {
        result = result && getMinInsyncReplicas()
            .equals(other.getMinInsyncReplicas());
      }
      result = result && (hasSegmentBytes() == other.hasSegmentBytes());
      if (hasSegmentBytes()) {
        result = result && getSegmentBytes()
            .equals(other.getSegmentBytes());
      }
      result = result && (hasPreallocate() == other.hasPreallocate());
      if (hasPreallocate()) {
        result = result && getPreallocate()
            .equals(other.getPreallocate());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + CLEANUP_POLICY_FIELD_NUMBER;
      hash = (53 * hash) + cleanupPolicy_;
      hash = (37 * hash) + COMPRESSION_TYPE_FIELD_NUMBER;
      hash = (53 * hash) + compressionType_;
      if (hasDeleteRetentionMs()) {
        hash = (37 * hash) + DELETE_RETENTION_MS_FIELD_NUMBER;
        hash = (53 * hash) + getDeleteRetentionMs().hashCode();
      }
      if (hasFileDeleteDelayMs()) {
        hash = (37 * hash) + FILE_DELETE_DELAY_MS_FIELD_NUMBER;
        hash = (53 * hash) + getFileDeleteDelayMs().hashCode();
      }
      if (hasFlushMessages()) {
        hash = (37 * hash) + FLUSH_MESSAGES_FIELD_NUMBER;
        hash = (53 * hash) + getFlushMessages().hashCode();
      }
      if (hasFlushMs()) {
        hash = (37 * hash) + FLUSH_MS_FIELD_NUMBER;
        hash = (53 * hash) + getFlushMs().hashCode();
      }
      if (hasMinCompactionLagMs()) {
        hash = (37 * hash) + MIN_COMPACTION_LAG_MS_FIELD_NUMBER;
        hash = (53 * hash) + getMinCompactionLagMs().hashCode();
      }
      if (hasRetentionBytes()) {
        hash = (37 * hash) + RETENTION_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getRetentionBytes().hashCode();
      }
      if (hasRetentionMs()) {
        hash = (37 * hash) + RETENTION_MS_FIELD_NUMBER;
        hash = (53 * hash) + getRetentionMs().hashCode();
      }
      if (hasMaxMessageBytes()) {
        hash = (37 * hash) + MAX_MESSAGE_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getMaxMessageBytes().hashCode();
      }
      if (hasMinInsyncReplicas()) {
        hash = (37 * hash) + MIN_INSYNC_REPLICAS_FIELD_NUMBER;
        hash = (53 * hash) + getMinInsyncReplicas().hashCode();
      }
      if (hasSegmentBytes()) {
        hash = (37 * hash) + SEGMENT_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getSegmentBytes().hashCode();
      }
      if (hasPreallocate()) {
        hash = (37 * hash) + PREALLOCATE_FIELD_NUMBER;
        hash = (53 * hash) + getPreallocate().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * A topic settings for 2.1.
     * </pre>
     *
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.TopicConfig2_1}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.TopicConfig2_1)
        yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1OrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_TopicConfig2_1_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_TopicConfig2_1_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.class, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.Builder.class);
      }

      // Construct using yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        cleanupPolicy_ = 0;

        compressionType_ = 0;

        if (deleteRetentionMsBuilder_ == null) {
          deleteRetentionMs_ = null;
        } else {
          deleteRetentionMs_ = null;
          deleteRetentionMsBuilder_ = null;
        }
        if (fileDeleteDelayMsBuilder_ == null) {
          fileDeleteDelayMs_ = null;
        } else {
          fileDeleteDelayMs_ = null;
          fileDeleteDelayMsBuilder_ = null;
        }
        if (flushMessagesBuilder_ == null) {
          flushMessages_ = null;
        } else {
          flushMessages_ = null;
          flushMessagesBuilder_ = null;
        }
        if (flushMsBuilder_ == null) {
          flushMs_ = null;
        } else {
          flushMs_ = null;
          flushMsBuilder_ = null;
        }
        if (minCompactionLagMsBuilder_ == null) {
          minCompactionLagMs_ = null;
        } else {
          minCompactionLagMs_ = null;
          minCompactionLagMsBuilder_ = null;
        }
        if (retentionBytesBuilder_ == null) {
          retentionBytes_ = null;
        } else {
          retentionBytes_ = null;
          retentionBytesBuilder_ = null;
        }
        if (retentionMsBuilder_ == null) {
          retentionMs_ = null;
        } else {
          retentionMs_ = null;
          retentionMsBuilder_ = null;
        }
        if (maxMessageBytesBuilder_ == null) {
          maxMessageBytes_ = null;
        } else {
          maxMessageBytes_ = null;
          maxMessageBytesBuilder_ = null;
        }
        if (minInsyncReplicasBuilder_ == null) {
          minInsyncReplicas_ = null;
        } else {
          minInsyncReplicas_ = null;
          minInsyncReplicasBuilder_ = null;
        }
        if (segmentBytesBuilder_ == null) {
          segmentBytes_ = null;
        } else {
          segmentBytes_ = null;
          segmentBytesBuilder_ = null;
        }
        if (preallocateBuilder_ == null) {
          preallocate_ = null;
        } else {
          preallocate_ = null;
          preallocateBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_TopicConfig2_1_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 getDefaultInstanceForType() {
        return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 build() {
        yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 buildPartial() {
        yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 result = new yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1(this);
        result.cleanupPolicy_ = cleanupPolicy_;
        result.compressionType_ = compressionType_;
        if (deleteRetentionMsBuilder_ == null) {
          result.deleteRetentionMs_ = deleteRetentionMs_;
        } else {
          result.deleteRetentionMs_ = deleteRetentionMsBuilder_.build();
        }
        if (fileDeleteDelayMsBuilder_ == null) {
          result.fileDeleteDelayMs_ = fileDeleteDelayMs_;
        } else {
          result.fileDeleteDelayMs_ = fileDeleteDelayMsBuilder_.build();
        }
        if (flushMessagesBuilder_ == null) {
          result.flushMessages_ = flushMessages_;
        } else {
          result.flushMessages_ = flushMessagesBuilder_.build();
        }
        if (flushMsBuilder_ == null) {
          result.flushMs_ = flushMs_;
        } else {
          result.flushMs_ = flushMsBuilder_.build();
        }
        if (minCompactionLagMsBuilder_ == null) {
          result.minCompactionLagMs_ = minCompactionLagMs_;
        } else {
          result.minCompactionLagMs_ = minCompactionLagMsBuilder_.build();
        }
        if (retentionBytesBuilder_ == null) {
          result.retentionBytes_ = retentionBytes_;
        } else {
          result.retentionBytes_ = retentionBytesBuilder_.build();
        }
        if (retentionMsBuilder_ == null) {
          result.retentionMs_ = retentionMs_;
        } else {
          result.retentionMs_ = retentionMsBuilder_.build();
        }
        if (maxMessageBytesBuilder_ == null) {
          result.maxMessageBytes_ = maxMessageBytes_;
        } else {
          result.maxMessageBytes_ = maxMessageBytesBuilder_.build();
        }
        if (minInsyncReplicasBuilder_ == null) {
          result.minInsyncReplicas_ = minInsyncReplicas_;
        } else {
          result.minInsyncReplicas_ = minInsyncReplicasBuilder_.build();
        }
        if (segmentBytesBuilder_ == null) {
          result.segmentBytes_ = segmentBytes_;
        } else {
          result.segmentBytes_ = segmentBytesBuilder_.build();
        }
        if (preallocateBuilder_ == null) {
          result.preallocate_ = preallocate_;
        } else {
          result.preallocate_ = preallocateBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1) {
          return mergeFrom((yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 other) {
        if (other == yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.getDefaultInstance()) return this;
        if (other.cleanupPolicy_ != 0) {
          setCleanupPolicyValue(other.getCleanupPolicyValue());
        }
        if (other.compressionType_ != 0) {
          setCompressionTypeValue(other.getCompressionTypeValue());
        }
        if (other.hasDeleteRetentionMs()) {
          mergeDeleteRetentionMs(other.getDeleteRetentionMs());
        }
        if (other.hasFileDeleteDelayMs()) {
          mergeFileDeleteDelayMs(other.getFileDeleteDelayMs());
        }
        if (other.hasFlushMessages()) {
          mergeFlushMessages(other.getFlushMessages());
        }
        if (other.hasFlushMs()) {
          mergeFlushMs(other.getFlushMs());
        }
        if (other.hasMinCompactionLagMs()) {
          mergeMinCompactionLagMs(other.getMinCompactionLagMs());
        }
        if (other.hasRetentionBytes()) {
          mergeRetentionBytes(other.getRetentionBytes());
        }
        if (other.hasRetentionMs()) {
          mergeRetentionMs(other.getRetentionMs());
        }
        if (other.hasMaxMessageBytes()) {
          mergeMaxMessageBytes(other.getMaxMessageBytes());
        }
        if (other.hasMinInsyncReplicas()) {
          mergeMinInsyncReplicas(other.getMinInsyncReplicas());
        }
        if (other.hasSegmentBytes()) {
          mergeSegmentBytes(other.getSegmentBytes());
        }
        if (other.hasPreallocate()) {
          mergePreallocate(other.getPreallocate());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private int cleanupPolicy_ = 0;
      /**
       * <pre>
       * Retention policy to use on old log messages.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1.CleanupPolicy cleanup_policy = 1;</code>
       */
      public int getCleanupPolicyValue() {
        return cleanupPolicy_;
      }
      /**
       * <pre>
       * Retention policy to use on old log messages.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1.CleanupPolicy cleanup_policy = 1;</code>
       */
      public Builder setCleanupPolicyValue(int value) {
        cleanupPolicy_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Retention policy to use on old log messages.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1.CleanupPolicy cleanup_policy = 1;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.CleanupPolicy getCleanupPolicy() {
        @SuppressWarnings("deprecation")
        yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.CleanupPolicy result = yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.CleanupPolicy.valueOf(cleanupPolicy_);
        return result == null ? yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.CleanupPolicy.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       * Retention policy to use on old log messages.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1.CleanupPolicy cleanup_policy = 1;</code>
       */
      public Builder setCleanupPolicy(yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1.CleanupPolicy value) {
        if (value == null) {
          throw new NullPointerException();
        }
        
        cleanupPolicy_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Retention policy to use on old log messages.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_1.CleanupPolicy cleanup_policy = 1;</code>
       */
      public Builder clearCleanupPolicy() {
        
        cleanupPolicy_ = 0;
        onChanged();
        return this;
      }

      private int compressionType_ = 0;
      /**
       * <pre>
       * The compression type for a given topic.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 2;</code>
       */
      public int getCompressionTypeValue() {
        return compressionType_;
      }
      /**
       * <pre>
       * The compression type for a given topic.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 2;</code>
       */
      public Builder setCompressionTypeValue(int value) {
        compressionType_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The compression type for a given topic.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 2;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.Common.CompressionType getCompressionType() {
        @SuppressWarnings("deprecation")
        yandex.cloud.api.mdb.kafka.v1.Common.CompressionType result = yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.valueOf(compressionType_);
        return result == null ? yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       * The compression type for a given topic.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 2;</code>
       */
      public Builder setCompressionType(yandex.cloud.api.mdb.kafka.v1.Common.CompressionType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        
        compressionType_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The compression type for a given topic.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 2;</code>
       */
      public Builder clearCompressionType() {
        
        compressionType_ = 0;
        onChanged();
        return this;
      }

      private com.google.protobuf.Int64Value deleteRetentionMs_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> deleteRetentionMsBuilder_;
      /**
       * <pre>
       * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
       */
      public boolean hasDeleteRetentionMs() {
        return deleteRetentionMsBuilder_ != null || deleteRetentionMs_ != null;
      }
      /**
       * <pre>
       * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
       */
      public com.google.protobuf.Int64Value getDeleteRetentionMs() {
        if (deleteRetentionMsBuilder_ == null) {
          return deleteRetentionMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : deleteRetentionMs_;
        } else {
          return deleteRetentionMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
       */
      public Builder setDeleteRetentionMs(com.google.protobuf.Int64Value value) {
        if (deleteRetentionMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          deleteRetentionMs_ = value;
          onChanged();
        } else {
          deleteRetentionMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
       */
      public Builder setDeleteRetentionMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (deleteRetentionMsBuilder_ == null) {
          deleteRetentionMs_ = builderForValue.build();
          onChanged();
        } else {
          deleteRetentionMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
       */
      public Builder mergeDeleteRetentionMs(com.google.protobuf.Int64Value value) {
        if (deleteRetentionMsBuilder_ == null) {
          if (deleteRetentionMs_ != null) {
            deleteRetentionMs_ =
              com.google.protobuf.Int64Value.newBuilder(deleteRetentionMs_).mergeFrom(value).buildPartial();
          } else {
            deleteRetentionMs_ = value;
          }
          onChanged();
        } else {
          deleteRetentionMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
       */
      public Builder clearDeleteRetentionMs() {
        if (deleteRetentionMsBuilder_ == null) {
          deleteRetentionMs_ = null;
          onChanged();
        } else {
          deleteRetentionMs_ = null;
          deleteRetentionMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
       */
      public com.google.protobuf.Int64Value.Builder getDeleteRetentionMsBuilder() {
        
        onChanged();
        return getDeleteRetentionMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getDeleteRetentionMsOrBuilder() {
        if (deleteRetentionMsBuilder_ != null) {
          return deleteRetentionMsBuilder_.getMessageOrBuilder();
        } else {
          return deleteRetentionMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : deleteRetentionMs_;
        }
      }
      /**
       * <pre>
       * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getDeleteRetentionMsFieldBuilder() {
        if (deleteRetentionMsBuilder_ == null) {
          deleteRetentionMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getDeleteRetentionMs(),
                  getParentForChildren(),
                  isClean());
          deleteRetentionMs_ = null;
        }
        return deleteRetentionMsBuilder_;
      }

      private com.google.protobuf.Int64Value fileDeleteDelayMs_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> fileDeleteDelayMsBuilder_;
      /**
       * <pre>
       * The time to wait before deleting a file from the filesystem.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
       */
      public boolean hasFileDeleteDelayMs() {
        return fileDeleteDelayMsBuilder_ != null || fileDeleteDelayMs_ != null;
      }
      /**
       * <pre>
       * The time to wait before deleting a file from the filesystem.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
       */
      public com.google.protobuf.Int64Value getFileDeleteDelayMs() {
        if (fileDeleteDelayMsBuilder_ == null) {
          return fileDeleteDelayMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : fileDeleteDelayMs_;
        } else {
          return fileDeleteDelayMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The time to wait before deleting a file from the filesystem.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
       */
      public Builder setFileDeleteDelayMs(com.google.protobuf.Int64Value value) {
        if (fileDeleteDelayMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          fileDeleteDelayMs_ = value;
          onChanged();
        } else {
          fileDeleteDelayMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The time to wait before deleting a file from the filesystem.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
       */
      public Builder setFileDeleteDelayMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (fileDeleteDelayMsBuilder_ == null) {
          fileDeleteDelayMs_ = builderForValue.build();
          onChanged();
        } else {
          fileDeleteDelayMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The time to wait before deleting a file from the filesystem.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
       */
      public Builder mergeFileDeleteDelayMs(com.google.protobuf.Int64Value value) {
        if (fileDeleteDelayMsBuilder_ == null) {
          if (fileDeleteDelayMs_ != null) {
            fileDeleteDelayMs_ =
              com.google.protobuf.Int64Value.newBuilder(fileDeleteDelayMs_).mergeFrom(value).buildPartial();
          } else {
            fileDeleteDelayMs_ = value;
          }
          onChanged();
        } else {
          fileDeleteDelayMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The time to wait before deleting a file from the filesystem.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
       */
      public Builder clearFileDeleteDelayMs() {
        if (fileDeleteDelayMsBuilder_ == null) {
          fileDeleteDelayMs_ = null;
          onChanged();
        } else {
          fileDeleteDelayMs_ = null;
          fileDeleteDelayMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The time to wait before deleting a file from the filesystem.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
       */
      public com.google.protobuf.Int64Value.Builder getFileDeleteDelayMsBuilder() {
        
        onChanged();
        return getFileDeleteDelayMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The time to wait before deleting a file from the filesystem.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getFileDeleteDelayMsOrBuilder() {
        if (fileDeleteDelayMsBuilder_ != null) {
          return fileDeleteDelayMsBuilder_.getMessageOrBuilder();
        } else {
          return fileDeleteDelayMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : fileDeleteDelayMs_;
        }
      }
      /**
       * <pre>
       * The time to wait before deleting a file from the filesystem.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getFileDeleteDelayMsFieldBuilder() {
        if (fileDeleteDelayMsBuilder_ == null) {
          fileDeleteDelayMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getFileDeleteDelayMs(),
                  getParentForChildren(),
                  isClean());
          fileDeleteDelayMs_ = null;
        }
        return fileDeleteDelayMsBuilder_;
      }

      private com.google.protobuf.Int64Value flushMessages_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> flushMessagesBuilder_;
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_messages] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
       */
      public boolean hasFlushMessages() {
        return flushMessagesBuilder_ != null || flushMessages_ != null;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_messages] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
       */
      public com.google.protobuf.Int64Value getFlushMessages() {
        if (flushMessagesBuilder_ == null) {
          return flushMessages_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : flushMessages_;
        } else {
          return flushMessagesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_messages] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
       */
      public Builder setFlushMessages(com.google.protobuf.Int64Value value) {
        if (flushMessagesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          flushMessages_ = value;
          onChanged();
        } else {
          flushMessagesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_messages] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
       */
      public Builder setFlushMessages(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (flushMessagesBuilder_ == null) {
          flushMessages_ = builderForValue.build();
          onChanged();
        } else {
          flushMessagesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_messages] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
       */
      public Builder mergeFlushMessages(com.google.protobuf.Int64Value value) {
        if (flushMessagesBuilder_ == null) {
          if (flushMessages_ != null) {
            flushMessages_ =
              com.google.protobuf.Int64Value.newBuilder(flushMessages_).mergeFrom(value).buildPartial();
          } else {
            flushMessages_ = value;
          }
          onChanged();
        } else {
          flushMessagesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_messages] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
       */
      public Builder clearFlushMessages() {
        if (flushMessagesBuilder_ == null) {
          flushMessages_ = null;
          onChanged();
        } else {
          flushMessages_ = null;
          flushMessagesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_messages] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
       */
      public com.google.protobuf.Int64Value.Builder getFlushMessagesBuilder() {
        
        onChanged();
        return getFlushMessagesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_messages] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getFlushMessagesOrBuilder() {
        if (flushMessagesBuilder_ != null) {
          return flushMessagesBuilder_.getMessageOrBuilder();
        } else {
          return flushMessages_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : flushMessages_;
        }
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_messages] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getFlushMessagesFieldBuilder() {
        if (flushMessagesBuilder_ == null) {
          flushMessagesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getFlushMessages(),
                  getParentForChildren(),
                  isClean());
          flushMessages_ = null;
        }
        return flushMessagesBuilder_;
      }

      private com.google.protobuf.Int64Value flushMs_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> flushMsBuilder_;
      /**
       * <pre>
       * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
       */
      public boolean hasFlushMs() {
        return flushMsBuilder_ != null || flushMs_ != null;
      }
      /**
       * <pre>
       * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
       */
      public com.google.protobuf.Int64Value getFlushMs() {
        if (flushMsBuilder_ == null) {
          return flushMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : flushMs_;
        } else {
          return flushMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
       */
      public Builder setFlushMs(com.google.protobuf.Int64Value value) {
        if (flushMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          flushMs_ = value;
          onChanged();
        } else {
          flushMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
       */
      public Builder setFlushMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (flushMsBuilder_ == null) {
          flushMs_ = builderForValue.build();
          onChanged();
        } else {
          flushMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
       */
      public Builder mergeFlushMs(com.google.protobuf.Int64Value value) {
        if (flushMsBuilder_ == null) {
          if (flushMs_ != null) {
            flushMs_ =
              com.google.protobuf.Int64Value.newBuilder(flushMs_).mergeFrom(value).buildPartial();
          } else {
            flushMs_ = value;
          }
          onChanged();
        } else {
          flushMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
       */
      public Builder clearFlushMs() {
        if (flushMsBuilder_ == null) {
          flushMs_ = null;
          onChanged();
        } else {
          flushMs_ = null;
          flushMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
       */
      public com.google.protobuf.Int64Value.Builder getFlushMsBuilder() {
        
        onChanged();
        return getFlushMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getFlushMsOrBuilder() {
        if (flushMsBuilder_ != null) {
          return flushMsBuilder_.getMessageOrBuilder();
        } else {
          return flushMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : flushMs_;
        }
      }
      /**
       * <pre>
       * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_flush_interval_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getFlushMsFieldBuilder() {
        if (flushMsBuilder_ == null) {
          flushMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getFlushMs(),
                  getParentForChildren(),
                  isClean());
          flushMs_ = null;
        }
        return flushMsBuilder_;
      }

      private com.google.protobuf.Int64Value minCompactionLagMs_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> minCompactionLagMsBuilder_;
      /**
       * <pre>
       * The minimum time in milliseconds a message will remain uncompacted in the log.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
       */
      public boolean hasMinCompactionLagMs() {
        return minCompactionLagMsBuilder_ != null || minCompactionLagMs_ != null;
      }
      /**
       * <pre>
       * The minimum time in milliseconds a message will remain uncompacted in the log.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
       */
      public com.google.protobuf.Int64Value getMinCompactionLagMs() {
        if (minCompactionLagMsBuilder_ == null) {
          return minCompactionLagMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : minCompactionLagMs_;
        } else {
          return minCompactionLagMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The minimum time in milliseconds a message will remain uncompacted in the log.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
       */
      public Builder setMinCompactionLagMs(com.google.protobuf.Int64Value value) {
        if (minCompactionLagMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          minCompactionLagMs_ = value;
          onChanged();
        } else {
          minCompactionLagMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The minimum time in milliseconds a message will remain uncompacted in the log.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
       */
      public Builder setMinCompactionLagMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (minCompactionLagMsBuilder_ == null) {
          minCompactionLagMs_ = builderForValue.build();
          onChanged();
        } else {
          minCompactionLagMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The minimum time in milliseconds a message will remain uncompacted in the log.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
       */
      public Builder mergeMinCompactionLagMs(com.google.protobuf.Int64Value value) {
        if (minCompactionLagMsBuilder_ == null) {
          if (minCompactionLagMs_ != null) {
            minCompactionLagMs_ =
              com.google.protobuf.Int64Value.newBuilder(minCompactionLagMs_).mergeFrom(value).buildPartial();
          } else {
            minCompactionLagMs_ = value;
          }
          onChanged();
        } else {
          minCompactionLagMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The minimum time in milliseconds a message will remain uncompacted in the log.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
       */
      public Builder clearMinCompactionLagMs() {
        if (minCompactionLagMsBuilder_ == null) {
          minCompactionLagMs_ = null;
          onChanged();
        } else {
          minCompactionLagMs_ = null;
          minCompactionLagMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The minimum time in milliseconds a message will remain uncompacted in the log.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
       */
      public com.google.protobuf.Int64Value.Builder getMinCompactionLagMsBuilder() {
        
        onChanged();
        return getMinCompactionLagMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The minimum time in milliseconds a message will remain uncompacted in the log.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getMinCompactionLagMsOrBuilder() {
        if (minCompactionLagMsBuilder_ != null) {
          return minCompactionLagMsBuilder_.getMessageOrBuilder();
        } else {
          return minCompactionLagMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : minCompactionLagMs_;
        }
      }
      /**
       * <pre>
       * The minimum time in milliseconds a message will remain uncompacted in the log.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getMinCompactionLagMsFieldBuilder() {
        if (minCompactionLagMsBuilder_ == null) {
          minCompactionLagMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getMinCompactionLagMs(),
                  getParentForChildren(),
                  isClean());
          minCompactionLagMs_ = null;
        }
        return minCompactionLagMsBuilder_;
      }

      private com.google.protobuf.Int64Value retentionBytes_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> retentionBytesBuilder_;
      /**
       * <pre>
       * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
       * It is helpful if you need to control the size of log due to limited disk space.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
       */
      public boolean hasRetentionBytes() {
        return retentionBytesBuilder_ != null || retentionBytes_ != null;
      }
      /**
       * <pre>
       * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
       * It is helpful if you need to control the size of log due to limited disk space.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
       */
      public com.google.protobuf.Int64Value getRetentionBytes() {
        if (retentionBytesBuilder_ == null) {
          return retentionBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : retentionBytes_;
        } else {
          return retentionBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
       * It is helpful if you need to control the size of log due to limited disk space.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
       */
      public Builder setRetentionBytes(com.google.protobuf.Int64Value value) {
        if (retentionBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          retentionBytes_ = value;
          onChanged();
        } else {
          retentionBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
       * It is helpful if you need to control the size of log due to limited disk space.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
       */
      public Builder setRetentionBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (retentionBytesBuilder_ == null) {
          retentionBytes_ = builderForValue.build();
          onChanged();
        } else {
          retentionBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
       * It is helpful if you need to control the size of log due to limited disk space.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
       */
      public Builder mergeRetentionBytes(com.google.protobuf.Int64Value value) {
        if (retentionBytesBuilder_ == null) {
          if (retentionBytes_ != null) {
            retentionBytes_ =
              com.google.protobuf.Int64Value.newBuilder(retentionBytes_).mergeFrom(value).buildPartial();
          } else {
            retentionBytes_ = value;
          }
          onChanged();
        } else {
          retentionBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
       * It is helpful if you need to control the size of log due to limited disk space.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
       */
      public Builder clearRetentionBytes() {
        if (retentionBytesBuilder_ == null) {
          retentionBytes_ = null;
          onChanged();
        } else {
          retentionBytes_ = null;
          retentionBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
       * It is helpful if you need to control the size of log due to limited disk space.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
       */
      public com.google.protobuf.Int64Value.Builder getRetentionBytesBuilder() {
        
        onChanged();
        return getRetentionBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
       * It is helpful if you need to control the size of log due to limited disk space.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getRetentionBytesOrBuilder() {
        if (retentionBytesBuilder_ != null) {
          return retentionBytesBuilder_.getMessageOrBuilder();
        } else {
          return retentionBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : retentionBytes_;
        }
      }
      /**
       * <pre>
       * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
       * It is helpful if you need to control the size of log due to limited disk space.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getRetentionBytesFieldBuilder() {
        if (retentionBytesBuilder_ == null) {
          retentionBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getRetentionBytes(),
                  getParentForChildren(),
                  isClean());
          retentionBytes_ = null;
        }
        return retentionBytesBuilder_;
      }

      private com.google.protobuf.Int64Value retentionMs_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> retentionMsBuilder_;
      /**
       * <pre>
       * The number of milliseconds to keep a log segment's file before deleting it.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
       */
      public boolean hasRetentionMs() {
        return retentionMsBuilder_ != null || retentionMs_ != null;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment's file before deleting it.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
       */
      public com.google.protobuf.Int64Value getRetentionMs() {
        if (retentionMsBuilder_ == null) {
          return retentionMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : retentionMs_;
        } else {
          return retentionMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment's file before deleting it.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
       */
      public Builder setRetentionMs(com.google.protobuf.Int64Value value) {
        if (retentionMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          retentionMs_ = value;
          onChanged();
        } else {
          retentionMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment's file before deleting it.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
       */
      public Builder setRetentionMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (retentionMsBuilder_ == null) {
          retentionMs_ = builderForValue.build();
          onChanged();
        } else {
          retentionMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment's file before deleting it.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
       */
      public Builder mergeRetentionMs(com.google.protobuf.Int64Value value) {
        if (retentionMsBuilder_ == null) {
          if (retentionMs_ != null) {
            retentionMs_ =
              com.google.protobuf.Int64Value.newBuilder(retentionMs_).mergeFrom(value).buildPartial();
          } else {
            retentionMs_ = value;
          }
          onChanged();
        } else {
          retentionMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment's file before deleting it.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
       */
      public Builder clearRetentionMs() {
        if (retentionMsBuilder_ == null) {
          retentionMs_ = null;
          onChanged();
        } else {
          retentionMs_ = null;
          retentionMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment's file before deleting it.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
       */
      public com.google.protobuf.Int64Value.Builder getRetentionMsBuilder() {
        
        onChanged();
        return getRetentionMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment's file before deleting it.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getRetentionMsOrBuilder() {
        if (retentionMsBuilder_ != null) {
          return retentionMsBuilder_.getMessageOrBuilder();
        } else {
          return retentionMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : retentionMs_;
        }
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment's file before deleting it.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_retention_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getRetentionMsFieldBuilder() {
        if (retentionMsBuilder_ == null) {
          retentionMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getRetentionMs(),
                  getParentForChildren(),
                  isClean());
          retentionMs_ = null;
        }
        return retentionMsBuilder_;
      }

      private com.google.protobuf.Int64Value maxMessageBytes_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> maxMessageBytesBuilder_;
      /**
       * <pre>
       * The largest record batch size allowed in topic.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
       */
      public boolean hasMaxMessageBytes() {
        return maxMessageBytesBuilder_ != null || maxMessageBytes_ != null;
      }
      /**
       * <pre>
       * The largest record batch size allowed in topic.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
       */
      public com.google.protobuf.Int64Value getMaxMessageBytes() {
        if (maxMessageBytesBuilder_ == null) {
          return maxMessageBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : maxMessageBytes_;
        } else {
          return maxMessageBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The largest record batch size allowed in topic.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
       */
      public Builder setMaxMessageBytes(com.google.protobuf.Int64Value value) {
        if (maxMessageBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          maxMessageBytes_ = value;
          onChanged();
        } else {
          maxMessageBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The largest record batch size allowed in topic.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
       */
      public Builder setMaxMessageBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (maxMessageBytesBuilder_ == null) {
          maxMessageBytes_ = builderForValue.build();
          onChanged();
        } else {
          maxMessageBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The largest record batch size allowed in topic.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
       */
      public Builder mergeMaxMessageBytes(com.google.protobuf.Int64Value value) {
        if (maxMessageBytesBuilder_ == null) {
          if (maxMessageBytes_ != null) {
            maxMessageBytes_ =
              com.google.protobuf.Int64Value.newBuilder(maxMessageBytes_).mergeFrom(value).buildPartial();
          } else {
            maxMessageBytes_ = value;
          }
          onChanged();
        } else {
          maxMessageBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The largest record batch size allowed in topic.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
       */
      public Builder clearMaxMessageBytes() {
        if (maxMessageBytesBuilder_ == null) {
          maxMessageBytes_ = null;
          onChanged();
        } else {
          maxMessageBytes_ = null;
          maxMessageBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The largest record batch size allowed in topic.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
       */
      public com.google.protobuf.Int64Value.Builder getMaxMessageBytesBuilder() {
        
        onChanged();
        return getMaxMessageBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The largest record batch size allowed in topic.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getMaxMessageBytesOrBuilder() {
        if (maxMessageBytesBuilder_ != null) {
          return maxMessageBytesBuilder_.getMessageOrBuilder();
        } else {
          return maxMessageBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : maxMessageBytes_;
        }
      }
      /**
       * <pre>
       * The largest record batch size allowed in topic.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getMaxMessageBytesFieldBuilder() {
        if (maxMessageBytesBuilder_ == null) {
          maxMessageBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getMaxMessageBytes(),
                  getParentForChildren(),
                  isClean());
          maxMessageBytes_ = null;
        }
        return maxMessageBytesBuilder_;
      }

      private com.google.protobuf.Int64Value minInsyncReplicas_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> minInsyncReplicasBuilder_;
      /**
       * <pre>
       * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
       * to be considered successful (when a producer sets acks to "all").
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
       */
      public boolean hasMinInsyncReplicas() {
        return minInsyncReplicasBuilder_ != null || minInsyncReplicas_ != null;
      }
      /**
       * <pre>
       * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
       * to be considered successful (when a producer sets acks to "all").
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
       */
      public com.google.protobuf.Int64Value getMinInsyncReplicas() {
        if (minInsyncReplicasBuilder_ == null) {
          return minInsyncReplicas_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : minInsyncReplicas_;
        } else {
          return minInsyncReplicasBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
       * to be considered successful (when a producer sets acks to "all").
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
       */
      public Builder setMinInsyncReplicas(com.google.protobuf.Int64Value value) {
        if (minInsyncReplicasBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          minInsyncReplicas_ = value;
          onChanged();
        } else {
          minInsyncReplicasBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
       * to be considered successful (when a producer sets acks to "all").
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
       */
      public Builder setMinInsyncReplicas(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (minInsyncReplicasBuilder_ == null) {
          minInsyncReplicas_ = builderForValue.build();
          onChanged();
        } else {
          minInsyncReplicasBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
       * to be considered successful (when a producer sets acks to "all").
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
       */
      public Builder mergeMinInsyncReplicas(com.google.protobuf.Int64Value value) {
        if (minInsyncReplicasBuilder_ == null) {
          if (minInsyncReplicas_ != null) {
            minInsyncReplicas_ =
              com.google.protobuf.Int64Value.newBuilder(minInsyncReplicas_).mergeFrom(value).buildPartial();
          } else {
            minInsyncReplicas_ = value;
          }
          onChanged();
        } else {
          minInsyncReplicasBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
       * to be considered successful (when a producer sets acks to "all").
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
       */
      public Builder clearMinInsyncReplicas() {
        if (minInsyncReplicasBuilder_ == null) {
          minInsyncReplicas_ = null;
          onChanged();
        } else {
          minInsyncReplicas_ = null;
          minInsyncReplicasBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
       * to be considered successful (when a producer sets acks to "all").
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
       */
      public com.google.protobuf.Int64Value.Builder getMinInsyncReplicasBuilder() {
        
        onChanged();
        return getMinInsyncReplicasFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
       * to be considered successful (when a producer sets acks to "all").
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getMinInsyncReplicasOrBuilder() {
        if (minInsyncReplicasBuilder_ != null) {
          return minInsyncReplicasBuilder_.getMessageOrBuilder();
        } else {
          return minInsyncReplicas_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : minInsyncReplicas_;
        }
      }
      /**
       * <pre>
       * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
       * to be considered successful (when a producer sets acks to "all").
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getMinInsyncReplicasFieldBuilder() {
        if (minInsyncReplicasBuilder_ == null) {
          minInsyncReplicasBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getMinInsyncReplicas(),
                  getParentForChildren(),
                  isClean());
          minInsyncReplicas_ = null;
        }
        return minInsyncReplicasBuilder_;
      }

      private com.google.protobuf.Int64Value segmentBytes_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> segmentBytesBuilder_;
      /**
       * <pre>
       * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
       * at a time so a larger segment size means fewer files but less granular control over retention.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_segment_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
       */
      public boolean hasSegmentBytes() {
        return segmentBytesBuilder_ != null || segmentBytes_ != null;
      }
      /**
       * <pre>
       * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
       * at a time so a larger segment size means fewer files but less granular control over retention.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_segment_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
       */
      public com.google.protobuf.Int64Value getSegmentBytes() {
        if (segmentBytesBuilder_ == null) {
          return segmentBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : segmentBytes_;
        } else {
          return segmentBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
       * at a time so a larger segment size means fewer files but less granular control over retention.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_segment_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
       */
      public Builder setSegmentBytes(com.google.protobuf.Int64Value value) {
        if (segmentBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          segmentBytes_ = value;
          onChanged();
        } else {
          segmentBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
       * at a time so a larger segment size means fewer files but less granular control over retention.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_segment_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
       */
      public Builder setSegmentBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (segmentBytesBuilder_ == null) {
          segmentBytes_ = builderForValue.build();
          onChanged();
        } else {
          segmentBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
       * at a time so a larger segment size means fewer files but less granular control over retention.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_segment_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
       */
      public Builder mergeSegmentBytes(com.google.protobuf.Int64Value value) {
        if (segmentBytesBuilder_ == null) {
          if (segmentBytes_ != null) {
            segmentBytes_ =
              com.google.protobuf.Int64Value.newBuilder(segmentBytes_).mergeFrom(value).buildPartial();
          } else {
            segmentBytes_ = value;
          }
          onChanged();
        } else {
          segmentBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
       * at a time so a larger segment size means fewer files but less granular control over retention.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_segment_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
       */
      public Builder clearSegmentBytes() {
        if (segmentBytesBuilder_ == null) {
          segmentBytes_ = null;
          onChanged();
        } else {
          segmentBytes_ = null;
          segmentBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
       * at a time so a larger segment size means fewer files but less granular control over retention.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_segment_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
       */
      public com.google.protobuf.Int64Value.Builder getSegmentBytesBuilder() {
        
        onChanged();
        return getSegmentBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
       * at a time so a larger segment size means fewer files but less granular control over retention.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_segment_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getSegmentBytesOrBuilder() {
        if (segmentBytesBuilder_ != null) {
          return segmentBytesBuilder_.getMessageOrBuilder();
        } else {
          return segmentBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : segmentBytes_;
        }
      }
      /**
       * <pre>
       * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
       * at a time so a larger segment size means fewer files but less granular control over retention.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_segment_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getSegmentBytesFieldBuilder() {
        if (segmentBytesBuilder_ == null) {
          segmentBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getSegmentBytes(),
                  getParentForChildren(),
                  isClean());
          segmentBytes_ = null;
        }
        return segmentBytesBuilder_;
      }

      private com.google.protobuf.BoolValue preallocate_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder> preallocateBuilder_;
      /**
       * <pre>
       * True if we should preallocate the file on disk when creating a new log segment.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_preallocate] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue preallocate = 13;</code>
       */
      public boolean hasPreallocate() {
        return preallocateBuilder_ != null || preallocate_ != null;
      }
      /**
       * <pre>
       * True if we should preallocate the file on disk when creating a new log segment.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_preallocate] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue preallocate = 13;</code>
       */
      public com.google.protobuf.BoolValue getPreallocate() {
        if (preallocateBuilder_ == null) {
          return preallocate_ == null ? com.google.protobuf.BoolValue.getDefaultInstance() : preallocate_;
        } else {
          return preallocateBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * True if we should preallocate the file on disk when creating a new log segment.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_preallocate] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue preallocate = 13;</code>
       */
      public Builder setPreallocate(com.google.protobuf.BoolValue value) {
        if (preallocateBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          preallocate_ = value;
          onChanged();
        } else {
          preallocateBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * True if we should preallocate the file on disk when creating a new log segment.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_preallocate] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue preallocate = 13;</code>
       */
      public Builder setPreallocate(
          com.google.protobuf.BoolValue.Builder builderForValue) {
        if (preallocateBuilder_ == null) {
          preallocate_ = builderForValue.build();
          onChanged();
        } else {
          preallocateBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * True if we should preallocate the file on disk when creating a new log segment.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_preallocate] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue preallocate = 13;</code>
       */
      public Builder mergePreallocate(com.google.protobuf.BoolValue value) {
        if (preallocateBuilder_ == null) {
          if (preallocate_ != null) {
            preallocate_ =
              com.google.protobuf.BoolValue.newBuilder(preallocate_).mergeFrom(value).buildPartial();
          } else {
            preallocate_ = value;
          }
          onChanged();
        } else {
          preallocateBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * True if we should preallocate the file on disk when creating a new log segment.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_preallocate] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue preallocate = 13;</code>
       */
      public Builder clearPreallocate() {
        if (preallocateBuilder_ == null) {
          preallocate_ = null;
          onChanged();
        } else {
          preallocate_ = null;
          preallocateBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * True if we should preallocate the file on disk when creating a new log segment.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_preallocate] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue preallocate = 13;</code>
       */
      public com.google.protobuf.BoolValue.Builder getPreallocateBuilder() {
        
        onChanged();
        return getPreallocateFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * True if we should preallocate the file on disk when creating a new log segment.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_preallocate] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue preallocate = 13;</code>
       */
      public com.google.protobuf.BoolValueOrBuilder getPreallocateOrBuilder() {
        if (preallocateBuilder_ != null) {
          return preallocateBuilder_.getMessageOrBuilder();
        } else {
          return preallocate_ == null ?
              com.google.protobuf.BoolValue.getDefaultInstance() : preallocate_;
        }
      }
      /**
       * <pre>
       * True if we should preallocate the file on disk when creating a new log segment.
       * This setting overrides the cluster-level [KafkaConfig2_1.log_preallocate] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue preallocate = 13;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder> 
          getPreallocateFieldBuilder() {
        if (preallocateBuilder_ == null) {
          preallocateBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder>(
                  getPreallocate(),
                  getParentForChildren(),
                  isClean());
          preallocate_ = null;
        }
        return preallocateBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.TopicConfig2_1)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.TopicConfig2_1)
    private static final yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1();
    }

    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<TopicConfig2_1>
        PARSER = new com.google.protobuf.AbstractParser<TopicConfig2_1>() {
      @java.lang.Override
      public TopicConfig2_1 parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new TopicConfig2_1(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<TopicConfig2_1> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<TopicConfig2_1> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_1 getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface TopicConfig2_6OrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.TopicConfig2_6)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Retention policy to use on old log messages.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6.CleanupPolicy cleanup_policy = 1;</code>
     */
    int getCleanupPolicyValue();
    /**
     * <pre>
     * Retention policy to use on old log messages.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6.CleanupPolicy cleanup_policy = 1;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.CleanupPolicy getCleanupPolicy();

    /**
     * <pre>
     * The compression type for a given topic.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 2;</code>
     */
    int getCompressionTypeValue();
    /**
     * <pre>
     * The compression type for a given topic.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 2;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.Common.CompressionType getCompressionType();

    /**
     * <pre>
     * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
     */
    boolean hasDeleteRetentionMs();
    /**
     * <pre>
     * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
     */
    com.google.protobuf.Int64Value getDeleteRetentionMs();
    /**
     * <pre>
     * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getDeleteRetentionMsOrBuilder();

    /**
     * <pre>
     * The time to wait before deleting a file from the filesystem.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
     */
    boolean hasFileDeleteDelayMs();
    /**
     * <pre>
     * The time to wait before deleting a file from the filesystem.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
     */
    com.google.protobuf.Int64Value getFileDeleteDelayMs();
    /**
     * <pre>
     * The time to wait before deleting a file from the filesystem.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getFileDeleteDelayMsOrBuilder();

    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_messages] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
     */
    boolean hasFlushMessages();
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_messages] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
     */
    com.google.protobuf.Int64Value getFlushMessages();
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_messages] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getFlushMessagesOrBuilder();

    /**
     * <pre>
     * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_ms] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
     */
    boolean hasFlushMs();
    /**
     * <pre>
     * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_ms] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
     */
    com.google.protobuf.Int64Value getFlushMs();
    /**
     * <pre>
     * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_ms] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getFlushMsOrBuilder();

    /**
     * <pre>
     * The minimum time in milliseconds a message will remain uncompacted in the log.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
     */
    boolean hasMinCompactionLagMs();
    /**
     * <pre>
     * The minimum time in milliseconds a message will remain uncompacted in the log.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
     */
    com.google.protobuf.Int64Value getMinCompactionLagMs();
    /**
     * <pre>
     * The minimum time in milliseconds a message will remain uncompacted in the log.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getMinCompactionLagMsOrBuilder();

    /**
     * <pre>
     * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
     * It is helpful if you need to control the size of log due to limited disk space.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_bytes] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
     */
    boolean hasRetentionBytes();
    /**
     * <pre>
     * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
     * It is helpful if you need to control the size of log due to limited disk space.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_bytes] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
     */
    com.google.protobuf.Int64Value getRetentionBytes();
    /**
     * <pre>
     * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
     * It is helpful if you need to control the size of log due to limited disk space.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_bytes] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getRetentionBytesOrBuilder();

    /**
     * <pre>
     * The number of milliseconds to keep a log segment's file before deleting it.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_ms] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
     */
    boolean hasRetentionMs();
    /**
     * <pre>
     * The number of milliseconds to keep a log segment's file before deleting it.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_ms] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
     */
    com.google.protobuf.Int64Value getRetentionMs();
    /**
     * <pre>
     * The number of milliseconds to keep a log segment's file before deleting it.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_ms] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getRetentionMsOrBuilder();

    /**
     * <pre>
     * The largest record batch size allowed in topic.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
     */
    boolean hasMaxMessageBytes();
    /**
     * <pre>
     * The largest record batch size allowed in topic.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
     */
    com.google.protobuf.Int64Value getMaxMessageBytes();
    /**
     * <pre>
     * The largest record batch size allowed in topic.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getMaxMessageBytesOrBuilder();

    /**
     * <pre>
     * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
     * to be considered successful (when a producer sets acks to "all").
     * </pre>
     *
     * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
     */
    boolean hasMinInsyncReplicas();
    /**
     * <pre>
     * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
     * to be considered successful (when a producer sets acks to "all").
     * </pre>
     *
     * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
     */
    com.google.protobuf.Int64Value getMinInsyncReplicas();
    /**
     * <pre>
     * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
     * to be considered successful (when a producer sets acks to "all").
     * </pre>
     *
     * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getMinInsyncReplicasOrBuilder();

    /**
     * <pre>
     * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
     * at a time so a larger segment size means fewer files but less granular control over retention.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_segment_bytes] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
     */
    boolean hasSegmentBytes();
    /**
     * <pre>
     * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
     * at a time so a larger segment size means fewer files but less granular control over retention.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_segment_bytes] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
     */
    com.google.protobuf.Int64Value getSegmentBytes();
    /**
     * <pre>
     * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
     * at a time so a larger segment size means fewer files but less granular control over retention.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_segment_bytes] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getSegmentBytesOrBuilder();

    /**
     * <pre>
     * True if we should preallocate the file on disk when creating a new log segment.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_preallocate] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue preallocate = 13;</code>
     */
    boolean hasPreallocate();
    /**
     * <pre>
     * True if we should preallocate the file on disk when creating a new log segment.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_preallocate] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue preallocate = 13;</code>
     */
    com.google.protobuf.BoolValue getPreallocate();
    /**
     * <pre>
     * True if we should preallocate the file on disk when creating a new log segment.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_preallocate] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue preallocate = 13;</code>
     */
    com.google.protobuf.BoolValueOrBuilder getPreallocateOrBuilder();
  }
  /**
   * <pre>
   * A topic settings for 2.6
   * </pre>
   *
   * Protobuf type {@code yandex.cloud.mdb.kafka.v1.TopicConfig2_6}
   */
  public  static final class TopicConfig2_6 extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.TopicConfig2_6)
      TopicConfig2_6OrBuilder {
  private static final long serialVersionUID = 0L;
    // Use TopicConfig2_6.newBuilder() to construct.
    private TopicConfig2_6(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private TopicConfig2_6() {
      cleanupPolicy_ = 0;
      compressionType_ = 0;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private TopicConfig2_6(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              int rawValue = input.readEnum();

              cleanupPolicy_ = rawValue;
              break;
            }
            case 16: {
              int rawValue = input.readEnum();

              compressionType_ = rawValue;
              break;
            }
            case 26: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (deleteRetentionMs_ != null) {
                subBuilder = deleteRetentionMs_.toBuilder();
              }
              deleteRetentionMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(deleteRetentionMs_);
                deleteRetentionMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 34: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (fileDeleteDelayMs_ != null) {
                subBuilder = fileDeleteDelayMs_.toBuilder();
              }
              fileDeleteDelayMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(fileDeleteDelayMs_);
                fileDeleteDelayMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 42: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (flushMessages_ != null) {
                subBuilder = flushMessages_.toBuilder();
              }
              flushMessages_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(flushMessages_);
                flushMessages_ = subBuilder.buildPartial();
              }

              break;
            }
            case 50: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (flushMs_ != null) {
                subBuilder = flushMs_.toBuilder();
              }
              flushMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(flushMs_);
                flushMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 58: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (minCompactionLagMs_ != null) {
                subBuilder = minCompactionLagMs_.toBuilder();
              }
              minCompactionLagMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(minCompactionLagMs_);
                minCompactionLagMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 66: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (retentionBytes_ != null) {
                subBuilder = retentionBytes_.toBuilder();
              }
              retentionBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(retentionBytes_);
                retentionBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 74: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (retentionMs_ != null) {
                subBuilder = retentionMs_.toBuilder();
              }
              retentionMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(retentionMs_);
                retentionMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 82: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (maxMessageBytes_ != null) {
                subBuilder = maxMessageBytes_.toBuilder();
              }
              maxMessageBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(maxMessageBytes_);
                maxMessageBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 90: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (minInsyncReplicas_ != null) {
                subBuilder = minInsyncReplicas_.toBuilder();
              }
              minInsyncReplicas_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(minInsyncReplicas_);
                minInsyncReplicas_ = subBuilder.buildPartial();
              }

              break;
            }
            case 98: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (segmentBytes_ != null) {
                subBuilder = segmentBytes_.toBuilder();
              }
              segmentBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(segmentBytes_);
                segmentBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 106: {
              com.google.protobuf.BoolValue.Builder subBuilder = null;
              if (preallocate_ != null) {
                subBuilder = preallocate_.toBuilder();
              }
              preallocate_ = input.readMessage(com.google.protobuf.BoolValue.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(preallocate_);
                preallocate_ = subBuilder.buildPartial();
              }

              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_TopicConfig2_6_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_TopicConfig2_6_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.class, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.Builder.class);
    }

    /**
     * Protobuf enum {@code yandex.cloud.mdb.kafka.v1.TopicConfig2_6.CleanupPolicy}
     */
    public enum CleanupPolicy
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>CLEANUP_POLICY_UNSPECIFIED = 0;</code>
       */
      CLEANUP_POLICY_UNSPECIFIED(0),
      /**
       * <pre>
       * this policy discards log segments when either their retention time or log size limit is reached. See also: [KafkaConfig2_1.log_retention_ms] and other similar parameters.
       * </pre>
       *
       * <code>CLEANUP_POLICY_DELETE = 1;</code>
       */
      CLEANUP_POLICY_DELETE(1),
      /**
       * <pre>
       * this policy compacts messages in log.
       * </pre>
       *
       * <code>CLEANUP_POLICY_COMPACT = 2;</code>
       */
      CLEANUP_POLICY_COMPACT(2),
      /**
       * <pre>
       * this policy use both compaction and deletion for messages and log segments.
       * </pre>
       *
       * <code>CLEANUP_POLICY_COMPACT_AND_DELETE = 3;</code>
       */
      CLEANUP_POLICY_COMPACT_AND_DELETE(3),
      UNRECOGNIZED(-1),
      ;

      /**
       * <code>CLEANUP_POLICY_UNSPECIFIED = 0;</code>
       */
      public static final int CLEANUP_POLICY_UNSPECIFIED_VALUE = 0;
      /**
       * <pre>
       * this policy discards log segments when either their retention time or log size limit is reached. See also: [KafkaConfig2_1.log_retention_ms] and other similar parameters.
       * </pre>
       *
       * <code>CLEANUP_POLICY_DELETE = 1;</code>
       */
      public static final int CLEANUP_POLICY_DELETE_VALUE = 1;
      /**
       * <pre>
       * this policy compacts messages in log.
       * </pre>
       *
       * <code>CLEANUP_POLICY_COMPACT = 2;</code>
       */
      public static final int CLEANUP_POLICY_COMPACT_VALUE = 2;
      /**
       * <pre>
       * this policy use both compaction and deletion for messages and log segments.
       * </pre>
       *
       * <code>CLEANUP_POLICY_COMPACT_AND_DELETE = 3;</code>
       */
      public static final int CLEANUP_POLICY_COMPACT_AND_DELETE_VALUE = 3;


      public final int getNumber() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalArgumentException(
              "Can't get the number of an unknown enum value.");
        }
        return value;
      }

      /**
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static CleanupPolicy valueOf(int value) {
        return forNumber(value);
      }

      public static CleanupPolicy forNumber(int value) {
        switch (value) {
          case 0: return CLEANUP_POLICY_UNSPECIFIED;
          case 1: return CLEANUP_POLICY_DELETE;
          case 2: return CLEANUP_POLICY_COMPACT;
          case 3: return CLEANUP_POLICY_COMPACT_AND_DELETE;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<CleanupPolicy>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final com.google.protobuf.Internal.EnumLiteMap<
          CleanupPolicy> internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<CleanupPolicy>() {
              public CleanupPolicy findValueByNumber(int number) {
                return CleanupPolicy.forNumber(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(ordinal());
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.getDescriptor().getEnumTypes().get(0);
      }

      private static final CleanupPolicy[] VALUES = values();

      public static CleanupPolicy valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        if (desc.getIndex() == -1) {
          return UNRECOGNIZED;
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private CleanupPolicy(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:yandex.cloud.mdb.kafka.v1.TopicConfig2_6.CleanupPolicy)
    }

    public static final int CLEANUP_POLICY_FIELD_NUMBER = 1;
    private int cleanupPolicy_;
    /**
     * <pre>
     * Retention policy to use on old log messages.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6.CleanupPolicy cleanup_policy = 1;</code>
     */
    public int getCleanupPolicyValue() {
      return cleanupPolicy_;
    }
    /**
     * <pre>
     * Retention policy to use on old log messages.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6.CleanupPolicy cleanup_policy = 1;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.CleanupPolicy getCleanupPolicy() {
      @SuppressWarnings("deprecation")
      yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.CleanupPolicy result = yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.CleanupPolicy.valueOf(cleanupPolicy_);
      return result == null ? yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.CleanupPolicy.UNRECOGNIZED : result;
    }

    public static final int COMPRESSION_TYPE_FIELD_NUMBER = 2;
    private int compressionType_;
    /**
     * <pre>
     * The compression type for a given topic.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 2;</code>
     */
    public int getCompressionTypeValue() {
      return compressionType_;
    }
    /**
     * <pre>
     * The compression type for a given topic.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 2;</code>
     */
    public yandex.cloud.api.mdb.kafka.v1.Common.CompressionType getCompressionType() {
      @SuppressWarnings("deprecation")
      yandex.cloud.api.mdb.kafka.v1.Common.CompressionType result = yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.valueOf(compressionType_);
      return result == null ? yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.UNRECOGNIZED : result;
    }

    public static final int DELETE_RETENTION_MS_FIELD_NUMBER = 3;
    private com.google.protobuf.Int64Value deleteRetentionMs_;
    /**
     * <pre>
     * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
     */
    public boolean hasDeleteRetentionMs() {
      return deleteRetentionMs_ != null;
    }
    /**
     * <pre>
     * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
     */
    public com.google.protobuf.Int64Value getDeleteRetentionMs() {
      return deleteRetentionMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : deleteRetentionMs_;
    }
    /**
     * <pre>
     * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getDeleteRetentionMsOrBuilder() {
      return getDeleteRetentionMs();
    }

    public static final int FILE_DELETE_DELAY_MS_FIELD_NUMBER = 4;
    private com.google.protobuf.Int64Value fileDeleteDelayMs_;
    /**
     * <pre>
     * The time to wait before deleting a file from the filesystem.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
     */
    public boolean hasFileDeleteDelayMs() {
      return fileDeleteDelayMs_ != null;
    }
    /**
     * <pre>
     * The time to wait before deleting a file from the filesystem.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
     */
    public com.google.protobuf.Int64Value getFileDeleteDelayMs() {
      return fileDeleteDelayMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : fileDeleteDelayMs_;
    }
    /**
     * <pre>
     * The time to wait before deleting a file from the filesystem.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getFileDeleteDelayMsOrBuilder() {
      return getFileDeleteDelayMs();
    }

    public static final int FLUSH_MESSAGES_FIELD_NUMBER = 5;
    private com.google.protobuf.Int64Value flushMessages_;
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_messages] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
     */
    public boolean hasFlushMessages() {
      return flushMessages_ != null;
    }
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_messages] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
     */
    public com.google.protobuf.Int64Value getFlushMessages() {
      return flushMessages_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : flushMessages_;
    }
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_messages] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getFlushMessagesOrBuilder() {
      return getFlushMessages();
    }

    public static final int FLUSH_MS_FIELD_NUMBER = 6;
    private com.google.protobuf.Int64Value flushMs_;
    /**
     * <pre>
     * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_ms] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
     */
    public boolean hasFlushMs() {
      return flushMs_ != null;
    }
    /**
     * <pre>
     * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_ms] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
     */
    public com.google.protobuf.Int64Value getFlushMs() {
      return flushMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : flushMs_;
    }
    /**
     * <pre>
     * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_ms] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getFlushMsOrBuilder() {
      return getFlushMs();
    }

    public static final int MIN_COMPACTION_LAG_MS_FIELD_NUMBER = 7;
    private com.google.protobuf.Int64Value minCompactionLagMs_;
    /**
     * <pre>
     * The minimum time in milliseconds a message will remain uncompacted in the log.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
     */
    public boolean hasMinCompactionLagMs() {
      return minCompactionLagMs_ != null;
    }
    /**
     * <pre>
     * The minimum time in milliseconds a message will remain uncompacted in the log.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
     */
    public com.google.protobuf.Int64Value getMinCompactionLagMs() {
      return minCompactionLagMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : minCompactionLagMs_;
    }
    /**
     * <pre>
     * The minimum time in milliseconds a message will remain uncompacted in the log.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getMinCompactionLagMsOrBuilder() {
      return getMinCompactionLagMs();
    }

    public static final int RETENTION_BYTES_FIELD_NUMBER = 8;
    private com.google.protobuf.Int64Value retentionBytes_;
    /**
     * <pre>
     * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
     * It is helpful if you need to control the size of log due to limited disk space.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_bytes] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
     */
    public boolean hasRetentionBytes() {
      return retentionBytes_ != null;
    }
    /**
     * <pre>
     * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
     * It is helpful if you need to control the size of log due to limited disk space.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_bytes] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
     */
    public com.google.protobuf.Int64Value getRetentionBytes() {
      return retentionBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : retentionBytes_;
    }
    /**
     * <pre>
     * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
     * It is helpful if you need to control the size of log due to limited disk space.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_bytes] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getRetentionBytesOrBuilder() {
      return getRetentionBytes();
    }

    public static final int RETENTION_MS_FIELD_NUMBER = 9;
    private com.google.protobuf.Int64Value retentionMs_;
    /**
     * <pre>
     * The number of milliseconds to keep a log segment's file before deleting it.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_ms] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
     */
    public boolean hasRetentionMs() {
      return retentionMs_ != null;
    }
    /**
     * <pre>
     * The number of milliseconds to keep a log segment's file before deleting it.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_ms] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
     */
    public com.google.protobuf.Int64Value getRetentionMs() {
      return retentionMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : retentionMs_;
    }
    /**
     * <pre>
     * The number of milliseconds to keep a log segment's file before deleting it.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_ms] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getRetentionMsOrBuilder() {
      return getRetentionMs();
    }

    public static final int MAX_MESSAGE_BYTES_FIELD_NUMBER = 10;
    private com.google.protobuf.Int64Value maxMessageBytes_;
    /**
     * <pre>
     * The largest record batch size allowed in topic.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
     */
    public boolean hasMaxMessageBytes() {
      return maxMessageBytes_ != null;
    }
    /**
     * <pre>
     * The largest record batch size allowed in topic.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
     */
    public com.google.protobuf.Int64Value getMaxMessageBytes() {
      return maxMessageBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : maxMessageBytes_;
    }
    /**
     * <pre>
     * The largest record batch size allowed in topic.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getMaxMessageBytesOrBuilder() {
      return getMaxMessageBytes();
    }

    public static final int MIN_INSYNC_REPLICAS_FIELD_NUMBER = 11;
    private com.google.protobuf.Int64Value minInsyncReplicas_;
    /**
     * <pre>
     * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
     * to be considered successful (when a producer sets acks to "all").
     * </pre>
     *
     * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
     */
    public boolean hasMinInsyncReplicas() {
      return minInsyncReplicas_ != null;
    }
    /**
     * <pre>
     * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
     * to be considered successful (when a producer sets acks to "all").
     * </pre>
     *
     * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
     */
    public com.google.protobuf.Int64Value getMinInsyncReplicas() {
      return minInsyncReplicas_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : minInsyncReplicas_;
    }
    /**
     * <pre>
     * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
     * to be considered successful (when a producer sets acks to "all").
     * </pre>
     *
     * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getMinInsyncReplicasOrBuilder() {
      return getMinInsyncReplicas();
    }

    public static final int SEGMENT_BYTES_FIELD_NUMBER = 12;
    private com.google.protobuf.Int64Value segmentBytes_;
    /**
     * <pre>
     * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
     * at a time so a larger segment size means fewer files but less granular control over retention.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_segment_bytes] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
     */
    public boolean hasSegmentBytes() {
      return segmentBytes_ != null;
    }
    /**
     * <pre>
     * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
     * at a time so a larger segment size means fewer files but less granular control over retention.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_segment_bytes] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
     */
    public com.google.protobuf.Int64Value getSegmentBytes() {
      return segmentBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : segmentBytes_;
    }
    /**
     * <pre>
     * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
     * at a time so a larger segment size means fewer files but less granular control over retention.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_segment_bytes] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
     */
    public com.google.protobuf.Int64ValueOrBuilder getSegmentBytesOrBuilder() {
      return getSegmentBytes();
    }

    public static final int PREALLOCATE_FIELD_NUMBER = 13;
    private com.google.protobuf.BoolValue preallocate_;
    /**
     * <pre>
     * True if we should preallocate the file on disk when creating a new log segment.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_preallocate] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue preallocate = 13;</code>
     */
    public boolean hasPreallocate() {
      return preallocate_ != null;
    }
    /**
     * <pre>
     * True if we should preallocate the file on disk when creating a new log segment.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_preallocate] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue preallocate = 13;</code>
     */
    public com.google.protobuf.BoolValue getPreallocate() {
      return preallocate_ == null ? com.google.protobuf.BoolValue.getDefaultInstance() : preallocate_;
    }
    /**
     * <pre>
     * True if we should preallocate the file on disk when creating a new log segment.
     * This setting overrides the cluster-level [KafkaConfig2_6.log_preallocate] setting on the topic level.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue preallocate = 13;</code>
     */
    public com.google.protobuf.BoolValueOrBuilder getPreallocateOrBuilder() {
      return getPreallocate();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (cleanupPolicy_ != yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.CleanupPolicy.CLEANUP_POLICY_UNSPECIFIED.getNumber()) {
        output.writeEnum(1, cleanupPolicy_);
      }
      if (compressionType_ != yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.COMPRESSION_TYPE_UNSPECIFIED.getNumber()) {
        output.writeEnum(2, compressionType_);
      }
      if (deleteRetentionMs_ != null) {
        output.writeMessage(3, getDeleteRetentionMs());
      }
      if (fileDeleteDelayMs_ != null) {
        output.writeMessage(4, getFileDeleteDelayMs());
      }
      if (flushMessages_ != null) {
        output.writeMessage(5, getFlushMessages());
      }
      if (flushMs_ != null) {
        output.writeMessage(6, getFlushMs());
      }
      if (minCompactionLagMs_ != null) {
        output.writeMessage(7, getMinCompactionLagMs());
      }
      if (retentionBytes_ != null) {
        output.writeMessage(8, getRetentionBytes());
      }
      if (retentionMs_ != null) {
        output.writeMessage(9, getRetentionMs());
      }
      if (maxMessageBytes_ != null) {
        output.writeMessage(10, getMaxMessageBytes());
      }
      if (minInsyncReplicas_ != null) {
        output.writeMessage(11, getMinInsyncReplicas());
      }
      if (segmentBytes_ != null) {
        output.writeMessage(12, getSegmentBytes());
      }
      if (preallocate_ != null) {
        output.writeMessage(13, getPreallocate());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (cleanupPolicy_ != yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.CleanupPolicy.CLEANUP_POLICY_UNSPECIFIED.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, cleanupPolicy_);
      }
      if (compressionType_ != yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.COMPRESSION_TYPE_UNSPECIFIED.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, compressionType_);
      }
      if (deleteRetentionMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getDeleteRetentionMs());
      }
      if (fileDeleteDelayMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getFileDeleteDelayMs());
      }
      if (flushMessages_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getFlushMessages());
      }
      if (flushMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, getFlushMs());
      }
      if (minCompactionLagMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, getMinCompactionLagMs());
      }
      if (retentionBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(8, getRetentionBytes());
      }
      if (retentionMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(9, getRetentionMs());
      }
      if (maxMessageBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(10, getMaxMessageBytes());
      }
      if (minInsyncReplicas_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(11, getMinInsyncReplicas());
      }
      if (segmentBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(12, getSegmentBytes());
      }
      if (preallocate_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(13, getPreallocate());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6)) {
        return super.equals(obj);
      }
      yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 other = (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6) obj;

      boolean result = true;
      result = result && cleanupPolicy_ == other.cleanupPolicy_;
      result = result && compressionType_ == other.compressionType_;
      result = result && (hasDeleteRetentionMs() == other.hasDeleteRetentionMs());
      if (hasDeleteRetentionMs()) {
        result = result && getDeleteRetentionMs()
            .equals(other.getDeleteRetentionMs());
      }
      result = result && (hasFileDeleteDelayMs() == other.hasFileDeleteDelayMs());
      if (hasFileDeleteDelayMs()) {
        result = result && getFileDeleteDelayMs()
            .equals(other.getFileDeleteDelayMs());
      }
      result = result && (hasFlushMessages() == other.hasFlushMessages());
      if (hasFlushMessages()) {
        result = result && getFlushMessages()
            .equals(other.getFlushMessages());
      }
      result = result && (hasFlushMs() == other.hasFlushMs());
      if (hasFlushMs()) {
        result = result && getFlushMs()
            .equals(other.getFlushMs());
      }
      result = result && (hasMinCompactionLagMs() == other.hasMinCompactionLagMs());
      if (hasMinCompactionLagMs()) {
        result = result && getMinCompactionLagMs()
            .equals(other.getMinCompactionLagMs());
      }
      result = result && (hasRetentionBytes() == other.hasRetentionBytes());
      if (hasRetentionBytes()) {
        result = result && getRetentionBytes()
            .equals(other.getRetentionBytes());
      }
      result = result && (hasRetentionMs() == other.hasRetentionMs());
      if (hasRetentionMs()) {
        result = result && getRetentionMs()
            .equals(other.getRetentionMs());
      }
      result = result && (hasMaxMessageBytes() == other.hasMaxMessageBytes());
      if (hasMaxMessageBytes()) {
        result = result && getMaxMessageBytes()
            .equals(other.getMaxMessageBytes());
      }
      result = result && (hasMinInsyncReplicas() == other.hasMinInsyncReplicas());
      if (hasMinInsyncReplicas()) {
        result = result && getMinInsyncReplicas()
            .equals(other.getMinInsyncReplicas());
      }
      result = result && (hasSegmentBytes() == other.hasSegmentBytes());
      if (hasSegmentBytes()) {
        result = result && getSegmentBytes()
            .equals(other.getSegmentBytes());
      }
      result = result && (hasPreallocate() == other.hasPreallocate());
      if (hasPreallocate()) {
        result = result && getPreallocate()
            .equals(other.getPreallocate());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + CLEANUP_POLICY_FIELD_NUMBER;
      hash = (53 * hash) + cleanupPolicy_;
      hash = (37 * hash) + COMPRESSION_TYPE_FIELD_NUMBER;
      hash = (53 * hash) + compressionType_;
      if (hasDeleteRetentionMs()) {
        hash = (37 * hash) + DELETE_RETENTION_MS_FIELD_NUMBER;
        hash = (53 * hash) + getDeleteRetentionMs().hashCode();
      }
      if (hasFileDeleteDelayMs()) {
        hash = (37 * hash) + FILE_DELETE_DELAY_MS_FIELD_NUMBER;
        hash = (53 * hash) + getFileDeleteDelayMs().hashCode();
      }
      if (hasFlushMessages()) {
        hash = (37 * hash) + FLUSH_MESSAGES_FIELD_NUMBER;
        hash = (53 * hash) + getFlushMessages().hashCode();
      }
      if (hasFlushMs()) {
        hash = (37 * hash) + FLUSH_MS_FIELD_NUMBER;
        hash = (53 * hash) + getFlushMs().hashCode();
      }
      if (hasMinCompactionLagMs()) {
        hash = (37 * hash) + MIN_COMPACTION_LAG_MS_FIELD_NUMBER;
        hash = (53 * hash) + getMinCompactionLagMs().hashCode();
      }
      if (hasRetentionBytes()) {
        hash = (37 * hash) + RETENTION_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getRetentionBytes().hashCode();
      }
      if (hasRetentionMs()) {
        hash = (37 * hash) + RETENTION_MS_FIELD_NUMBER;
        hash = (53 * hash) + getRetentionMs().hashCode();
      }
      if (hasMaxMessageBytes()) {
        hash = (37 * hash) + MAX_MESSAGE_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getMaxMessageBytes().hashCode();
      }
      if (hasMinInsyncReplicas()) {
        hash = (37 * hash) + MIN_INSYNC_REPLICAS_FIELD_NUMBER;
        hash = (53 * hash) + getMinInsyncReplicas().hashCode();
      }
      if (hasSegmentBytes()) {
        hash = (37 * hash) + SEGMENT_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getSegmentBytes().hashCode();
      }
      if (hasPreallocate()) {
        hash = (37 * hash) + PREALLOCATE_FIELD_NUMBER;
        hash = (53 * hash) + getPreallocate().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * A topic settings for 2.6
     * </pre>
     *
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.TopicConfig2_6}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.TopicConfig2_6)
        yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6OrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_TopicConfig2_6_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_TopicConfig2_6_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.class, yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.Builder.class);
      }

      // Construct using yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        cleanupPolicy_ = 0;

        compressionType_ = 0;

        if (deleteRetentionMsBuilder_ == null) {
          deleteRetentionMs_ = null;
        } else {
          deleteRetentionMs_ = null;
          deleteRetentionMsBuilder_ = null;
        }
        if (fileDeleteDelayMsBuilder_ == null) {
          fileDeleteDelayMs_ = null;
        } else {
          fileDeleteDelayMs_ = null;
          fileDeleteDelayMsBuilder_ = null;
        }
        if (flushMessagesBuilder_ == null) {
          flushMessages_ = null;
        } else {
          flushMessages_ = null;
          flushMessagesBuilder_ = null;
        }
        if (flushMsBuilder_ == null) {
          flushMs_ = null;
        } else {
          flushMs_ = null;
          flushMsBuilder_ = null;
        }
        if (minCompactionLagMsBuilder_ == null) {
          minCompactionLagMs_ = null;
        } else {
          minCompactionLagMs_ = null;
          minCompactionLagMsBuilder_ = null;
        }
        if (retentionBytesBuilder_ == null) {
          retentionBytes_ = null;
        } else {
          retentionBytes_ = null;
          retentionBytesBuilder_ = null;
        }
        if (retentionMsBuilder_ == null) {
          retentionMs_ = null;
        } else {
          retentionMs_ = null;
          retentionMsBuilder_ = null;
        }
        if (maxMessageBytesBuilder_ == null) {
          maxMessageBytes_ = null;
        } else {
          maxMessageBytes_ = null;
          maxMessageBytesBuilder_ = null;
        }
        if (minInsyncReplicasBuilder_ == null) {
          minInsyncReplicas_ = null;
        } else {
          minInsyncReplicas_ = null;
          minInsyncReplicasBuilder_ = null;
        }
        if (segmentBytesBuilder_ == null) {
          segmentBytes_ = null;
        } else {
          segmentBytes_ = null;
          segmentBytesBuilder_ = null;
        }
        if (preallocateBuilder_ == null) {
          preallocate_ = null;
        } else {
          preallocate_ = null;
          preallocateBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_TopicConfig2_6_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 getDefaultInstanceForType() {
        return yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 build() {
        yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 buildPartial() {
        yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 result = new yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6(this);
        result.cleanupPolicy_ = cleanupPolicy_;
        result.compressionType_ = compressionType_;
        if (deleteRetentionMsBuilder_ == null) {
          result.deleteRetentionMs_ = deleteRetentionMs_;
        } else {
          result.deleteRetentionMs_ = deleteRetentionMsBuilder_.build();
        }
        if (fileDeleteDelayMsBuilder_ == null) {
          result.fileDeleteDelayMs_ = fileDeleteDelayMs_;
        } else {
          result.fileDeleteDelayMs_ = fileDeleteDelayMsBuilder_.build();
        }
        if (flushMessagesBuilder_ == null) {
          result.flushMessages_ = flushMessages_;
        } else {
          result.flushMessages_ = flushMessagesBuilder_.build();
        }
        if (flushMsBuilder_ == null) {
          result.flushMs_ = flushMs_;
        } else {
          result.flushMs_ = flushMsBuilder_.build();
        }
        if (minCompactionLagMsBuilder_ == null) {
          result.minCompactionLagMs_ = minCompactionLagMs_;
        } else {
          result.minCompactionLagMs_ = minCompactionLagMsBuilder_.build();
        }
        if (retentionBytesBuilder_ == null) {
          result.retentionBytes_ = retentionBytes_;
        } else {
          result.retentionBytes_ = retentionBytesBuilder_.build();
        }
        if (retentionMsBuilder_ == null) {
          result.retentionMs_ = retentionMs_;
        } else {
          result.retentionMs_ = retentionMsBuilder_.build();
        }
        if (maxMessageBytesBuilder_ == null) {
          result.maxMessageBytes_ = maxMessageBytes_;
        } else {
          result.maxMessageBytes_ = maxMessageBytesBuilder_.build();
        }
        if (minInsyncReplicasBuilder_ == null) {
          result.minInsyncReplicas_ = minInsyncReplicas_;
        } else {
          result.minInsyncReplicas_ = minInsyncReplicasBuilder_.build();
        }
        if (segmentBytesBuilder_ == null) {
          result.segmentBytes_ = segmentBytes_;
        } else {
          result.segmentBytes_ = segmentBytesBuilder_.build();
        }
        if (preallocateBuilder_ == null) {
          result.preallocate_ = preallocate_;
        } else {
          result.preallocate_ = preallocateBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6) {
          return mergeFrom((yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 other) {
        if (other == yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.getDefaultInstance()) return this;
        if (other.cleanupPolicy_ != 0) {
          setCleanupPolicyValue(other.getCleanupPolicyValue());
        }
        if (other.compressionType_ != 0) {
          setCompressionTypeValue(other.getCompressionTypeValue());
        }
        if (other.hasDeleteRetentionMs()) {
          mergeDeleteRetentionMs(other.getDeleteRetentionMs());
        }
        if (other.hasFileDeleteDelayMs()) {
          mergeFileDeleteDelayMs(other.getFileDeleteDelayMs());
        }
        if (other.hasFlushMessages()) {
          mergeFlushMessages(other.getFlushMessages());
        }
        if (other.hasFlushMs()) {
          mergeFlushMs(other.getFlushMs());
        }
        if (other.hasMinCompactionLagMs()) {
          mergeMinCompactionLagMs(other.getMinCompactionLagMs());
        }
        if (other.hasRetentionBytes()) {
          mergeRetentionBytes(other.getRetentionBytes());
        }
        if (other.hasRetentionMs()) {
          mergeRetentionMs(other.getRetentionMs());
        }
        if (other.hasMaxMessageBytes()) {
          mergeMaxMessageBytes(other.getMaxMessageBytes());
        }
        if (other.hasMinInsyncReplicas()) {
          mergeMinInsyncReplicas(other.getMinInsyncReplicas());
        }
        if (other.hasSegmentBytes()) {
          mergeSegmentBytes(other.getSegmentBytes());
        }
        if (other.hasPreallocate()) {
          mergePreallocate(other.getPreallocate());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private int cleanupPolicy_ = 0;
      /**
       * <pre>
       * Retention policy to use on old log messages.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6.CleanupPolicy cleanup_policy = 1;</code>
       */
      public int getCleanupPolicyValue() {
        return cleanupPolicy_;
      }
      /**
       * <pre>
       * Retention policy to use on old log messages.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6.CleanupPolicy cleanup_policy = 1;</code>
       */
      public Builder setCleanupPolicyValue(int value) {
        cleanupPolicy_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Retention policy to use on old log messages.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6.CleanupPolicy cleanup_policy = 1;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.CleanupPolicy getCleanupPolicy() {
        @SuppressWarnings("deprecation")
        yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.CleanupPolicy result = yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.CleanupPolicy.valueOf(cleanupPolicy_);
        return result == null ? yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.CleanupPolicy.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       * Retention policy to use on old log messages.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6.CleanupPolicy cleanup_policy = 1;</code>
       */
      public Builder setCleanupPolicy(yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6.CleanupPolicy value) {
        if (value == null) {
          throw new NullPointerException();
        }
        
        cleanupPolicy_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Retention policy to use on old log messages.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.TopicConfig2_6.CleanupPolicy cleanup_policy = 1;</code>
       */
      public Builder clearCleanupPolicy() {
        
        cleanupPolicy_ = 0;
        onChanged();
        return this;
      }

      private int compressionType_ = 0;
      /**
       * <pre>
       * The compression type for a given topic.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 2;</code>
       */
      public int getCompressionTypeValue() {
        return compressionType_;
      }
      /**
       * <pre>
       * The compression type for a given topic.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 2;</code>
       */
      public Builder setCompressionTypeValue(int value) {
        compressionType_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The compression type for a given topic.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 2;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.Common.CompressionType getCompressionType() {
        @SuppressWarnings("deprecation")
        yandex.cloud.api.mdb.kafka.v1.Common.CompressionType result = yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.valueOf(compressionType_);
        return result == null ? yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       * The compression type for a given topic.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 2;</code>
       */
      public Builder setCompressionType(yandex.cloud.api.mdb.kafka.v1.Common.CompressionType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        
        compressionType_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The compression type for a given topic.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 2;</code>
       */
      public Builder clearCompressionType() {
        
        compressionType_ = 0;
        onChanged();
        return this;
      }

      private com.google.protobuf.Int64Value deleteRetentionMs_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> deleteRetentionMsBuilder_;
      /**
       * <pre>
       * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
       */
      public boolean hasDeleteRetentionMs() {
        return deleteRetentionMsBuilder_ != null || deleteRetentionMs_ != null;
      }
      /**
       * <pre>
       * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
       */
      public com.google.protobuf.Int64Value getDeleteRetentionMs() {
        if (deleteRetentionMsBuilder_ == null) {
          return deleteRetentionMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : deleteRetentionMs_;
        } else {
          return deleteRetentionMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
       */
      public Builder setDeleteRetentionMs(com.google.protobuf.Int64Value value) {
        if (deleteRetentionMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          deleteRetentionMs_ = value;
          onChanged();
        } else {
          deleteRetentionMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
       */
      public Builder setDeleteRetentionMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (deleteRetentionMsBuilder_ == null) {
          deleteRetentionMs_ = builderForValue.build();
          onChanged();
        } else {
          deleteRetentionMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
       */
      public Builder mergeDeleteRetentionMs(com.google.protobuf.Int64Value value) {
        if (deleteRetentionMsBuilder_ == null) {
          if (deleteRetentionMs_ != null) {
            deleteRetentionMs_ =
              com.google.protobuf.Int64Value.newBuilder(deleteRetentionMs_).mergeFrom(value).buildPartial();
          } else {
            deleteRetentionMs_ = value;
          }
          onChanged();
        } else {
          deleteRetentionMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
       */
      public Builder clearDeleteRetentionMs() {
        if (deleteRetentionMsBuilder_ == null) {
          deleteRetentionMs_ = null;
          onChanged();
        } else {
          deleteRetentionMs_ = null;
          deleteRetentionMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
       */
      public com.google.protobuf.Int64Value.Builder getDeleteRetentionMsBuilder() {
        
        onChanged();
        return getDeleteRetentionMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getDeleteRetentionMsOrBuilder() {
        if (deleteRetentionMsBuilder_ != null) {
          return deleteRetentionMsBuilder_.getMessageOrBuilder();
        } else {
          return deleteRetentionMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : deleteRetentionMs_;
        }
      }
      /**
       * <pre>
       * The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value delete_retention_ms = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getDeleteRetentionMsFieldBuilder() {
        if (deleteRetentionMsBuilder_ == null) {
          deleteRetentionMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getDeleteRetentionMs(),
                  getParentForChildren(),
                  isClean());
          deleteRetentionMs_ = null;
        }
        return deleteRetentionMsBuilder_;
      }

      private com.google.protobuf.Int64Value fileDeleteDelayMs_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> fileDeleteDelayMsBuilder_;
      /**
       * <pre>
       * The time to wait before deleting a file from the filesystem.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
       */
      public boolean hasFileDeleteDelayMs() {
        return fileDeleteDelayMsBuilder_ != null || fileDeleteDelayMs_ != null;
      }
      /**
       * <pre>
       * The time to wait before deleting a file from the filesystem.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
       */
      public com.google.protobuf.Int64Value getFileDeleteDelayMs() {
        if (fileDeleteDelayMsBuilder_ == null) {
          return fileDeleteDelayMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : fileDeleteDelayMs_;
        } else {
          return fileDeleteDelayMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The time to wait before deleting a file from the filesystem.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
       */
      public Builder setFileDeleteDelayMs(com.google.protobuf.Int64Value value) {
        if (fileDeleteDelayMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          fileDeleteDelayMs_ = value;
          onChanged();
        } else {
          fileDeleteDelayMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The time to wait before deleting a file from the filesystem.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
       */
      public Builder setFileDeleteDelayMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (fileDeleteDelayMsBuilder_ == null) {
          fileDeleteDelayMs_ = builderForValue.build();
          onChanged();
        } else {
          fileDeleteDelayMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The time to wait before deleting a file from the filesystem.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
       */
      public Builder mergeFileDeleteDelayMs(com.google.protobuf.Int64Value value) {
        if (fileDeleteDelayMsBuilder_ == null) {
          if (fileDeleteDelayMs_ != null) {
            fileDeleteDelayMs_ =
              com.google.protobuf.Int64Value.newBuilder(fileDeleteDelayMs_).mergeFrom(value).buildPartial();
          } else {
            fileDeleteDelayMs_ = value;
          }
          onChanged();
        } else {
          fileDeleteDelayMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The time to wait before deleting a file from the filesystem.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
       */
      public Builder clearFileDeleteDelayMs() {
        if (fileDeleteDelayMsBuilder_ == null) {
          fileDeleteDelayMs_ = null;
          onChanged();
        } else {
          fileDeleteDelayMs_ = null;
          fileDeleteDelayMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The time to wait before deleting a file from the filesystem.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
       */
      public com.google.protobuf.Int64Value.Builder getFileDeleteDelayMsBuilder() {
        
        onChanged();
        return getFileDeleteDelayMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The time to wait before deleting a file from the filesystem.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getFileDeleteDelayMsOrBuilder() {
        if (fileDeleteDelayMsBuilder_ != null) {
          return fileDeleteDelayMsBuilder_.getMessageOrBuilder();
        } else {
          return fileDeleteDelayMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : fileDeleteDelayMs_;
        }
      }
      /**
       * <pre>
       * The time to wait before deleting a file from the filesystem.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value file_delete_delay_ms = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getFileDeleteDelayMsFieldBuilder() {
        if (fileDeleteDelayMsBuilder_ == null) {
          fileDeleteDelayMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getFileDeleteDelayMs(),
                  getParentForChildren(),
                  isClean());
          fileDeleteDelayMs_ = null;
        }
        return fileDeleteDelayMsBuilder_;
      }

      private com.google.protobuf.Int64Value flushMessages_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> flushMessagesBuilder_;
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_messages] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
       */
      public boolean hasFlushMessages() {
        return flushMessagesBuilder_ != null || flushMessages_ != null;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_messages] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
       */
      public com.google.protobuf.Int64Value getFlushMessages() {
        if (flushMessagesBuilder_ == null) {
          return flushMessages_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : flushMessages_;
        } else {
          return flushMessagesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_messages] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
       */
      public Builder setFlushMessages(com.google.protobuf.Int64Value value) {
        if (flushMessagesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          flushMessages_ = value;
          onChanged();
        } else {
          flushMessagesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_messages] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
       */
      public Builder setFlushMessages(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (flushMessagesBuilder_ == null) {
          flushMessages_ = builderForValue.build();
          onChanged();
        } else {
          flushMessagesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_messages] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
       */
      public Builder mergeFlushMessages(com.google.protobuf.Int64Value value) {
        if (flushMessagesBuilder_ == null) {
          if (flushMessages_ != null) {
            flushMessages_ =
              com.google.protobuf.Int64Value.newBuilder(flushMessages_).mergeFrom(value).buildPartial();
          } else {
            flushMessages_ = value;
          }
          onChanged();
        } else {
          flushMessagesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_messages] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
       */
      public Builder clearFlushMessages() {
        if (flushMessagesBuilder_ == null) {
          flushMessages_ = null;
          onChanged();
        } else {
          flushMessages_ = null;
          flushMessagesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_messages] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
       */
      public com.google.protobuf.Int64Value.Builder getFlushMessagesBuilder() {
        
        onChanged();
        return getFlushMessagesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_messages] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getFlushMessagesOrBuilder() {
        if (flushMessagesBuilder_ != null) {
          return flushMessagesBuilder_.getMessageOrBuilder();
        } else {
          return flushMessages_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : flushMessages_;
        }
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_messages] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_messages = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getFlushMessagesFieldBuilder() {
        if (flushMessagesBuilder_ == null) {
          flushMessagesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getFlushMessages(),
                  getParentForChildren(),
                  isClean());
          flushMessages_ = null;
        }
        return flushMessagesBuilder_;
      }

      private com.google.protobuf.Int64Value flushMs_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> flushMsBuilder_;
      /**
       * <pre>
       * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
       */
      public boolean hasFlushMs() {
        return flushMsBuilder_ != null || flushMs_ != null;
      }
      /**
       * <pre>
       * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
       */
      public com.google.protobuf.Int64Value getFlushMs() {
        if (flushMsBuilder_ == null) {
          return flushMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : flushMs_;
        } else {
          return flushMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
       */
      public Builder setFlushMs(com.google.protobuf.Int64Value value) {
        if (flushMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          flushMs_ = value;
          onChanged();
        } else {
          flushMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
       */
      public Builder setFlushMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (flushMsBuilder_ == null) {
          flushMs_ = builderForValue.build();
          onChanged();
        } else {
          flushMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
       */
      public Builder mergeFlushMs(com.google.protobuf.Int64Value value) {
        if (flushMsBuilder_ == null) {
          if (flushMs_ != null) {
            flushMs_ =
              com.google.protobuf.Int64Value.newBuilder(flushMs_).mergeFrom(value).buildPartial();
          } else {
            flushMs_ = value;
          }
          onChanged();
        } else {
          flushMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
       */
      public Builder clearFlushMs() {
        if (flushMsBuilder_ == null) {
          flushMs_ = null;
          onChanged();
        } else {
          flushMs_ = null;
          flushMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
       */
      public com.google.protobuf.Int64Value.Builder getFlushMsBuilder() {
        
        onChanged();
        return getFlushMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getFlushMsOrBuilder() {
        if (flushMsBuilder_ != null) {
          return flushMsBuilder_.getMessageOrBuilder();
        } else {
          return flushMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : flushMs_;
        }
      }
      /**
       * <pre>
       * The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_flush_interval_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value flush_ms = 6;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getFlushMsFieldBuilder() {
        if (flushMsBuilder_ == null) {
          flushMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getFlushMs(),
                  getParentForChildren(),
                  isClean());
          flushMs_ = null;
        }
        return flushMsBuilder_;
      }

      private com.google.protobuf.Int64Value minCompactionLagMs_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> minCompactionLagMsBuilder_;
      /**
       * <pre>
       * The minimum time in milliseconds a message will remain uncompacted in the log.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
       */
      public boolean hasMinCompactionLagMs() {
        return minCompactionLagMsBuilder_ != null || minCompactionLagMs_ != null;
      }
      /**
       * <pre>
       * The minimum time in milliseconds a message will remain uncompacted in the log.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
       */
      public com.google.protobuf.Int64Value getMinCompactionLagMs() {
        if (minCompactionLagMsBuilder_ == null) {
          return minCompactionLagMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : minCompactionLagMs_;
        } else {
          return minCompactionLagMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The minimum time in milliseconds a message will remain uncompacted in the log.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
       */
      public Builder setMinCompactionLagMs(com.google.protobuf.Int64Value value) {
        if (minCompactionLagMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          minCompactionLagMs_ = value;
          onChanged();
        } else {
          minCompactionLagMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The minimum time in milliseconds a message will remain uncompacted in the log.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
       */
      public Builder setMinCompactionLagMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (minCompactionLagMsBuilder_ == null) {
          minCompactionLagMs_ = builderForValue.build();
          onChanged();
        } else {
          minCompactionLagMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The minimum time in milliseconds a message will remain uncompacted in the log.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
       */
      public Builder mergeMinCompactionLagMs(com.google.protobuf.Int64Value value) {
        if (minCompactionLagMsBuilder_ == null) {
          if (minCompactionLagMs_ != null) {
            minCompactionLagMs_ =
              com.google.protobuf.Int64Value.newBuilder(minCompactionLagMs_).mergeFrom(value).buildPartial();
          } else {
            minCompactionLagMs_ = value;
          }
          onChanged();
        } else {
          minCompactionLagMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The minimum time in milliseconds a message will remain uncompacted in the log.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
       */
      public Builder clearMinCompactionLagMs() {
        if (minCompactionLagMsBuilder_ == null) {
          minCompactionLagMs_ = null;
          onChanged();
        } else {
          minCompactionLagMs_ = null;
          minCompactionLagMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The minimum time in milliseconds a message will remain uncompacted in the log.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
       */
      public com.google.protobuf.Int64Value.Builder getMinCompactionLagMsBuilder() {
        
        onChanged();
        return getMinCompactionLagMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The minimum time in milliseconds a message will remain uncompacted in the log.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getMinCompactionLagMsOrBuilder() {
        if (minCompactionLagMsBuilder_ != null) {
          return minCompactionLagMsBuilder_.getMessageOrBuilder();
        } else {
          return minCompactionLagMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : minCompactionLagMs_;
        }
      }
      /**
       * <pre>
       * The minimum time in milliseconds a message will remain uncompacted in the log.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_compaction_lag_ms = 7;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getMinCompactionLagMsFieldBuilder() {
        if (minCompactionLagMsBuilder_ == null) {
          minCompactionLagMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getMinCompactionLagMs(),
                  getParentForChildren(),
                  isClean());
          minCompactionLagMs_ = null;
        }
        return minCompactionLagMsBuilder_;
      }

      private com.google.protobuf.Int64Value retentionBytes_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> retentionBytesBuilder_;
      /**
       * <pre>
       * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
       * It is helpful if you need to control the size of log due to limited disk space.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
       */
      public boolean hasRetentionBytes() {
        return retentionBytesBuilder_ != null || retentionBytes_ != null;
      }
      /**
       * <pre>
       * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
       * It is helpful if you need to control the size of log due to limited disk space.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
       */
      public com.google.protobuf.Int64Value getRetentionBytes() {
        if (retentionBytesBuilder_ == null) {
          return retentionBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : retentionBytes_;
        } else {
          return retentionBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
       * It is helpful if you need to control the size of log due to limited disk space.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
       */
      public Builder setRetentionBytes(com.google.protobuf.Int64Value value) {
        if (retentionBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          retentionBytes_ = value;
          onChanged();
        } else {
          retentionBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
       * It is helpful if you need to control the size of log due to limited disk space.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
       */
      public Builder setRetentionBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (retentionBytesBuilder_ == null) {
          retentionBytes_ = builderForValue.build();
          onChanged();
        } else {
          retentionBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
       * It is helpful if you need to control the size of log due to limited disk space.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
       */
      public Builder mergeRetentionBytes(com.google.protobuf.Int64Value value) {
        if (retentionBytesBuilder_ == null) {
          if (retentionBytes_ != null) {
            retentionBytes_ =
              com.google.protobuf.Int64Value.newBuilder(retentionBytes_).mergeFrom(value).buildPartial();
          } else {
            retentionBytes_ = value;
          }
          onChanged();
        } else {
          retentionBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
       * It is helpful if you need to control the size of log due to limited disk space.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
       */
      public Builder clearRetentionBytes() {
        if (retentionBytesBuilder_ == null) {
          retentionBytes_ = null;
          onChanged();
        } else {
          retentionBytes_ = null;
          retentionBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
       * It is helpful if you need to control the size of log due to limited disk space.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
       */
      public com.google.protobuf.Int64Value.Builder getRetentionBytesBuilder() {
        
        onChanged();
        return getRetentionBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
       * It is helpful if you need to control the size of log due to limited disk space.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getRetentionBytesOrBuilder() {
        if (retentionBytesBuilder_ != null) {
          return retentionBytesBuilder_.getMessageOrBuilder();
        } else {
          return retentionBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : retentionBytes_;
        }
      }
      /**
       * <pre>
       * The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the `delete` [cleanup_policy] is in effect.
       * It is helpful if you need to control the size of log due to limited disk space.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_bytes = 8;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getRetentionBytesFieldBuilder() {
        if (retentionBytesBuilder_ == null) {
          retentionBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getRetentionBytes(),
                  getParentForChildren(),
                  isClean());
          retentionBytes_ = null;
        }
        return retentionBytesBuilder_;
      }

      private com.google.protobuf.Int64Value retentionMs_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> retentionMsBuilder_;
      /**
       * <pre>
       * The number of milliseconds to keep a log segment's file before deleting it.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
       */
      public boolean hasRetentionMs() {
        return retentionMsBuilder_ != null || retentionMs_ != null;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment's file before deleting it.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
       */
      public com.google.protobuf.Int64Value getRetentionMs() {
        if (retentionMsBuilder_ == null) {
          return retentionMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : retentionMs_;
        } else {
          return retentionMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment's file before deleting it.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
       */
      public Builder setRetentionMs(com.google.protobuf.Int64Value value) {
        if (retentionMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          retentionMs_ = value;
          onChanged();
        } else {
          retentionMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment's file before deleting it.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
       */
      public Builder setRetentionMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (retentionMsBuilder_ == null) {
          retentionMs_ = builderForValue.build();
          onChanged();
        } else {
          retentionMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment's file before deleting it.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
       */
      public Builder mergeRetentionMs(com.google.protobuf.Int64Value value) {
        if (retentionMsBuilder_ == null) {
          if (retentionMs_ != null) {
            retentionMs_ =
              com.google.protobuf.Int64Value.newBuilder(retentionMs_).mergeFrom(value).buildPartial();
          } else {
            retentionMs_ = value;
          }
          onChanged();
        } else {
          retentionMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment's file before deleting it.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
       */
      public Builder clearRetentionMs() {
        if (retentionMsBuilder_ == null) {
          retentionMs_ = null;
          onChanged();
        } else {
          retentionMs_ = null;
          retentionMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment's file before deleting it.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
       */
      public com.google.protobuf.Int64Value.Builder getRetentionMsBuilder() {
        
        onChanged();
        return getRetentionMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment's file before deleting it.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getRetentionMsOrBuilder() {
        if (retentionMsBuilder_ != null) {
          return retentionMsBuilder_.getMessageOrBuilder();
        } else {
          return retentionMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : retentionMs_;
        }
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment's file before deleting it.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_retention_ms] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value retention_ms = 9;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getRetentionMsFieldBuilder() {
        if (retentionMsBuilder_ == null) {
          retentionMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getRetentionMs(),
                  getParentForChildren(),
                  isClean());
          retentionMs_ = null;
        }
        return retentionMsBuilder_;
      }

      private com.google.protobuf.Int64Value maxMessageBytes_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> maxMessageBytesBuilder_;
      /**
       * <pre>
       * The largest record batch size allowed in topic.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
       */
      public boolean hasMaxMessageBytes() {
        return maxMessageBytesBuilder_ != null || maxMessageBytes_ != null;
      }
      /**
       * <pre>
       * The largest record batch size allowed in topic.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
       */
      public com.google.protobuf.Int64Value getMaxMessageBytes() {
        if (maxMessageBytesBuilder_ == null) {
          return maxMessageBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : maxMessageBytes_;
        } else {
          return maxMessageBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The largest record batch size allowed in topic.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
       */
      public Builder setMaxMessageBytes(com.google.protobuf.Int64Value value) {
        if (maxMessageBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          maxMessageBytes_ = value;
          onChanged();
        } else {
          maxMessageBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The largest record batch size allowed in topic.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
       */
      public Builder setMaxMessageBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (maxMessageBytesBuilder_ == null) {
          maxMessageBytes_ = builderForValue.build();
          onChanged();
        } else {
          maxMessageBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The largest record batch size allowed in topic.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
       */
      public Builder mergeMaxMessageBytes(com.google.protobuf.Int64Value value) {
        if (maxMessageBytesBuilder_ == null) {
          if (maxMessageBytes_ != null) {
            maxMessageBytes_ =
              com.google.protobuf.Int64Value.newBuilder(maxMessageBytes_).mergeFrom(value).buildPartial();
          } else {
            maxMessageBytes_ = value;
          }
          onChanged();
        } else {
          maxMessageBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The largest record batch size allowed in topic.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
       */
      public Builder clearMaxMessageBytes() {
        if (maxMessageBytesBuilder_ == null) {
          maxMessageBytes_ = null;
          onChanged();
        } else {
          maxMessageBytes_ = null;
          maxMessageBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The largest record batch size allowed in topic.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
       */
      public com.google.protobuf.Int64Value.Builder getMaxMessageBytesBuilder() {
        
        onChanged();
        return getMaxMessageBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The largest record batch size allowed in topic.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getMaxMessageBytesOrBuilder() {
        if (maxMessageBytesBuilder_ != null) {
          return maxMessageBytesBuilder_.getMessageOrBuilder();
        } else {
          return maxMessageBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : maxMessageBytes_;
        }
      }
      /**
       * <pre>
       * The largest record batch size allowed in topic.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value max_message_bytes = 10;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getMaxMessageBytesFieldBuilder() {
        if (maxMessageBytesBuilder_ == null) {
          maxMessageBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getMaxMessageBytes(),
                  getParentForChildren(),
                  isClean());
          maxMessageBytes_ = null;
        }
        return maxMessageBytesBuilder_;
      }

      private com.google.protobuf.Int64Value minInsyncReplicas_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> minInsyncReplicasBuilder_;
      /**
       * <pre>
       * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
       * to be considered successful (when a producer sets acks to "all").
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
       */
      public boolean hasMinInsyncReplicas() {
        return minInsyncReplicasBuilder_ != null || minInsyncReplicas_ != null;
      }
      /**
       * <pre>
       * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
       * to be considered successful (when a producer sets acks to "all").
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
       */
      public com.google.protobuf.Int64Value getMinInsyncReplicas() {
        if (minInsyncReplicasBuilder_ == null) {
          return minInsyncReplicas_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : minInsyncReplicas_;
        } else {
          return minInsyncReplicasBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
       * to be considered successful (when a producer sets acks to "all").
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
       */
      public Builder setMinInsyncReplicas(com.google.protobuf.Int64Value value) {
        if (minInsyncReplicasBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          minInsyncReplicas_ = value;
          onChanged();
        } else {
          minInsyncReplicasBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
       * to be considered successful (when a producer sets acks to "all").
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
       */
      public Builder setMinInsyncReplicas(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (minInsyncReplicasBuilder_ == null) {
          minInsyncReplicas_ = builderForValue.build();
          onChanged();
        } else {
          minInsyncReplicasBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
       * to be considered successful (when a producer sets acks to "all").
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
       */
      public Builder mergeMinInsyncReplicas(com.google.protobuf.Int64Value value) {
        if (minInsyncReplicasBuilder_ == null) {
          if (minInsyncReplicas_ != null) {
            minInsyncReplicas_ =
              com.google.protobuf.Int64Value.newBuilder(minInsyncReplicas_).mergeFrom(value).buildPartial();
          } else {
            minInsyncReplicas_ = value;
          }
          onChanged();
        } else {
          minInsyncReplicasBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
       * to be considered successful (when a producer sets acks to "all").
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
       */
      public Builder clearMinInsyncReplicas() {
        if (minInsyncReplicasBuilder_ == null) {
          minInsyncReplicas_ = null;
          onChanged();
        } else {
          minInsyncReplicas_ = null;
          minInsyncReplicasBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
       * to be considered successful (when a producer sets acks to "all").
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
       */
      public com.google.protobuf.Int64Value.Builder getMinInsyncReplicasBuilder() {
        
        onChanged();
        return getMinInsyncReplicasFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
       * to be considered successful (when a producer sets acks to "all").
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getMinInsyncReplicasOrBuilder() {
        if (minInsyncReplicasBuilder_ != null) {
          return minInsyncReplicasBuilder_.getMessageOrBuilder();
        } else {
          return minInsyncReplicas_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : minInsyncReplicas_;
        }
      }
      /**
       * <pre>
       * This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write
       * to be considered successful (when a producer sets acks to "all").
       * </pre>
       *
       * <code>.google.protobuf.Int64Value min_insync_replicas = 11;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getMinInsyncReplicasFieldBuilder() {
        if (minInsyncReplicasBuilder_ == null) {
          minInsyncReplicasBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getMinInsyncReplicas(),
                  getParentForChildren(),
                  isClean());
          minInsyncReplicas_ = null;
        }
        return minInsyncReplicasBuilder_;
      }

      private com.google.protobuf.Int64Value segmentBytes_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> segmentBytesBuilder_;
      /**
       * <pre>
       * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
       * at a time so a larger segment size means fewer files but less granular control over retention.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_segment_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
       */
      public boolean hasSegmentBytes() {
        return segmentBytesBuilder_ != null || segmentBytes_ != null;
      }
      /**
       * <pre>
       * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
       * at a time so a larger segment size means fewer files but less granular control over retention.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_segment_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
       */
      public com.google.protobuf.Int64Value getSegmentBytes() {
        if (segmentBytesBuilder_ == null) {
          return segmentBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : segmentBytes_;
        } else {
          return segmentBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
       * at a time so a larger segment size means fewer files but less granular control over retention.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_segment_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
       */
      public Builder setSegmentBytes(com.google.protobuf.Int64Value value) {
        if (segmentBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          segmentBytes_ = value;
          onChanged();
        } else {
          segmentBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
       * at a time so a larger segment size means fewer files but less granular control over retention.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_segment_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
       */
      public Builder setSegmentBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (segmentBytesBuilder_ == null) {
          segmentBytes_ = builderForValue.build();
          onChanged();
        } else {
          segmentBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
       * at a time so a larger segment size means fewer files but less granular control over retention.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_segment_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
       */
      public Builder mergeSegmentBytes(com.google.protobuf.Int64Value value) {
        if (segmentBytesBuilder_ == null) {
          if (segmentBytes_ != null) {
            segmentBytes_ =
              com.google.protobuf.Int64Value.newBuilder(segmentBytes_).mergeFrom(value).buildPartial();
          } else {
            segmentBytes_ = value;
          }
          onChanged();
        } else {
          segmentBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
       * at a time so a larger segment size means fewer files but less granular control over retention.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_segment_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
       */
      public Builder clearSegmentBytes() {
        if (segmentBytesBuilder_ == null) {
          segmentBytes_ = null;
          onChanged();
        } else {
          segmentBytes_ = null;
          segmentBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
       * at a time so a larger segment size means fewer files but less granular control over retention.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_segment_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
       */
      public com.google.protobuf.Int64Value.Builder getSegmentBytesBuilder() {
        
        onChanged();
        return getSegmentBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
       * at a time so a larger segment size means fewer files but less granular control over retention.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_segment_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getSegmentBytesOrBuilder() {
        if (segmentBytesBuilder_ != null) {
          return segmentBytesBuilder_.getMessageOrBuilder();
        } else {
          return segmentBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : segmentBytes_;
        }
      }
      /**
       * <pre>
       * This configuration controls the segment file size for the log. Retention and cleaning is always done a file
       * at a time so a larger segment size means fewer files but less granular control over retention.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_segment_bytes] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value segment_bytes = 12;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getSegmentBytesFieldBuilder() {
        if (segmentBytesBuilder_ == null) {
          segmentBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getSegmentBytes(),
                  getParentForChildren(),
                  isClean());
          segmentBytes_ = null;
        }
        return segmentBytesBuilder_;
      }

      private com.google.protobuf.BoolValue preallocate_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder> preallocateBuilder_;
      /**
       * <pre>
       * True if we should preallocate the file on disk when creating a new log segment.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_preallocate] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue preallocate = 13;</code>
       */
      public boolean hasPreallocate() {
        return preallocateBuilder_ != null || preallocate_ != null;
      }
      /**
       * <pre>
       * True if we should preallocate the file on disk when creating a new log segment.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_preallocate] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue preallocate = 13;</code>
       */
      public com.google.protobuf.BoolValue getPreallocate() {
        if (preallocateBuilder_ == null) {
          return preallocate_ == null ? com.google.protobuf.BoolValue.getDefaultInstance() : preallocate_;
        } else {
          return preallocateBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * True if we should preallocate the file on disk when creating a new log segment.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_preallocate] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue preallocate = 13;</code>
       */
      public Builder setPreallocate(com.google.protobuf.BoolValue value) {
        if (preallocateBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          preallocate_ = value;
          onChanged();
        } else {
          preallocateBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * True if we should preallocate the file on disk when creating a new log segment.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_preallocate] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue preallocate = 13;</code>
       */
      public Builder setPreallocate(
          com.google.protobuf.BoolValue.Builder builderForValue) {
        if (preallocateBuilder_ == null) {
          preallocate_ = builderForValue.build();
          onChanged();
        } else {
          preallocateBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * True if we should preallocate the file on disk when creating a new log segment.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_preallocate] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue preallocate = 13;</code>
       */
      public Builder mergePreallocate(com.google.protobuf.BoolValue value) {
        if (preallocateBuilder_ == null) {
          if (preallocate_ != null) {
            preallocate_ =
              com.google.protobuf.BoolValue.newBuilder(preallocate_).mergeFrom(value).buildPartial();
          } else {
            preallocate_ = value;
          }
          onChanged();
        } else {
          preallocateBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * True if we should preallocate the file on disk when creating a new log segment.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_preallocate] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue preallocate = 13;</code>
       */
      public Builder clearPreallocate() {
        if (preallocateBuilder_ == null) {
          preallocate_ = null;
          onChanged();
        } else {
          preallocate_ = null;
          preallocateBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * True if we should preallocate the file on disk when creating a new log segment.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_preallocate] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue preallocate = 13;</code>
       */
      public com.google.protobuf.BoolValue.Builder getPreallocateBuilder() {
        
        onChanged();
        return getPreallocateFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * True if we should preallocate the file on disk when creating a new log segment.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_preallocate] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue preallocate = 13;</code>
       */
      public com.google.protobuf.BoolValueOrBuilder getPreallocateOrBuilder() {
        if (preallocateBuilder_ != null) {
          return preallocateBuilder_.getMessageOrBuilder();
        } else {
          return preallocate_ == null ?
              com.google.protobuf.BoolValue.getDefaultInstance() : preallocate_;
        }
      }
      /**
       * <pre>
       * True if we should preallocate the file on disk when creating a new log segment.
       * This setting overrides the cluster-level [KafkaConfig2_6.log_preallocate] setting on the topic level.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue preallocate = 13;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder> 
          getPreallocateFieldBuilder() {
        if (preallocateBuilder_ == null) {
          preallocateBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder>(
                  getPreallocate(),
                  getParentForChildren(),
                  isClean());
          preallocate_ = null;
        }
        return preallocateBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.TopicConfig2_6)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.TopicConfig2_6)
    private static final yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6();
    }

    public static yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<TopicConfig2_6>
        PARSER = new com.google.protobuf.AbstractParser<TopicConfig2_6>() {
      @java.lang.Override
      public TopicConfig2_6 parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new TopicConfig2_6(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<TopicConfig2_6> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<TopicConfig2_6> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.TopicOuterClass.TopicConfig2_6 getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_Topic_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_Topic_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_TopicSpec_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_TopicSpec_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_TopicConfig2_1_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_TopicConfig2_1_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_TopicConfig2_6_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_TopicConfig2_6_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n%yandex/cloud/mdb/kafka/v1/topic.proto\022" +
      "\031yandex.cloud.mdb.kafka.v1\032\036google/proto" +
      "buf/wrappers.proto\032\035yandex/cloud/validat" +
      "ion.proto\032&yandex/cloud/mdb/kafka/v1/com" +
      "mon.proto\"\323\002\n\005Topic\022\014\n\004name\030\001 \001(\t\022\022\n\nclu" +
      "ster_id\030\002 \001(\t\022/\n\npartitions\030\003 \001(\0132\033.goog" +
      "le.protobuf.Int64Value\0227\n\022replication_fa" +
      "ctor\030\004 \001(\0132\033.google.protobuf.Int64Value\022" +
      "V\n\020topic_config_2_1\030\005 \001(\0132).yandex.cloud" +
      ".mdb.kafka.v1.TopicConfig2_1H\000R\017topicCon" +
      "fig_2_1\022V\n\020topic_config_2_6\030\006 \001(\0132).yand" +
      "ex.cloud.mdb.kafka.v1.TopicConfig2_6H\000R\017" +
      "topicConfig_2_6B\016\n\014topic_config\"\241\002\n\tTopi" +
      "cSpec\022\014\n\004name\030\001 \001(\t\022/\n\npartitions\030\002 \001(\0132" +
      "\033.google.protobuf.Int64Value\0227\n\022replicat" +
      "ion_factor\030\003 \001(\0132\033.google.protobuf.Int64" +
      "Value\022E\n\020topic_config_2_1\030\004 \001(\0132).yandex" +
      ".cloud.mdb.kafka.v1.TopicConfig2_1H\000\022E\n\020" +
      "topic_config_2_6\030\005 \001(\0132).yandex.cloud.md" +
      "b.kafka.v1.TopicConfig2_6H\000B\016\n\014topic_con" +
      "fig\"\214\007\n\016TopicConfig2_1\022O\n\016cleanup_policy" +
      "\030\001 \001(\01627.yandex.cloud.mdb.kafka.v1.Topic" +
      "Config2_1.CleanupPolicy\022D\n\020compression_t" +
      "ype\030\002 \001(\0162*.yandex.cloud.mdb.kafka.v1.Co" +
      "mpressionType\0228\n\023delete_retention_ms\030\003 \001" +
      "(\0132\033.google.protobuf.Int64Value\0229\n\024file_" +
      "delete_delay_ms\030\004 \001(\0132\033.google.protobuf." +
      "Int64Value\0223\n\016flush_messages\030\005 \001(\0132\033.goo" +
      "gle.protobuf.Int64Value\022-\n\010flush_ms\030\006 \001(" +
      "\0132\033.google.protobuf.Int64Value\022:\n\025min_co" +
      "mpaction_lag_ms\030\007 \001(\0132\033.google.protobuf." +
      "Int64Value\0224\n\017retention_bytes\030\010 \001(\0132\033.go" +
      "ogle.protobuf.Int64Value\0221\n\014retention_ms" +
      "\030\t \001(\0132\033.google.protobuf.Int64Value\0226\n\021m" +
      "ax_message_bytes\030\n \001(\0132\033.google.protobuf" +
      ".Int64Value\0228\n\023min_insync_replicas\030\013 \001(\013" +
      "2\033.google.protobuf.Int64Value\0222\n\rsegment" +
      "_bytes\030\014 \001(\0132\033.google.protobuf.Int64Valu" +
      "e\022/\n\013preallocate\030\r \001(\0132\032.google.protobuf" +
      ".BoolValue\"\215\001\n\rCleanupPolicy\022\036\n\032CLEANUP_" +
      "POLICY_UNSPECIFIED\020\000\022\031\n\025CLEANUP_POLICY_D" +
      "ELETE\020\001\022\032\n\026CLEANUP_POLICY_COMPACT\020\002\022%\n!C" +
      "LEANUP_POLICY_COMPACT_AND_DELETE\020\003\"\214\007\n\016T" +
      "opicConfig2_6\022O\n\016cleanup_policy\030\001 \001(\01627." +
      "yandex.cloud.mdb.kafka.v1.TopicConfig2_6" +
      ".CleanupPolicy\022D\n\020compression_type\030\002 \001(\016" +
      "2*.yandex.cloud.mdb.kafka.v1.Compression" +
      "Type\0228\n\023delete_retention_ms\030\003 \001(\0132\033.goog" +
      "le.protobuf.Int64Value\0229\n\024file_delete_de" +
      "lay_ms\030\004 \001(\0132\033.google.protobuf.Int64Valu" +
      "e\0223\n\016flush_messages\030\005 \001(\0132\033.google.proto" +
      "buf.Int64Value\022-\n\010flush_ms\030\006 \001(\0132\033.googl" +
      "e.protobuf.Int64Value\022:\n\025min_compaction_" +
      "lag_ms\030\007 \001(\0132\033.google.protobuf.Int64Valu" +
      "e\0224\n\017retention_bytes\030\010 \001(\0132\033.google.prot" +
      "obuf.Int64Value\0221\n\014retention_ms\030\t \001(\0132\033." +
      "google.protobuf.Int64Value\0226\n\021max_messag" +
      "e_bytes\030\n \001(\0132\033.google.protobuf.Int64Val" +
      "ue\0228\n\023min_insync_replicas\030\013 \001(\0132\033.google" +
      ".protobuf.Int64Value\0222\n\rsegment_bytes\030\014 " +
      "\001(\0132\033.google.protobuf.Int64Value\022/\n\013prea" +
      "llocate\030\r \001(\0132\032.google.protobuf.BoolValu" +
      "e\"\215\001\n\rCleanupPolicy\022\036\n\032CLEANUP_POLICY_UN" +
      "SPECIFIED\020\000\022\031\n\025CLEANUP_POLICY_DELETE\020\001\022\032" +
      "\n\026CLEANUP_POLICY_COMPACT\020\002\022%\n!CLEANUP_PO" +
      "LICY_COMPACT_AND_DELETE\020\003Bd\n\035yandex.clou" +
      "d.api.mdb.kafka.v1ZCgithub.com/yandex-cl" +
      "oud/go-genproto/yandex/cloud/mdb/kafka/v" +
      "1;kafkab\006proto3"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
        new com.google.protobuf.Descriptors.FileDescriptor.    InternalDescriptorAssigner() {
          public com.google.protobuf.ExtensionRegistry assignDescriptors(
              com.google.protobuf.Descriptors.FileDescriptor root) {
            descriptor = root;
            return null;
          }
        };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          com.google.protobuf.WrappersProto.getDescriptor(),
          yandex.cloud.api.Validation.getDescriptor(),
          yandex.cloud.api.mdb.kafka.v1.Common.getDescriptor(),
        }, assigner);
    internal_static_yandex_cloud_mdb_kafka_v1_Topic_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_yandex_cloud_mdb_kafka_v1_Topic_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_Topic_descriptor,
        new java.lang.String[] { "Name", "ClusterId", "Partitions", "ReplicationFactor", "TopicConfig21", "TopicConfig26", "TopicConfig", });
    internal_static_yandex_cloud_mdb_kafka_v1_TopicSpec_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_yandex_cloud_mdb_kafka_v1_TopicSpec_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_TopicSpec_descriptor,
        new java.lang.String[] { "Name", "Partitions", "ReplicationFactor", "TopicConfig21", "TopicConfig26", "TopicConfig", });
    internal_static_yandex_cloud_mdb_kafka_v1_TopicConfig2_1_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_yandex_cloud_mdb_kafka_v1_TopicConfig2_1_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_TopicConfig2_1_descriptor,
        new java.lang.String[] { "CleanupPolicy", "CompressionType", "DeleteRetentionMs", "FileDeleteDelayMs", "FlushMessages", "FlushMs", "MinCompactionLagMs", "RetentionBytes", "RetentionMs", "MaxMessageBytes", "MinInsyncReplicas", "SegmentBytes", "Preallocate", });
    internal_static_yandex_cloud_mdb_kafka_v1_TopicConfig2_6_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_yandex_cloud_mdb_kafka_v1_TopicConfig2_6_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_TopicConfig2_6_descriptor,
        new java.lang.String[] { "CleanupPolicy", "CompressionType", "DeleteRetentionMs", "FileDeleteDelayMs", "FlushMessages", "FlushMs", "MinCompactionLagMs", "RetentionBytes", "RetentionMs", "MaxMessageBytes", "MinInsyncReplicas", "SegmentBytes", "Preallocate", });
    com.google.protobuf.WrappersProto.getDescriptor();
    yandex.cloud.api.Validation.getDescriptor();
    yandex.cloud.api.mdb.kafka.v1.Common.getDescriptor();
  }

  // @@protoc_insertion_point(outer_class_scope)
}
